{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Presentation of the OpenBHB dataset\n\nThis notebook introduces the OpenBHB dataset [1]_, a large-scale, multi-site\nbrain MRI dataset. It is designed to perform benchmarking of machine learning\nand deep learning models on neuroimaging data.\n\nWe will demonstrate how to use OpenBHB for:\n\n- **Age prediction** [4]_\n- **Sex classification** [5]_\n- **Brain aging trajectories modeling** [2]_, [6]_\n\nWe will start by visualizing the available resources in OpenBHB, then we will\ndemonstrate how to perform these prediction tasks.\n\n\n## Load the packages\n\nFirst, we need to load the packages to run this notebook:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import packages\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport nibabel\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom nilearn import datasets, plotting\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel, WhiteKernel\nfrom sklearn.linear_model import LogisticRegression, Ridge\nfrom sklearn.metrics import (\n    accuracy_score,\n    r2_score,\n)\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\n\nfrom nidl.datasets import OpenBHB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the OpenBHB dataset and plot the modalities\n\nOpenBHB contains 6 modalities (or preprocessed data) of healthy subject\nanatomical brains. It contains $n_{train}=3227$ training images and\n$n_{val}=757$ validation images. Demographic information about the\nsubjects (age, sex) are available along with the details on the acquisition\nmachines (magnetic field strength, acquisition setting).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = OpenBHB(\n    root=\"/tmp/openBHB\",\n    modality=(\n        \"vbm\",\n        \"quasiraw\",\n        \"vbm_roi\",\n        \"fs_desikan_roi\",\n        \"fs_destrieux_roi\",\n        \"fs_xhemi\",\n    ),\n    target=[\"age\", \"sex\", \"site\"],\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot whole-brain Voxel-Based Morphometry (VBM) and Quasi-Raw images\n\nLet's take a look at the first subject in the dataset. We'll visualize two\ndifferent modalities:\n\n- **VBM** (Voxel-Based Morphometry): gray matter density maps computed using\n  the CAT12 toolbox. VBM preprocessing involves tissue segmentation, normalization\n  to MNI space, and modulation, resulting in voxel-wise maps that reflect local gray\n  matter volume.\n- **Quasi-Raw**: T1-weighted MRI scans that have been preprocessed with basic\n  steps like bias correction and skull stripping, but without spatial normalization\n  or heavy smoothing. The goal is to retain as much of the anatomical detail of the\n  original scan as possible, providing input that is close to raw data while still\n  being in the same physical space across subjects.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "all_mods, infos = dataset[0]  # Get data from first subject\n\n# VBM\nimg_vbm = all_mods[\"vbm\"][0]  # select the first (and only) channel\nnii_img = nibabel.Nifti1Image(img_vbm, affine=np.eye(4))\nprint(img_vbm.shape)\nplotting.plot_anat(nii_img, title=f\"VBM image (infos={infos})\")\n\n# Quasi-Raw\nimg_quasiraw = all_mods[\"quasiraw\"][0]  # select the first (and only) channel\nnii_img = nibabel.Nifti1Image(img_quasiraw, affine=np.eye(4))\nplotting.plot_anat(nii_img, title=f\"Quasi-Raw image (infos={infos})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot VBM-ROI on the Neuromorphometrics atlas\n\nIn this visualization, we map **regional gray matter volumes (VBM-ROI)** onto\na brain template using the Neuromorphometrics atlas**:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# - The VBM-ROI features are computed by averaging voxel-wise gray matter volumes\n#   within each of the **142 anatomical regions** defined in the atlas.\n# - Each region corresponds to a gray matter structure, and volumes are\n#   extracted independently for each hemisphere.\n# - The resulting brain map shows the **regional gray matter volume in\n#   milliliters (mL)**.\n\n\ndef map_roi_on_neuromorphometrics_atlas(roi_values, labels, atlas):\n    # Map ROI values on the Neuromorphometrics atlas\n    atlas_data = atlas[\"data\"].get_fdata()\n    atlas_labels = atlas[\"labels\"]\n    brain_map = np.zeros_like(atlas_data)\n    idx_mapping = {name: atlas_labels.index(name) for name in labels}\n    for idx, label in enumerate(labels):\n        brain_map[atlas_data == idx_mapping[label]] = roi_values[idx]\n    brain_map = nibabel.Nifti1Image(brain_map, affine=atlas[\"data\"].affine)\n    return brain_map\n\n\n# Step 1: Select regional gray matter volumes for the first subject\n# first 142 ROI volumes (gray matter only)\nvbm_roi = all_mods[\"vbm_roi\"][0][:142]\n\n# Step 2: Clean up ROI labels (remove '_GM_Vol' suffix)\nlabels = [\n    label.replace(\"_GM_Vol\", \"\")\n    for label in dataset.get_vbm_roi_labels()[:142]\n]\n\n# Step 3: Load the Neuromorphometrics atlas used for mapping\natlas = dataset.get_neuromorphometrics_atlas()\n\n# Step 4: Project the ROI values onto the brain volume using the atlas\nbrain_map = map_roi_on_neuromorphometrics_atlas(vbm_roi, labels, atlas)\n\n# Step 5: Plot the resulting brain map\nplotting.plot_stat_map(\n    brain_map,\n    title=\"Regional Gray Matter Volume (mL)\",\n    cmap=\"plasma\",  # visually appealing sequential colormap\n    draw_cross=False,\n    colorbar=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Surface-Based Measures from FreeSurfer\n\nThe OpenBHB dataset includes **surface-based cortical measurements** extracted\nusing FreeSurfer, such as:\n\n- **Cortical thickness**\n- **Surface area**\n- **Gray matter volume**\n- **Curvature**\n\nThese measures are averaged over predefined regions from:\n\n- The **Desikan-Killiany atlas** (34 cortical regions per hemisphere)\n- The **Destrieux atlas** (74 cortical regions per hemisphere, excluding the\n  medial wall)\n\nEach value represents a regional summary of the surface geometry or morphology\nof the cortex. In addition, OpenBHB provides **xhemi** (cross-hemisphere) data\ncomputed on the fsaverage7 template (163842 vertices), which merges homologous\nregions across both hemispheres. This allows for analysis that reduces hemispheric\nasymmetries and improves statistical power by combining left and right hemisphere\ninformation.\n\nIn the following, we will define a small utility function to map these regional\nvalues onto the standard FreeSurfer surface (fsaverage5) for visualization of\nDesikan and Destrieux-based measures. For the xhemi data, which is computed\non the higher-resolution fsaverage7 surface, visualization can be done similarly\nbut requires using the corresponding fsaverage7 mesh files.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize regional measures on the Destrieux atlas\n\nWe start by visualizing the regional measures based on the Destrieux atlas.\nThe following function maps the regional values onto the fsaverage5 surface\nfor visualization.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def map_freesurfer_destrieux_data(roi_values, labels, hemi=\"left\"):\n    # Load Destrieux atlas\n    fsaverage = datasets.fetch_atlas_surf_destrieux(verbose=0)\n    fs_labels = list(fsaverage[\"labels\"])\n    map_hemi = fsaverage[f\"map_{hemi}\"]\n\n    # Map ROI values to vertex-wise data using the labels\n    idx_mapping = {name: fs_labels.index(name) for name in labels}\n    vertex_data = np.zeros_like(map_hemi, dtype=float)\n\n    for idx, roi_name in enumerate(labels):\n        vertex_data[map_hemi == idx_mapping[roi_name]] = roi_values[idx]\n\n    return vertex_data\n\n\n# Load the correct channel index for the features\nsurface_area = dataset.get_fs_roi_feature_names().index(\"surface_area_mm^2\")\nvolume = dataset.get_fs_roi_feature_names().index(\"gray_matter_volume_mm^3\")\nthickness = dataset.get_fs_roi_feature_names().index(\"average_thickness_mm\")\ncurvature = dataset.get_fs_roi_feature_names().index(\n    \"integrated_rectified_mean_curvature_mm^-1\"\n)\n# Load the ROI data\nlabels = dataset.get_fs_labels(symmetric=True)\nfs_surface = all_mods[\"fs_destrieux_roi\"][surface_area]\nfs_volume = all_mods[\"fs_destrieux_roi\"][volume]\nfs_thickness = all_mods[\"fs_destrieux_roi\"][thickness]\nfs_curv = all_mods[\"fs_destrieux_roi\"][curvature]\n# Map the ROI on the Destrieux surfacic atlas\nsurface_vertex = map_freesurfer_destrieux_data(fs_surface, labels)\nvolume_vertex = map_freesurfer_destrieux_data(fs_volume, labels)\nthickness_vertex = map_freesurfer_destrieux_data(fs_thickness, labels)\ncurv_vertex = map_freesurfer_destrieux_data(fs_curv, labels)\n\n# Prepare plots\ndata = [surface_vertex, volume_vertex, thickness_vertex, curv_vertex]\ntitles = [\n    \"Surface area ($mm^2$)\",\n    \"GM volume ($mm^3$)\",\n    \"Cortical thickness ($mm$)\",\n    \"Mean curvature ($mm^{-1}$)\",\n]\n\nfsaverage = datasets.fetch_surf_fsaverage(mesh=\"fsaverage5\")\ninflated_left = fsaverage[\"infl_left\"]\nsulc_left = fsaverage[\"sulc_left\"]\nfig, axes = plt.subplots(\n    1, 4, figsize=(12, 3), subplot_kw={\"projection\": \"3d\"}\n)\n# Plot each measurement\nfor ax, dat, title in zip(axes, data, titles):\n    plotting.plot_surf(\n        inflated_left,\n        surf_map=dat,\n        hemi=\"left\",\n        view=\"lateral\",\n        bg_map=sulc_left,\n        cmap=\"plasma\",\n        colorbar=True,\n        axes=ax,\n        title=title,\n        figure=fig,\n    )\n\nplt.subplots_adjust(wspace=0.25)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize fine-grained measures on the fsaverage7 template\n\nNext, we visualize more fine-grained FreeSurfer surface features on\nthe left hemisphere using the higher-resolution fsaverage7 template:\n\n- `lh.curv`: Mean curvature map of the cortical surface, reflecting folding\n  patterns (arbitrary unit, negative=sulci, positive=gyri).\n- `lh.sulc`: Sulcal depth map, indicating the depth of sulci (cortical folds),\n  in millimiter.\n- `lh.thickness`: Cortical thickness values at each vertex (in millimiter).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load the correct channels for xhemi\nthickness = dataset.get_fs_xhemi_feature_names().index(\"lh.thickness\")\nsulc = dataset.get_fs_xhemi_feature_names().index(\"lh.sulc\")\ncurv = dataset.get_fs_xhemi_feature_names().index(\"lh.curv\")\n# Load the xhemi data\nfs_thickness = all_mods[\"fs_xhemi\"][thickness]\nfs_sulc = all_mods[\"fs_xhemi\"][sulc]\nfs_curv = all_mods[\"fs_xhemi\"][curv]\n# Get fsaverage7 template\nfsaverage = datasets.fetch_surf_fsaverage(mesh=\"fsaverage7\")\ninfl_left = fsaverage[\"infl_left\"]\nsulc_left = fsaverage[\"sulc_left\"]\n\n# Prepare plots\ndata = [fs_thickness, fs_sulc, fs_curv]\ntitles = [\n    \"Cortical thickness (in $mm$)\",\n    \"Sulcal depth (in $mm$)\",\n    \"Curvature\",\n]\nfig, axes = plt.subplots(1, 3, figsize=(9, 4), subplot_kw={\"projection\": \"3d\"})\n\nfor ax, dat, title in zip(axes, data, titles):\n    plotting.plot_surf(\n        infl_left,\n        surf_map=dat,\n        hemi=\"left\",\n        bg_map=sulc_left,\n        darkness=0.5,\n        cmap=\"plasma\",\n        colorbar=True,\n        axes=ax,\n        title=title,\n        figure=fig,\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit machine learning models for age and sex prediction\n\nNow that we have explored the different modalities in OpenBHB, we will\ndemonstrate how to use them to fit simple machine learning models on two\nstandard benchmarking tasks: age prediction (regression) and sex\nclassification.\nWe will compare three representations of the brain:\n\n- the **VBM-ROI** features, which provides regional gray matter volumes based\n  on the Neuromorphometrics atlas,\n- the **Desikan-based SBM ROI** features, which provide surface-based\n  measures in 68 cortical regions,\n- the **Destrieux-based SBM ROI** features, which provide surface-based\n  measures in 148 cortical regions.\n\nWe start by loading all the relevant datasets for these tasks:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "modalities = [\"vbm_roi\", \"fs_desikan_roi\", \"fs_destrieux_roi\"]\n\nmodality_names = {\n    \"vbm_roi\": \"VBM-Neuromorphometrics\",\n    \"fs_desikan_roi\": \"SBM-Desikan\",\n    \"fs_destrieux_roi\": \"SBM-Destrieux\",\n}\ndataset_train = OpenBHB(\n    \"/tmp/openBHB\",\n    modality=modalities,\n    target=[\"age\", \"sex\"],\n    split=\"train\",\n    streaming=True,\n)\ndataset_val = OpenBHB(\n    \"/tmp/openBHB\",\n    modality=modalities,\n    target=[\"age\", \"sex\"],\n    split=\"val\",\n    streaming=True,\n)\n\n\ndef extract_features_and_targets(dataset, modalities=modalities):\n    \"\"\"Extract features and target arrays from OpenBHB dataset.\"\"\"\n    X, y_age, y_sex = {m: [] for m in modalities}, [], []\n\n    for x, y in dataset:\n        for m in modalities:\n            X[m].append(x[m].flatten())\n        y_age.append(y[\"age\"])\n        y_sex.append(y[\"sex\"])\n\n    return (\n        {m: np.array(x) for m, x in X.items()},\n        np.array(y_age),\n        np.array(y_sex),\n    )\n\n\nX_train, y_train_age, y_train_sex = extract_features_and_targets(dataset_train)\nX_test, y_test_age, y_test_sex = extract_features_and_targets(dataset_val)\nprint(\"Age range:\", y_train_age.min(), \"-\", y_train_age.max())\nprint(\"Sex distribution:\\n\", pd.Series(y_train_sex).value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Age prediction with Ridge regression\n\nWe will use a Ridge regression model with standard scaling as a baseline\nfor age prediction. We will evaluate the model using the R\u00b2 score and visualize\nthe predicted vs. true ages for the three modalities.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "colors = {\n    \"vbm_roi\": \"tab:blue\",\n    \"fs_desikan_roi\": \"tab:green\",\n    \"fs_destrieux_roi\": \"tab:orange\",\n}\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5), sharex=True, sharey=True)\n\nfor ax, modality in zip(axes, modalities):\n    ridge_model = make_pipeline(StandardScaler(), Ridge(alpha=1.0))\n    ridge_model.fit(X_train[modality], y_train_age)\n    y_pred_age = ridge_model.predict(X_test[modality])\n    score = r2_score(y_test_age, y_pred_age)\n\n    sns.scatterplot(\n        x=y_test_age,\n        y=y_pred_age,\n        alpha=0.5,\n        edgecolor=None,\n        color=colors[modality],\n        ax=ax,\n    )\n    # Add reference line y=x\n    sns.lineplot(\n        x=y_test_age,\n        y=y_test_age,\n        color=\"red\",\n        linestyle=\"--\",\n        ax=ax,\n    )\n\n    ax.set_title(f\"{modality_names[modality]}\\nR\u00b2={score:.2f}\")\n    ax.set_xlabel(\"True Age\")\n    ax.set_ylabel(\"Predicted Age\")\n    ax.grid(True)\n\nplt.suptitle(\"Age Prediction with Ridge Regression\", fontsize=14, y=1.02)\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sex classification with logistic regression\n\nNext, we will use a logistic regression model with standard scaling as a\nbaseline for sex classification. We will evaluate the model using accuracy.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "accuracies = []\n\nfor modality in modalities:\n    logreg_model = make_pipeline(\n        StandardScaler(), LogisticRegression(max_iter=1000)\n    )\n    logreg_model.fit(X_train[modality], y_train_sex)\n    y_pred_sex = logreg_model.predict(X_test[modality])\n    acc = accuracy_score(y_test_sex, y_pred_sex)\n    accuracies.append(acc)\n\nplt.figure(figsize=(6, 4))\nsns.barplot(\n    x=[modality_names[m] for m in modalities],\n    y=accuracies,\n    palette=colors.values(),\n)\n\nplt.xlabel(\"Modality\")\nplt.ylabel(\"Accuracy\")\nplt.ylim(0, 1.0)\nplt.title(\"Sex Classification with Logistic Regression\")\n\n# Add accuracy text above bars\nfor i, acc in enumerate(accuracies):\n    plt.text(i, acc + 0.02, f\"{acc:.2f}\", ha=\"center\", fontsize=10)\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observations: the VBM representation gives the best results for both tasks,\nindicating that regional gray matter volumes are highly informative for predicting\nage and sex. Nevertheless, it would be interesting to check whether combining the\nmodalities would improve the result, which would mean that they provide complementary\ninformation. This is left as an exercise to the reader.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modeling brain aging trajectories\n\nSince brain morphometric features have been computed for all subjects in\nOpenBHB, we can study the brain atrophy patterns across subjects age [2]_.\nSpecifically, we will use gray matter volumes computed on the\nNeuromorphometrics atlas for each subject to regress a Gaussian Process\nRegression (GPR) against age. This way, we will estimate the mean and\nstandard variation of the GM volume trajectories.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We start by formatting correctly the previous data before fitting the GPR.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(\n    np.concatenate((X_train[\"vbm_roi\"], X_test[\"vbm_roi\"])),\n    columns=dataset_train.get_vbm_roi_labels(),\n)\nage = np.concatenate((y_train_age, y_test_age))\nsex = np.concatenate((y_train_sex, y_test_sex))\ntiv = np.array(dataset_train.get_participants()[\"tiv\"])\n\n# Mapping region codes to clean names\nregion_map = {\n    \"Hip\": \"Hippocampus\",\n    \"Amy\": \"Amygdala\",\n    \"LatVen\": \"Lateral Ventricles\",\n    \"Cau\": \"Caudate\",\n    \"Put\": \"Putamen\",\n    \"Pal\": \"Pallidum\",\n    \"ThaPro\": \"Thalamus\",\n    \"Acc\": \"Nucleus Accumbens\",\n    \"FusGy\": \"Fusiform Gyrus\",\n    \"MidFroGy\": \"Middle Frontal Gyrus\",\n    \"PoCGy\": \"Postcentral Gyrus\",\n    \"PrcGy\": \"Precentral Gyrus\",\n}\n\nregions = list(region_map.values())\n\n\n# Average left/right regions + normalize by TIV\ndef average_hemispheres_and_tiv_normalized(df):\n    avg_data = {}\n    for region, region_name in region_map.items():\n        l_col = f\"l{region}_GM_Vol\"\n        r_col = f\"r{region}_GM_Vol\"\n        if l_col in df.columns and r_col in df.columns:\n            avg_data[region_name] = (df[l_col] + df[r_col]) / 2\n        avg_data[region_name] = avg_data[region_name] / tiv\n    return pd.DataFrame(avg_data)\n\n\ndf = average_hemispheres_and_tiv_normalized(df)\ndf[\"age\"] = age\ndf[\"sex\"] = sex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now fit the GPR model to obtain brain aging trajectories\nof gray matter volumes:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gpr_results = {}\nfor sex in [\"male\", \"female\"]:\n    df_sex = df[df[\"sex\"] == sex]\n    X = df_sex[\"age\"].values.reshape(-1, 1)\n    X_orig = np.copy(X)\n    y = df_sex[regions].values\n\n    X = MinMaxScaler().fit_transform(X)\n\n    # Define kernel: Constant * RBF\n    kernel = ConstantKernel(1.0, (0.1, 10.0)) * RBF() + WhiteKernel(\n        noise_level=0.05, noise_level_bounds=(1e-4, 1.0)\n    )\n\n    # Fit Gaussian Process\n    gpr = GaussianProcessRegressor(\n        kernel=kernel,\n        alpha=1e-7,\n        normalize_y=True,\n        random_state=42,\n    )\n    gpr.fit(X, y)\n\n    # Predictions with uncertainty\n    X_grid = np.linspace(X.min(), X.max(), 200).reshape(-1, 1)\n    y_mean, y_std = gpr.predict(X_grid, return_std=True)\n    X_grid = np.linspace(X_orig.min(), X_orig.max(), 200).reshape(-1, 1)\n    gpr_results[sex] = (X_grid, y_mean, y_std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we plot the brain trajectories per brain region:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sns.set_theme(style=\"whitegrid\")\nsex_palette = {\n    \"male\": \"skyblue\",\n    \"female\": \"salmon\",\n}\nn_cols = 3\nn_rows = int(np.ceil(len(regions) / n_cols))\nfig, axes = plt.subplots(\n    n_rows, n_cols, figsize=(18, n_rows * 3.5), sharex=True\n)\naxes = axes.flatten()\nfor i, region in enumerate(regions):\n    ax = axes[i]\n    sns.scatterplot(\n        data=df,\n        x=\"age\",\n        y=region,\n        hue=\"sex\",\n        palette=sex_palette,\n        ax=ax,\n        alpha=0.7,\n        s=40,\n    )\n    ax.legend(title=\"Sex\")\n\n    for sex in [\"male\", \"female\"]:\n        # Plot\n        X_grid, y_mean, y_std = gpr_results[sex]\n        y_mean, y_std = y_mean[:, i], y_std[:, i]\n        ax.plot(X_grid, y_mean, color=sex_palette[sex], lw=2)\n        ax.fill_between(\n            X_grid.ravel(),\n            y_mean - 1.96 * y_std,\n            y_mean + 1.96 * y_std,\n            color=\"blue\",\n            alpha=0.1,\n        )\n        ax.legend()\n        ax.set_title(region, fontsize=13)\n        ax.set_xlabel(\"Age\")\n        ax.set_ylabel(\"GM volume (TIV-normalized)\")\n\nplt.tight_layout(rect=[0, 0, 0.9, 1])\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observations: We retrieve some results from the literature [2]_, [3]_\nin particular regarding the earlier atrophy of the thalamus compared to\nhippocampus and amygdala (relatively preserved until 50-60 years old) and\nglobal atrophy early-on of pre-central and post-central gryus.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. [1] Dufumier et al., OpenBHB: a Large-Scale Multi-Site Brain MRI Dataset\n       for Age Prediction and Debiasing, NeuroImage, 2022.\n       https://www.sciencedirect.com/science/article/pii/S1053811922007522\n.. [2] Bethlehem et al., Brain charts for the human lifespan, Nature 2022\n       https://www.nature.com/articles/s41586-022-04554-y.pdf\n.. [3] Subcortical volumes across the lifespan: Data from 18,605 healthy\n       individuals aged 3\u201390 years, Hum. Brain Mapping, 2022\n       https://onlinelibrary.wiley.com/doi/pdf/10.1002/hbm.25320\n.. [4] Cole et al., Predicting brain age with deep learning from raw imaging\n       data results in a reliable and heritable biomarker, NeuroImage, 2017\n       https://www.sciencedirect.com/science/article/pii/S1053811917306407\n.. [5] Ryali et al., Deep learning models reveal replicable, generalizable,\n       and behaviorally relevant sex differences in human functional brain\n       organization, Proceedings of the National Academy of Sciences, 2024\n       https://www.pnas.org/doi/10.1073/pnas.2310012121\n.. [6] Raznahan et al., How does your cortex grow?, J. Neurosci., 2011\n       https://www.jneurosci.org/content/31/19/7174\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}