{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Visualization of metrics during training of PyTorch-Lightning models\n\nThe current logic in nidl is to separate the implementation of the actual model\n(i.e. everything required to fit the model on data) from everything else, such\nas metrics computation and logging. This is usually performed to check the\nbehavior of a model during training or validation but it is not essential for\nfitting.\n\nThis notebook will show you how to visualize some metrics (either given by\n``torchmetrics``, ``scikit-learn`` or a custom function score) during the\ntraining of a Pytorch Lightning model, using the\n:class:`~nidl.callbacks.MetricsCallback` callback.\n\n## Setup\n\nThis notebook requires some packages besides nidl. Let's first start with\nimporting our standard libraries below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport re\n\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as func\nfrom tensorboard.backend.event_processing import event_accumulator\nfrom torch import concat, nn\nfrom torch.optim import SGD\nfrom torch.utils.data import DataLoader\nfrom torchmetrics import Accuracy, F1Score, Precision, Recall\nfrom torchvision import transforms\nfrom torchvision.datasets import MNIST\nfrom torchvision.utils import make_grid\n\nfrom nidl.callbacks import MetricsCallback\nfrom nidl.estimators import BaseEstimator, ClassifierMixin\nfrom nidl.estimators.ssl import SimCLR\nfrom nidl.metrics.ssl import (\n    alignment_score,\n    contrastive_accuracy_score,\n    uniformity_score,\n)\nfrom nidl.transforms import MultiViewsTransform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define some global parameters that will be used throughout the notebook:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_dir = \"/tmp/mnist\"\nbatch_size = 256\nnum_workers = 10\nlatent_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification metrics in supervised learning\n\nFor illustration purposes on how to use the metrics callback, we will focus\non the popular MNIST dataset. It contains 60k training images and\n10k test images of size 28x28 pixels. Each image contains a digit from 0 to\n9. We will train a simple classification model on these data and log standard\nclassification metrics (accuracy, F1-score, precision, recall) to understand\nhow the :class:`~nidl.callbacks.MetricsCallback` works.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We start by loading the MNIST dataset dataset with standard scaling\ntransforms.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scale_transforms = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n)\ntrain_xy_dataset = MNIST(data_dir, download=True, transform=scale_transforms)\ntest_xy_dataset = MNIST(\n    data_dir, download=True, train=False, transform=scale_transforms\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we create the data loaders for training and testing the models.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_xy_loader = DataLoader(\n    train_xy_dataset,\n    batch_size=batch_size,\n    shuffle=True,\n    drop_last=False,\n    pin_memory=True,\n    num_workers=num_workers,\n)\ntest_xy_loader = DataLoader(\n    test_xy_dataset,\n    batch_size=batch_size,\n    shuffle=False,\n    drop_last=False,\n    num_workers=num_workers,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before starting training classifiers, let's visualize some\nexamples of the dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def show_images(images, title=None, nrow=8):\n    grid = make_grid(images, nrow=nrow, normalize=True, pad_value=1)\n    plt.figure(figsize=(10, 5))\n    plt.imshow(grid.permute(1, 2, 0).cpu())\n    if title:\n        plt.title(title)\n    plt.axis(\"off\")\n    plt.show()\n\n\nimages, labels = next(iter(test_xy_loader))\nfig, axes = plt.subplots(1, 3, figsize=(6, 4))\nfor i in range(3):\n    axes[i].imshow(images[i][0].cpu(), cmap=\"gray\")\n    axes[i].set_title(f\"Label={labels[i].item()}\")\n    axes[i].axis(\"off\")\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Supervised training with metrics callback\n\nSince MNIST images are small, we can use a simple LeNet-like architecture\nas encoder, with few parameters. The output dimension of the\nencoder is set to 32, which is approximately 30 times smaller that the input,\nbut larger than the number of input classes (10).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class LeNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super().__init__()\n        self.latent_size = num_classes\n        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)\n        self.pool1 = nn.AvgPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n        self.pool2 = nn.AvgPool2d(2, 2)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, num_classes)\n\n    def forward(self, x):\n        x = func.relu(self.conv1(x))\n        x = self.pool1(x)\n        x = func.relu(self.conv2(x))\n        x = self.pool2(x)\n        x = x.view(x.size(0), -1)\n        x = func.relu(self.fc1(x))\n        x = func.relu(self.fc2(x))\n        return self.fc3(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now fit a supervised model with cross-entopy loss (PL-compatible).\nWe limit the training to 10 epochs for the sake of time and because it is\nenough for checking the evolution of the metrics across training.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class SupervisedCrossEntropy(ClassifierMixin, BaseEstimator):\n    \"\"\"Self-contained Pytorch-Lightning model.\n\n    Metrics are not computed here since it is not essential to model's\n    training.\n    \"\"\"\n\n    def __init__(\n        self,\n        backbone: nn.Module,\n        lr: float = 1e-2,\n        momentum: float = 0.9,\n        weight_decay: float = 5e-4,\n        **kwargs,\n    ):\n        super().__init__(ignore=[\"callbacks\", \"backbone\"], **kwargs)\n        self.backbone = backbone\n        self.lr = lr\n        self.momentum = momentum\n        self.weight_decay = weight_decay\n\n    def configure_optimizers(self):\n        optimizer = SGD(\n            self.parameters(),\n            lr=self.lr,\n            momentum=self.momentum,\n            weight_decay=self.weight_decay,\n        )\n        return [optimizer]\n\n    def forward(self, imgs):\n        return self.backbone(imgs)\n\n    def training_step(\n        self,\n        batch,\n        batch_idx: int,\n        dataloader_idx: int = 0,\n    ):\n        imgs, labels = batch\n        preds = self.backbone(imgs)\n        loss = nn.functional.cross_entropy(preds, labels)\n        self.log(\"loss/train\", loss, on_step=True)\n        return {\n            \"loss\": loss,\n            \"preds\": preds,\n            \"target\": labels,\n        }\n\n    def validation_step(\n        self,\n        batch,\n        batch_idx: int,\n        dataloader_idx: int = 0,\n    ):\n        imgs, labels = batch\n        preds = self.backbone(imgs)\n        loss = nn.functional.cross_entropy(preds, labels)\n        self.log(\"loss/val\", loss, on_epoch=True)\n        return {\n            \"val_loss\": loss,\n            \"preds\": preds,\n            \"target\": labels,\n        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create the metrics callback that will log the classification metrics\nduring training every training step and every validation epoch (default):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "callback = MetricsCallback(\n    metrics={\n        \"acc1\": Accuracy(task=\"multiclass\", num_classes=10),\n        \"f1\": F1Score(task=\"multiclass\", num_classes=10),\n        \"precision\": Precision(task=\"multiclass\", num_classes=10),\n        \"recall\": Recall(task=\"multiclass\", num_classes=10),\n    }\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we fit the model:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = SupervisedCrossEntropy(\n    backbone=LeNet(),\n    lr=1e-2,\n    momentum=0.9,\n    max_epochs=10,\n    check_val_every_n_epoch=2,\n    enable_checkpointing=False,\n    callbacks=callback,  # <-- key part for metrics computation\n)\nmodel.fit(train_xy_loader, test_xy_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualization of the classification metrics during training\n\nDuring training, we can visualize the classification metrics logged\nby the :class:`~nidl.callbacks.MetricsCallback` using TensorBoard.\nThe logged metrics are stored in the `lightning_logs` folder by default.\nThey contain the accuracy, F1-score, precision (macro) and recall (macro).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_last_log_version(logs_dir=\"lightning_logs\"):\n    versions = []\n    for d in os.listdir(logs_dir):\n        match = re.match(r\"version_(\\d+)\", d)\n        if match:\n            versions.append(int(match.group(1)))\n    return max(versions) if versions else None\n\n\nlog_dir = f\"lightning_logs/version_{get_last_log_version()}/\"\nea = event_accumulator.EventAccumulator(log_dir)\nea.Reload()\nmetrics = [\n    \"acc1/val\",\n    \"f1/val\",\n    \"precision/val\",\n    \"recall/val\",\n]\nscalars = {m: ea.Scalars(m) for m in metrics}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once all the metrics are loaded, we plot them as the number of training steps\nincreases:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_metrics = len(scalars)\nfig, axes = plt.subplots(1, num_metrics, figsize=(3 * num_metrics, 3))\n\nfor ax, (metric_name, events) in zip(axes, scalars.items()):\n    steps = [e.step for e in events]\n    values = [e.value for e in events]\n\n    ax.plot(steps, values, marker=\"o\", linestyle=\"-\")\n    ax.set_title(metric_name.split(\"/\")[0].capitalize())\n    ax.set_xlabel(f\"Steps (batch size={batch_size})\")\n    ax.set_ylabel(metric_name)\n    ax.grid(True, alpha=0.3)\n\nplt.suptitle(\"Supervised metrics during training\", fontsize=\"x-large\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Unsupervised contrastive learning with metrics callback\n\nWe now demonstrate how to plot self-supervised metrics (alignment and\nuniformity scores) during the training of a SimCLR model (implementation from\nNIDL). The logic is the same as before.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset and data augmentations for contrastive learning\n\nTo perform self-supervisde contrastive learning, we need to define a set of\ndata augmentations to create multiple views of the same image. Since we work\nwith grayscale images, we will use random resized crop and Gaussian blur. We\nreduce the size of the Gaussian kernel to 3x3 since MNIST images are only\n28x28 pixels.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "contrast_transforms = transforms.Compose(\n    [\n        transforms.RandomResizedCrop(size=28, scale=(0.8, 1.0)),\n        transforms.GaussianBlur(kernel_size=3),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,)),\n    ]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a MNIST dataset that returns multiple views of the same image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ssl_dataset = MNIST(\n    data_dir,\n    download=True,\n    transform=MultiViewsTransform(contrast_transforms, n_views=2),\n)\ntest_ssl_dataset = MNIST(\n    data_dir,\n    download=True,\n    train=False,\n    transform=MultiViewsTransform(contrast_transforms, n_views=2),\n)\n\ntrain_ssl_loader = DataLoader(\n    ssl_dataset,\n    batch_size=batch_size,\n    shuffle=True,\n    pin_memory=True,\n    num_workers=num_workers,\n)\ntest_ssl_loader = DataLoader(\n    test_ssl_dataset,\n    batch_size=batch_size,\n    shuffle=False,\n    pin_memory=True,\n    num_workers=num_workers,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we create the callback that will compute and log the self-supervised\nmetrics during training and validation.\n\n**Important remark**: uniformity score cannot be aggregated with a simple\naverage over batch as the alignment score. Here, we perform an exact\ncomputation of the uniformity score on the *validation set* only. The score\non the training set is just an approximation but we don't require exact\ncomputation as the model's weights are changing over iterations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "callback = MetricsCallback(\n    metrics={\n        \"alignment\": alignment_score,\n        \"uniformity\": uniformity_score,\n        \"contrastive_acc\": contrastive_accuracy_score,\n    },\n    needs={\n        \"alignment\": [\"z1\", \"z2\"],\n        \"uniformity\": {\"z\": lambda out: concat((out[\"z1\"], out[\"z2\"]))},\n        \"contrastive_acc\": [\"z1\", \"z2\"],\n    },\n    every_n_train_steps=None,\n    every_n_val_epochs=2,\n)\n\nmodel = SimCLR(\n    encoder=LeNet(num_classes=latent_size),\n    proj_input_dim=latent_size,\n    proj_hidden_dim=latent_size,\n    proj_output_dim=32,\n    learning_rate=3e-4,\n    temperature=0.1,\n    weight_decay=5e-5,\n    max_epochs=10,\n    enable_checkpointing=False,\n    callbacks=callback,  # <-- key part for metrics computation\n)\n\nmodel.fit(train_ssl_loader, test_ssl_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualization of the self-supervised metrics during training\n\nAs before, we visualize the logged metrics using tensorboard.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_last_log_version(logs_dir=\"lightning_logs\"):\n    versions = []\n    for d in os.listdir(logs_dir):\n        match = re.match(r\"version_(\\d+)\", d)\n        if match:\n            versions.append(int(match.group(1)))\n    return max(versions) if versions else None\n\n\nlog_dir = f\"lightning_logs/version_{get_last_log_version()}/\"\nea = event_accumulator.EventAccumulator(log_dir)\nea.Reload()\nmetrics = [\"alignment/val\", \"uniformity/val\", \"contrastive_acc/val\"]\nscalars = {m: ea.Scalars(m) for m in metrics}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once all the metrics are loaded, we plot them as the number of training steps\nincreases:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_metrics = len(scalars)\nfig, axes = plt.subplots(1, num_metrics, figsize=(3 * num_metrics, 3))\n\nfor ax, (metric_name, events) in zip(axes, scalars.items()):\n    steps = [e.step for e in events]\n    values = [e.value for e in events]\n\n    ax.plot(steps, values, marker=\"o\", linestyle=\"-\")\n    ax.set_title(metric_name.split(\"/\")[0].capitalize())\n    ax.set_xlabel(f\"Steps (batch size={batch_size})\")\n    ax.set_ylabel(metric_name)\n    ax.grid(True, alpha=0.3)\n\nplt.suptitle(\"Self-supervised metrics during training\", fontsize=\"x-large\")\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}