<!doctype html>
<html lang="en">

    <head>

		<!-- Required meta tags -->
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

        <title>nidl</title>
        
        <!-- CSS -->
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500&display=swap">
		<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
        <link rel="stylesheet" href="../../../_static/css/jquery.mCustomScrollbar.min.css">
        <link rel="stylesheet" href="../../../_static/css/animate.css">
        <link rel="stylesheet" href="../../../_static/css/style.css">
        <link rel="stylesheet" href="../../../_static/css/jquery.mosaic.css">
        <link rel="stylesheet" href="../../../_static/sg_gallery.css">
        <link rel="stylesheet" href="../../../_static/css/media-queries.css">
        <link rel="stylesheet" href="../../../_static/css/pygment.css">

        <!-- Favicon and touch icons -->
        <link rel="shortcut icon" href="../../../_static/ico/favicon.png">
        <link rel="apple-touch-icon-precomposed" sizes="144x144" href="../../../_static/ico/apple-touch-icon-144-precomposed.png">
        <link rel="apple-touch-icon-precomposed" sizes="114x114" href="../../../_static/ico/apple-touch-icon-114-precomposed.png">
        <link rel="apple-touch-icon-precomposed" sizes="72x72" href="../../../_static/ico/apple-touch-icon-72-precomposed.png">
        <link rel="apple-touch-icon-precomposed" href="../../../_static/ico/apple-touch-icon-57-precomposed.png">

    </head>

    <body>

		<!-- Wrapper -->
    	<div class="wrapper">

			<!-- Sidebar -->
			<nav class="sidebar">
				
				<!-- close sidebar menu -->
				<div class="dismiss">
					<i class="fas fa-arrow-left"></i>
				</div>
				
				<!-- <div class="logo"">
					<h3><a href="../../../index.html">Sidebar Menu</a></h3>
				</div> -->

                <!-- info setup -->
                    <p class="doc-version">
                        This documentation is for nidl <strong>version 0.0.0</strong>
                    </p>
                <p class="citing">
                    If you use the software, please do not hesitate to 
                    <a &mdash; <a href="https://github.com/neurospin-deepinsight/nidl">
                    Report a Bug</a>.
                </p>
				
                <!-- links -->
                
                
				<ul class="list-unstyled menu-elements">
					<li class="active">
						<a href="../../../index.html"><i class="fas fa-home"></i> Home</a>
					</li>
					<li>
						<a href="../../../generated/installation.html"><i class="fas fa-cog"></i> Installation</a>
					</li>
					<li>
						<a href="../../../auto_gallery/index.html"><i class="fas fa-eye"></i> Gallery</a>
					</li>
					<li>
						<a href="../../../generated/documentation.html"><i class="fas fa-pencil-alt"></i> API documentation</a>
					</li>
					<li>
						<a href="../../../generated/search.html"><i class="fas fa-search"></i> Search</a>
					</li>
					<!-- <li>
						<a href="https://github.com/AGrigis/pysphinxdoc"><i class="fas fa-external-link-alt"></i> PYSPHINXDOC</a>
					</li> -->
					<!-- <li>
						<a href="#otherSections" data-toggle="collapse" aria-expanded="false" class="dropdown-toggle" role="button" aria-controls="otherSections">
							<i class="fas fa-sync"></i>Sections Shortcuts
						</a>
						<ul class="collapse list-unstyled" id="otherSections">
                            <li>LINKS</li><li><a href='https://github.com/neurospin-deepinsight/surfify'>surfify</a></li>
                            
                            <li>API</li>
                            <li><a href="../../../generated/nidl.html">nidl</a></li><li><a href="../../../generated/nidl.callbacks.html">nidl.callbacks</a></li><li><a href="../../../generated/nidl.datasets.html">nidl.datasets</a></li><li><a href="../../../generated/nidl.estimators.html">nidl.estimators</a></li><li><a href="../../../generated/nidl.estimators.linear.html">nidl.estimators.linear</a></li><li><a href="../../../generated/nidl.estimators.ssl.html">nidl.estimators.ssl</a></li><li><a href="../../../generated/nidl.losses.html">nidl.losses</a></li><li><a href="../../../generated/nidl.transforms.html">nidl.transforms</a></li><li><a href="../../../generated/nidl.utils.html">nidl.utils</a></li><li><a href="../../../generated/nidl.volume.html">nidl.volume</a></li><li><a href="../../../generated/nidl.volume.backbones.html">nidl.volume.backbones</a></li><li><a href="../../../generated/surfify.html">surfify</a></li><li><a href="../../../generated/surfify.augmentation.html">surfify.augmentation</a></li><li><a href="../../../generated/surfify.datasets.html">surfify.datasets</a></li><li><a href="../../../generated/surfify.losses.html">surfify.losses</a></li><li><a href="../../../generated/surfify.models.html">surfify.models</a></li><li><a href="../../../generated/surfify.nn.html">surfify.nn</a></li><li><a href="../../../generated/surfify.plotting.html">surfify.plotting</a></li><li><a href="../../../generated/surfify.utils.html">surfify.utils</a></li>
						</ul>
					</li> -->
				</ul>
				
                <!-- go top page -->
				<!-- <div class="to-top">
					<a class="btn btn-primary btn-customized-3" href="#" role="button">
	                    <i class="fas fa-arrow-up"></i> Top
	                </a>
				</div> -->
			
                <!-- change color -->
				<!-- <div class="dark-light-buttons">
					<a class="btn btn-primary btn-customized-4 btn-customized-dark" href="#" role="button">Dark</a>
					<a class="btn btn-primary btn-customized-4 btn-customized-light" href="#" role="button">Light</a>
				</div> -->
			
			</nav>
			<!-- End sidebar -->
			
			<!-- Dark overlay -->
    		<div class="overlay"></div>

			<!-- Content -->
			<div class="content">
			
				<!-- open sidebar menu -->
				<a class="btn btn-primary btn-customized open-menu" href="#" role="button">
                    <i class="fas fa-align-left"></i> <span>Menu</span>
                </a>

		        <!-- Top content -->
		        <div class="top-content section-container" id="top-content">
			        <div class="container">
			            <div class="row">
                            <div class="col-md-3 section-5-box banner-logo">
                                <img alt="Logo" src="../../../_static/nidl.png">
                            </div>
			                <div class="col-md-7 section-5-box">
			                	<h1 class="wow fadeIn">    <p>Deep learning for NeuroImaging in Python.</p></h1>
			                </div>
			            </div>
			        </div>
		        </div>
                    
                    <div class="document">
                        <h1>Source code for nidl.estimators.base</h1><div class='divider-1 wow fadeInUp' style='margin-top: -20px;'><span></span></div><div class="highlight"><pre>
<span></span><span class="c1">##########################################################################</span>
<span class="c1"># NSAp - Copyright (C) CEA, 2025</span>
<span class="c1"># Distributed under the terms of the CeCILL-B license, as published by</span>
<span class="c1"># the CEA-CNRS-INRIA. Refer to the LICENSE file or to</span>
<span class="c1"># http://www.cecill.info/licences/Licence_CeCILL-B_V1-en.html</span>
<span class="c1"># for details.</span>
<span class="c1">##########################################################################</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">abc</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Mapping</span><span class="p">,</span> <span class="n">Sequence</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">pytorch_lightning</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pl</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">data</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pytorch_lightning.accelerators</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pytorch_lightning.callbacks</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callback</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pytorch_lightning.strategies</span><span class="w"> </span><span class="kn">import</span> <span class="n">Strategy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pytorch_lightning.trainer.connectors.accelerator_connector</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_PRECISION_INPUT</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pytorch_lightning.utilities.types</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_METRIC</span><span class="p">,</span>
    <span class="n">STEP_OUTPUT</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchmetrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">MetricCollection</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">..utils.validation</span><span class="w"> </span><span class="kn">import</span> <span class="n">_estimator_is</span><span class="p">,</span> <span class="n">available_if</span><span class="p">,</span> <span class="n">check_is_fitted</span>

    
<div class="viewcode-block" id="BaseEstimator">
<a class="viewcode-back" href="../../../generated/nidl.estimators.base.BaseEstimator.html#nidl.estimators.BaseEstimator">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">BaseEstimator</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Base class for all estimators in the NIDL framework designed for</span>
<span class="sd">    scalability.</span>

<span class="sd">    Inherits from PyTorch Lightning&#39;s LightningModule.</span>
<span class="sd">    This class provides a common interface for training, validation, and</span>
<span class="sd">    prediction/transformation in a distributed setting (multi-node multi-GPU)</span>
<span class="sd">    inheriting from the Lightning&#39;s Trainer capabilities.</span>

<span class="sd">    Basicaly, this class defines:</span>

<span class="sd">    - a `fit` method.</span>
<span class="sd">    - a `transform` or `predict` method if the child class inherit from a</span>
<span class="sd">      valid  Mixin class.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    callbacks: list of Callback or Callback, default=None</span>
<span class="sd">        add a callback or list of callbacks.</span>
<span class="sd">    check_val_every_n_epoch: int, default=1</span>
<span class="sd">        perform a validation loop after every `N` training epochs. If ``None``,</span>
<span class="sd">        validation will be done solely based on the number of training</span>
<span class="sd">        batches, requiring ``val_check_interval`` to be an integer value.</span>
<span class="sd">    val_check_interval: int or float, default=None</span>
<span class="sd">        how often to check the validation set. Pass a ``float`` in the range</span>
<span class="sd">        [0.0, 1.0] to check after a fraction of the training epoch. Pass an</span>
<span class="sd">        ``int`` to check after a fixed number of training batches. An ``int``</span>
<span class="sd">        value can only be higher than the number of training batches when</span>
<span class="sd">        ``check_val_every_n_epoch=None``, which validates after every ``N``</span>
<span class="sd">        training batches across epochs or during iteration-based training.</span>
<span class="sd">        Default: ``1.0``.</span>
<span class="sd">    max_epochs: int, default=None</span>
<span class="sd">        stop training once this number of epochs is reached. If both</span>
<span class="sd">        max_epochs and max_steps are not specified, defaults to</span>
<span class="sd">        ``max_epochs = 1000``. To enable infinite training, set</span>
<span class="sd">        ``max_epochs = -1``.</span>
<span class="sd">    min_epochs: int, default=None</span>
<span class="sd">        force training for at least these many epochs.</span>
<span class="sd">        Disabled by default.</span>
<span class="sd">    max_steps: int, default -1</span>
<span class="sd">        stop training after this number of steps. If ``max_steps = -1``</span>
<span class="sd">        and ``max_epochs = None``, will default to ``max_epochs = 1000``.</span>
<span class="sd">        To enable infinite training, set ``max_epochs`` to ``-1``.</span>
<span class="sd">    min_steps: int, default=None</span>
<span class="sd">        force training for at least these number of steps.</span>
<span class="sd">        Disabled by default.</span>
<span class="sd">    enable_checkpointing: bool, default=None</span>
<span class="sd">        if ``True``, enable checkpointing. It will configure a default</span>
<span class="sd">        ModelCheckpoint callback if there is no user-defined ModelCheckpoint in</span>
<span class="sd">        trainer callbacks.</span>
<span class="sd">        Default: ``True``.</span>
<span class="sd">    enable_progress_bar: bool, default=None</span>
<span class="sd">        whether to enable to progress bar by default.</span>
<span class="sd">        Default: ``True``.</span>
<span class="sd">    enable_model_summary: bool, default=None</span>
<span class="sd">        whether to enable model summarization by default.</span>
<span class="sd">        Default: ``True``.</span>
<span class="sd">    accelerator: str or Accelerator, default=&quot;auto&quot;</span>
<span class="sd">        supports passing different accelerator types (&quot;cpu&quot;, &quot;gpu&quot;, &quot;tpu&quot;,</span>
<span class="sd">        &quot;hpu&quot;, &quot;mps&quot;, &quot;auto&quot;) as well as custom accelerator instances.</span>
<span class="sd">    strategy: str or Strategy, default=&quot;auto&quot;</span>
<span class="sd">        supports different training strategies with aliases as well custom</span>
<span class="sd">        strategies.</span>
<span class="sd">    devices: listof int, str, int, default=&quot;auto&quot;</span>
<span class="sd">        the devices to use. Can be set to a positive number (int or str), a</span>
<span class="sd">        sequence of device indices (list or str), the value ``-1`` to indicate</span>
<span class="sd">        all available devices should be used, or ``&quot;auto&quot;`` for automatic</span>
<span class="sd">        selection based on the chosen accelerator.</span>
<span class="sd">    num_nodes: int, default=1</span>
<span class="sd">        number of GPU nodes for distributed training.</span>
<span class="sd">    precision: int or str, default=&quot;32-true&quot;</span>
<span class="sd">        double precision (64, &#39;64&#39; or &#39;64-true&#39;), full</span>
<span class="sd">        precision (32, &#39;32&#39; or &#39;32-true&#39;), 16bit mixed precision (16, &#39;16&#39;,</span>
<span class="sd">        &#39;16-mixed&#39;) or bfloat16 mixed precision (&#39;bf16&#39;, &#39;bf16-mixed&#39;).</span>
<span class="sd">        Can be used on CPU, GPU, TPUs, or HPUs.</span>
<span class="sd">    ignore: list of str, default=None</span>
<span class="sd">        ignore attribute of instance `nn.Module`.</span>
<span class="sd">    random_state: int, default=None</span>
<span class="sd">        when shuffling is used, `random_state` affects the ordering of the</span>
<span class="sd">        indices, which controls the randomness of each batch. Pass an</span>
<span class="sd">        int for reproducible output across multiple function calls.</span>
<span class="sd">    kwargs: dict</span>
<span class="sd">        lightning&#39;s trainer extra parameters.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    fitted</span>
<span class="sd">        a boolean that is True if the estimator has been fitted, and is False</span>
<span class="sd">        otherwise.</span>
<span class="sd">    hparams:</span>
<span class="sd">        contains the estimator hyperparameters.</span>
<span class="sd">    trainer</span>
<span class="sd">        the current lightning trainer.</span>
<span class="sd">    trainer_params</span>
<span class="sd">        a dictionaray with the trainer parameters.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    :meth:`BaseEstimator.fit`</span>
<span class="sd">        the `fit` method.</span>
<span class="sd">    :meth:`BaseEstimator.transform`</span>
<span class="sd">        the `transform` method for transformer.</span>
<span class="sd">    :meth:`BaseEstimator.predict`</span>
<span class="sd">        the `predict` method for regression, classification and clustering.</span>
<span class="sd">    :meth:`BaseEstimator.training_step`</span>
<span class="sd">        compute and return the training loss and some additional</span>
<span class="sd">        metrics.</span>
<span class="sd">        TO BE IMPLEMENTED.</span>
<span class="sd">    :meth:`BaseEstimator.validation_step`</span>
<span class="sd">        compute anything of interest like accuracy on a single batch of data</span>
<span class="sd">        from the validation set.</span>
<span class="sd">        TO BE IMPLEMENTED.</span>
<span class="sd">    :meth:`BaseEstimator.transform_step`</span>
<span class="sd">        transform new data.</span>
<span class="sd">        TO BE IMPLEMENTED.</span>
<span class="sd">    :meth:`BaseEstimator.predict_step`</span>
<span class="sd">        make some predictions on new data.</span>
<span class="sd">        TO BE IMPLEMENTED.</span>
<span class="sd">    :meth:`BaseEstimator.log`</span>
<span class="sd">        log a key, value pair.</span>
<span class="sd">    :meth:`BaseEstimator.log_dict`</span>
<span class="sd">        log a dictionary of values at once.</span>
<span class="sd">        </span>
<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Callbacks can help you to tune, monitor or debug an estimator. For</span>
<span class="sd">    instance you can check the type of the input batches using</span>
<span class="sd">    `BatchTypingCallback` callback.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">callbacks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Callback</span><span class="p">],</span> <span class="n">Callback</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">check_val_every_n_epoch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">val_check_interval</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">max_epochs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">min_epochs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">max_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">min_steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">enable_checkpointing</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">enable_progress_bar</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">enable_model_summary</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">accelerator</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Accelerator</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
            <span class="n">strategy</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Strategy</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
            <span class="n">devices</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
            <span class="n">num_nodes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">precision</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_PRECISION_INPUT</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">ignore</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">random_state</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="n">ignore</span><span class="o">=</span><span class="n">ignore</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fitted_</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer_params_</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;callbacks&quot;</span><span class="p">:</span> <span class="n">callbacks</span><span class="p">,</span>
            <span class="s2">&quot;check_val_every_n_epoch&quot;</span><span class="p">:</span> <span class="n">check_val_every_n_epoch</span><span class="p">,</span>
            <span class="s2">&quot;val_check_interval&quot;</span><span class="p">:</span> <span class="n">val_check_interval</span><span class="p">,</span>
            <span class="s2">&quot;max_epochs&quot;</span><span class="p">:</span> <span class="n">max_epochs</span><span class="p">,</span>
            <span class="s2">&quot;min_epochs&quot;</span><span class="p">:</span> <span class="n">min_epochs</span><span class="p">,</span>
            <span class="s2">&quot;max_steps&quot;</span><span class="p">:</span> <span class="n">max_steps</span><span class="p">,</span>
            <span class="s2">&quot;min_steps&quot;</span><span class="p">:</span> <span class="n">min_steps</span><span class="p">,</span>
            <span class="s2">&quot;enable_checkpointing&quot;</span><span class="p">:</span> <span class="n">enable_checkpointing</span><span class="p">,</span>
            <span class="s2">&quot;enable_progress_bar&quot;</span><span class="p">:</span> <span class="n">enable_progress_bar</span><span class="p">,</span>
            <span class="s2">&quot;enable_model_summary&quot;</span><span class="p">:</span> <span class="n">enable_model_summary</span><span class="p">,</span>
            <span class="s2">&quot;accelerator&quot;</span><span class="p">:</span> <span class="n">accelerator</span><span class="p">,</span>
            <span class="s2">&quot;strategy&quot;</span><span class="p">:</span> <span class="n">strategy</span><span class="p">,</span>
            <span class="s2">&quot;devices&quot;</span><span class="p">:</span> <span class="n">devices</span><span class="p">,</span>
            <span class="s2">&quot;num_nodes&quot;</span><span class="p">:</span> <span class="n">num_nodes</span><span class="p">,</span>
            <span class="s2">&quot;precision&quot;</span><span class="p">:</span> <span class="n">precision</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer_params_</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
	    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fitted_</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">trainer_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
	    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer_params_</span>

<div class="viewcode-block" id="BaseEstimator.fit">
<a class="viewcode-back" href="../../../generated/nidl.estimators.base.BaseEstimator.html#nidl.estimators.BaseEstimator.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">train_dataloader</span><span class="p">:</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span>
            <span class="n">val_dataloader</span><span class="p">:</span>  <span class="n">Optional</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; The `fit` method.</span>

<span class="sd">        In the child class you will need to define:</span>

<span class="sd">        - a `training_step` method for defining the training instructions at</span>
<span class="sd">          each step.</span>
<span class="sd">        - a `validation_step` method for defining the validation instructions</span>
<span class="sd">          at each step.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        train_dataloader: torch DataLoader</span>
<span class="sd">            training samples.</span>
<span class="sd">        val_dataloader: torch DataLoader, default None</span>
<span class="sd">            validation samples.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self: object</span>
<span class="sd">            fitted estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer_params_</span><span class="p">)</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">_default_hp_metric</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">pl</span><span class="o">.</span><span class="n">seed_everything</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hparams</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">val_dataloader</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fitted_</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="BaseEstimator.transform">
<a class="viewcode-back" href="../../../generated/nidl.estimators.base.BaseEstimator.html#nidl.estimators.BaseEstimator.transform">[docs]</a>
    <span class="nd">@available_if</span><span class="p">(</span><span class="n">_estimator_is</span><span class="p">(</span><span class="s2">&quot;transformer&quot;</span><span class="p">))</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">test_dataloader</span><span class="p">:</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; The `transform` method for transformer.</span>

<span class="sd">        In the child class you will need to define:</span>

<span class="sd">        - a `transform_step` method for defining the transform instructions at</span>
<span class="sd">          each step.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        test_dataloader: torch DataLoader</span>
<span class="sd">            testing samples.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        out: torch Tensor</span>
<span class="sd">            returns transformed samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer_params_</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">test_dataloader</span><span class="p">,</span> <span class="n">return_predictions</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span></div>

    
<div class="viewcode-block" id="BaseEstimator.predict">
<a class="viewcode-back" href="../../../generated/nidl.estimators.base.BaseEstimator.html#nidl.estimators.BaseEstimator.predict">[docs]</a>
    <span class="nd">@available_if</span><span class="p">(</span><span class="n">_estimator_is</span><span class="p">((</span><span class="s2">&quot;regressor&quot;</span><span class="p">,</span> <span class="s2">&quot;classifier&quot;</span><span class="p">,</span> <span class="s2">&quot;clusterer&quot;</span><span class="p">)))</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">test_dataloader</span><span class="p">:</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; The `predict` method for regression, classification and clustering.</span>

<span class="sd">        In the child class you will need to define:</span>

<span class="sd">        - a `predict_step` method for defining the predict instructions at</span>
<span class="sd">          each step.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        test_dataloader: torch DataLoader</span>
<span class="sd">            testing samples.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        out: torch Tensor</span>
<span class="sd">            returns predicted samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer_params_</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">test_dataloader</span><span class="p">,</span> <span class="n">return_predictions</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span></div>


<div class="viewcode-block" id="BaseEstimator.training_step">
<a class="viewcode-back" href="../../../generated/nidl.estimators.base.BaseEstimator.html#nidl.estimators.BaseEstimator.training_step">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">training_step</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
            <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">dataloader_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">STEP_OUTPUT</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Here you compute and return the training loss and some additional</span>
<span class="sd">        metrics for e.g. the progress bar or logger.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        batch: iterable, normally a :class:`~torch.utils.data.DataLoader`</span>
<span class="sd">            the current data.</span>
<span class="sd">        batch_idx: int</span>
<span class="sd">            the index of this batch.</span>
<span class="sd">        dataloader_idx: int, default=0</span>
<span class="sd">            the index of the dataloader that produced this batch (only if</span>
<span class="sd">            multiple dataloaders are used).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        loss: STEP_OUTPUT</span>
<span class="sd">            the computed loss:</span>

<span class="sd">            - :class:`~torch.Tensor` - the loss tensor.</span>
<span class="sd">            - ``dict`` - a dictionary which can include any keys, but must</span>
<span class="sd">              include the key ``&#39;loss&#39;`` in the case of automatic optimization.</span>
<span class="sd">            - ``None`` - in automatic optimization, this will skip to the</span>
<span class="sd">              next batch (but is not supported for multi-GPU, TPU, or</span>
<span class="sd">              DeepSpeed). For manual optimization, this has no special</span>
<span class="sd">              meaning, as returning the loss is not required.</span>

<span class="sd">        To use multiple optimizers, you can switch to &#39;manual optimization&#39;</span>
<span class="sd">        and control their stepping:</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; def __init__(self):</span>
<span class="sd">        &gt;&gt;&gt;     super().__init__()</span>
<span class="sd">        &gt;&gt;&gt;     self.automatic_optimization = False</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Multiple optimizers (e.g.: GANs)</span>
<span class="sd">        &gt;&gt;&gt; def training_step(self, batch, batch_idx):</span>
<span class="sd">        &gt;&gt;&gt;     opt1, opt2 = self.optimizers()</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt;     # do training_step with encoder</span>
<span class="sd">        &gt;&gt;&gt;     ...</span>
<span class="sd">        &gt;&gt;&gt;     opt1.step()</span>
<span class="sd">        &gt;&gt;&gt;     # do training_step with decoder</span>
<span class="sd">        &gt;&gt;&gt;     ...</span>
<span class="sd">        &gt;&gt;&gt;     opt2.step()</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        When ``accumulate_grad_batches`` &gt; 1, the loss returned here will be</span>
<span class="sd">        automatically normalized by ``accumulate_grad_batches`` internally.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">training_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">)</span></div>


<div class="viewcode-block" id="BaseEstimator.validation_step">
<a class="viewcode-back" href="../../../generated/nidl.estimators.base.BaseEstimator.html#nidl.estimators.BaseEstimator.validation_step">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">validation_step</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
            <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">dataloader_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">STEP_OUTPUT</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Operates on a single batch of data from the validation set. In</span>
<span class="sd">        this step you&#39;d might generate examples or calculate anything of</span>
<span class="sd">        interest like accuracy.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        batch: iterable, normally a :class:`~torch.utils.data.DataLoader`</span>
<span class="sd">            the current data.</span>
<span class="sd">        batch_idx: int</span>
<span class="sd">            the index of this batch.</span>
<span class="sd">        dataloader_idx: int, default=0</span>
<span class="sd">            the index of the dataloader that produced this batch (only if</span>
<span class="sd">            multiple dataloaders are used).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        loss: STEP_OUTPUT</span>
<span class="sd">            the computed loss:</span>

<span class="sd">            - :class:`~torch.Tensor` - the loss tensor.</span>
<span class="sd">            - ``dict`` - a dictionary. can include any keys, but must include</span>
<span class="sd">              the key ``&#39;loss&#39;``.</span>
<span class="sd">            - ``None`` - skip to the next batch.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        If you don&#39;t need to validate you don&#39;t need to implement this method.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        When the :meth:`validation_step` is called, the model has been put in</span>
<span class="sd">        eval mode and PyTorch gradients have been disabled. At the end of</span>
<span class="sd">        validation,  the model goes back to training mode and gradients are</span>
<span class="sd">        enabled.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">validation_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">)</span></div>


<div class="viewcode-block" id="BaseEstimator.transform_step">
<a class="viewcode-back" href="../../../generated/nidl.estimators.base.BaseEstimator.html#nidl.estimators.BaseEstimator.transform_step">[docs]</a>
    <span class="nd">@available_if</span><span class="p">(</span><span class="n">_estimator_is</span><span class="p">(</span><span class="s2">&quot;transformer&quot;</span><span class="p">))</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_step</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
            <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">dataloader_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Define a transform step.</span>

<span class="sd">        Share the same API as :meth:`BaseEstimator.predict_step`.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="BaseEstimator.predict_step">
<a class="viewcode-back" href="../../../generated/nidl.estimators.base.BaseEstimator.html#nidl.estimators.BaseEstimator.predict_step">[docs]</a>
    <span class="nd">@available_if</span><span class="p">(</span><span class="n">_estimator_is</span><span class="p">((</span><span class="s2">&quot;transformer&quot;</span><span class="p">,</span> <span class="s2">&quot;regressor&quot;</span><span class="p">,</span> <span class="s2">&quot;classifier&quot;</span><span class="p">,</span>
                                 <span class="s2">&quot;clusterer&quot;</span><span class="p">)))</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">predict_step</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
            <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">dataloader_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Step function called during</span>
<span class="sd">        :meth:`~lightning.pytorch.trainer.trainer.Trainer.predict`. By default,</span>
<span class="sd">        it calls :meth:`~lightning.pytorch.core.LightningModule.forward`.</span>
<span class="sd">        Override to add any processing logic.</span>

<span class="sd">        The :meth:`~lightning.pytorch.core.LightningModule.predict_step` is</span>
<span class="sd">        used to scale inference on multi-devices.</span>

<span class="sd">        To prevent an OOM error, it is possible to use</span>
<span class="sd">        :class:`~lightning.pytorch.callbacks.BasePredictionWriter`</span>
<span class="sd">        callback to write the predictions to disk or database after each</span>
<span class="sd">        batch or on epoch end.</span>

<span class="sd">        The :class:`~lightning.pytorch.callbacks.BasePredictionWriter` should</span>
<span class="sd">        be used while using a spawn based accelerator. This happens for</span>
<span class="sd">        training strategy ``strategy=&quot;ddp_spawn&quot;`` or training on 8 TPU cores</span>
<span class="sd">        with ``accelerator=&quot;tpu&quot;, devices=8`` as predictions won&#39;t be returned.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        batch: iterable, normally a :class:`~torch.utils.data.DataLoader`</span>
<span class="sd">            the current data.</span>
<span class="sd">        batch_idx: int</span>
<span class="sd">            the index of this batch.</span>
<span class="sd">        dataloader_idx: int, default=0</span>
<span class="sd">            the index of the dataloader that produced this batch (only if</span>
<span class="sd">            multiple dataloaders are used).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        out: Any</span>
<span class="sd">            the predicted output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">_estimator_is</span><span class="p">(</span><span class="s2">&quot;transformer&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">predict_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">)</span></div>


<div class="viewcode-block" id="BaseEstimator.log">
<a class="viewcode-back" href="../../../generated/nidl.estimators.base.BaseEstimator.html#nidl.estimators.BaseEstimator.log">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">log</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
            <span class="n">value</span><span class="p">:</span> <span class="n">_METRIC</span><span class="p">,</span>
            <span class="n">prog_bar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">logger</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">on_step</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">on_epoch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">reduce_fx</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
            <span class="n">enable_graph</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">sync_dist</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">sync_dist_group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">add_dataloader_idx</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">metric_attribute</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">rank_zero_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Log a key, value pair.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            key to log. Must be identical across all processes if using DDP or</span>
<span class="sd">            any other distributed strategy.</span>
<span class="sd">        value: object</span>
<span class="sd">            value to log. Can be a ``float``, ``Tensor``, or a ``Metric``.</span>
<span class="sd">        prog_bar: bool, default=False</span>
<span class="sd">            if ``True`` logs to the progress bar.</span>
<span class="sd">        logger: bool, default=None</span>
<span class="sd">            if ``True`` logs to the logger.</span>
<span class="sd">        on_step: bool, default=None</span>
<span class="sd">            if ``True`` logs at this step. The default value is determined by</span>
<span class="sd">            the hook.</span>
<span class="sd">        on_epoch: bool, default=None</span>
<span class="sd">            if ``True`` logs epoch accumulated metrics. The default value is</span>
<span class="sd">            determined by the hook.</span>
<span class="sd">        reduce_fx: str of callable, default=&#39;mean&#39;</span>
<span class="sd">            reduction function over step values for end of epoch.</span>
<span class="sd">            :meth:`torch.mean` by default.</span>
<span class="sd">        enable_graph: bool, default=False</span>
<span class="sd">            if ``True``, will not auto detach the graph.</span>
<span class="sd">        sync_dist: bool, default=False</span>
<span class="sd">            if ``True``, reduces the metric across devices. Use with care as</span>
<span class="sd">            this may lead to a significant communication overhead.</span>
<span class="sd">        sync_dist_group: object, default=None</span>
<span class="sd">            the DDP group to sync across.</span>
<span class="sd">        add_dataloader_idx: bool, default=True</span>
<span class="sd">            if ``True``, appends the index of the current dataloader to</span>
<span class="sd">            the name (when using multiple dataloaders). If ``False``, user</span>
<span class="sd">            needs to give unique names for each dataloader to not mix the</span>
<span class="sd">            values.</span>
<span class="sd">        batch_size: int, default=None</span>
<span class="sd">            current batch_size. This will be directly inferred from the</span>
<span class="sd">            loaded batch, but for some data structures you might need to</span>
<span class="sd">            explicitly provide it.</span>
<span class="sd">        metric_attribute: str, default=None</span>
<span class="sd">            to restore the metric state, Lightning requires the reference of</span>
<span class="sd">            the :class:`torchmetrics.Metric` in your model. This is found</span>
<span class="sd">            automatically if it is a model attribute.</span>
<span class="sd">        rank_zero_only: bool, default=False</span>
<span class="sd">            tells Lightning if you are calling ``self.log`` from every</span>
<span class="sd">            process (default) or only from rank 0. If ``True``, you won&#39;t be</span>
<span class="sd">            able to use this metric as a monitor in callbacks (e.g., early</span>
<span class="sd">            stopping).</span>
<span class="sd">            Warning: Improper use can lead to deadlocks!</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; self.log(&#39;train_loss&#39;, loss)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span>
            <span class="n">prog_bar</span><span class="o">=</span><span class="n">prog_bar</span><span class="p">,</span>
            <span class="n">logger</span><span class="o">=</span><span class="n">logger</span><span class="p">,</span>
            <span class="n">on_step</span><span class="o">=</span><span class="n">on_step</span><span class="p">,</span>
            <span class="n">on_epoch</span><span class="o">=</span><span class="n">on_epoch</span><span class="p">,</span>
            <span class="n">reduce_fx</span><span class="o">=</span><span class="n">reduce_fx</span><span class="p">,</span>
            <span class="n">enable_graph</span><span class="o">=</span><span class="n">enable_graph</span><span class="p">,</span>
            <span class="n">sync_dist</span><span class="o">=</span><span class="n">sync_dist</span><span class="p">,</span>
            <span class="n">sync_dist_group</span><span class="o">=</span><span class="n">sync_dist_group</span><span class="p">,</span>
            <span class="n">add_dataloader_idx</span><span class="o">=</span><span class="n">add_dataloader_idx</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">metric_attribute</span><span class="o">=</span><span class="n">metric_attribute</span><span class="p">,</span>
            <span class="n">rank_zero_only</span><span class="o">=</span><span class="n">rank_zero_only</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="BaseEstimator.log_dict">
<a class="viewcode-back" href="../../../generated/nidl.estimators.base.BaseEstimator.html#nidl.estimators.BaseEstimator.log_dict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">log_dict</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">dictionary</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">_METRIC</span><span class="p">],</span> <span class="n">MetricCollection</span><span class="p">],</span>
            <span class="n">prog_bar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">logger</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">on_step</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">on_epoch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">reduce_fx</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
            <span class="n">enable_graph</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">sync_dist</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">sync_dist_group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">add_dataloader_idx</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">rank_zero_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Log a dictionary of values at once.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dictionary: dict</span>
<span class="sd">            key value pairs. Keys must be identical across all processes if</span>
<span class="sd">            using DDP or any other distributed strategy.</span>
<span class="sd">            The values can be a ``float``, ``Tensor``, ``Metric``, or</span>
<span class="sd">            ``MetricCollection``.</span>
<span class="sd">        prog_bar: bool, default=False</span>
<span class="sd">            if ``True`` logs to the progress bar.</span>
<span class="sd">        logger: bool, default=None</span>
<span class="sd">            if ``True`` logs to the logger.</span>
<span class="sd">        on_step: bool, default=None</span>
<span class="sd">            ``None`` auto-logs for training_step but not validation/test_step.</span>
<span class="sd">            The default value is determined by the hook.</span>
<span class="sd">        on_epoch: bool, default=None</span>
<span class="sd">            ``None`` auto-logs for val/test step but not ``training_step``.</span>
<span class="sd">            The default value is determined by the hook.</span>
<span class="sd">        reduce_fx: str of callable, default=&#39;mean&#39;</span>
<span class="sd">            reduction function over step values for end of epoch.</span>
<span class="sd">            :meth:`torch.mean` by default.</span>
<span class="sd">        enable_graph: bool, default=False</span>
<span class="sd">            if ``True``, will not auto detach the graph.</span>
<span class="sd">        sync_dist: bool, default=False</span>
<span class="sd">            if ``True``, reduces the metric across devices. Use with care as</span>
<span class="sd">            this may lead to a significant communication overhead.</span>
<span class="sd">        sync_dist_group: object, default=None</span>
<span class="sd">            the DDP group to sync across.</span>
<span class="sd">        add_dataloader_idx: bool, default=True</span>
<span class="sd">            if ``True``, appends the index of the current dataloader to</span>
<span class="sd">            the name (when using multiple dataloaders). If ``False``, user</span>
<span class="sd">            needs to give unique names for each dataloader to not mix the</span>
<span class="sd">            values.</span>
<span class="sd">        batch_size: int, default=None</span>
<span class="sd">            current batch_size. This will be directly inferred from the</span>
<span class="sd">            loaded batch, but for some data structures you might need to</span>
<span class="sd">            explicitly provide it.</span>
<span class="sd">        rank_zero_only: bool, default=False</span>
<span class="sd">            tells Lightning if you are calling ``self.log`` from every</span>
<span class="sd">            process (default) or only from rank 0. If ``True``, you won&#39;t be</span>
<span class="sd">            able to use this metric as a monitor in callbacks (e.g., early</span>
<span class="sd">            stopping).</span>
<span class="sd">            Warning: Improper use can lead to deadlocks!</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; values = {&#39;loss&#39;: loss, &#39;acc&#39;: acc, ..., &#39;metric_n&#39;: metric_n}</span>
<span class="sd">        &gt;&gt;&gt; self.log_dict(values)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">log_dict</span><span class="p">(</span>
            <span class="n">dictionary</span><span class="o">=</span><span class="n">dictionary</span><span class="p">,</span>
            <span class="n">prog_bar</span><span class="o">=</span><span class="n">prog_bar</span><span class="p">,</span>
            <span class="n">logger</span><span class="o">=</span><span class="n">logger</span><span class="p">,</span>
            <span class="n">on_step</span><span class="o">=</span><span class="n">on_step</span><span class="p">,</span>
            <span class="n">on_epoch</span><span class="o">=</span><span class="n">on_epoch</span><span class="p">,</span>
            <span class="n">reduce_fx</span><span class="o">=</span><span class="n">reduce_fx</span><span class="p">,</span>
            <span class="n">enable_graph</span><span class="o">=</span><span class="n">enable_graph</span><span class="p">,</span>
            <span class="n">sync_dist</span><span class="o">=</span><span class="n">sync_dist</span><span class="p">,</span>
            <span class="n">sync_dist_group</span><span class="o">=</span><span class="n">sync_dist_group</span><span class="p">,</span>
            <span class="n">add_dataloader_idx</span><span class="o">=</span><span class="n">add_dataloader_idx</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">rank_zero_only</span><span class="o">=</span><span class="n">rank_zero_only</span>
        <span class="p">)</span></div>
</div>



<div class="viewcode-block" id="RegressorMixin">
<a class="viewcode-back" href="../../../generated/nidl.estimators.base.RegressorMixin.html#nidl.estimators.RegressorMixin">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">RegressorMixin</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Mixin class for all regression estimators in nidl.</span>

<span class="sd">    This mixin sets the estimator type to `&quot;regressor&quot;` through the</span>
<span class="sd">    `estimator_type` tag.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_estimator_type</span> <span class="o">=</span> <span class="s2">&quot;regressor&quot;</span></div>



<div class="viewcode-block" id="ClassifierMixin">
<a class="viewcode-back" href="../../../generated/nidl.estimators.base.ClassifierMixin.html#nidl.estimators.ClassifierMixin">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ClassifierMixin</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Mixin class for all classifiers in nidl.</span>

<span class="sd">    This mixin sets the estimator type to `classifier` through the</span>
<span class="sd">    `estimator_type` tag.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_estimator_type</span> <span class="o">=</span> <span class="s2">&quot;classifier&quot;</span></div>

    
    
<div class="viewcode-block" id="ClusterMixin">
<a class="viewcode-back" href="../../../generated/nidl.estimators.base.ClusterMixin.html#nidl.estimators.ClusterMixin">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ClusterMixin</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Mixin class for all cluster estimators in nidl.</span>

<span class="sd">    This mixin sets the estimator type to `clusterer` through the</span>
<span class="sd">    `estimator_type` tag.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_estimator_type</span> <span class="o">=</span> <span class="s2">&quot;clusterer&quot;</span></div>



<div class="viewcode-block" id="TransformerMixin">
<a class="viewcode-back" href="../../../generated/nidl.estimators.base.TransformerMixin.html#nidl.estimators.TransformerMixin">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">TransformerMixin</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Mixin class for all transformers in nidl.</span>

<span class="sd">    This mixin sets the estimator type to `transformer` through the</span>
<span class="sd">    `estimator_type` tag.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_estimator_type</span> <span class="o">=</span> <span class="s2">&quot;transformer&quot;</span></div>

</pre></div>
                    </div>
                <div class="spacer"></div>
		        
		        <!-- Footer -->
		        <div class="section-6-container section-container section-container-image-bg" id="section-6">
			        <div class="container">
			            <div class="row">
		                    <div class="col-md-5 offset-md-1 section-6-box wow fadeInDown">
                                <div class="section-6-title">
		                    	    <p>Follow us</p>
                                </div>
		                    	<div class="section-6-social">
			                    	<a href="https://www.facebook.com/pages/NeuroSpin/171075046414933"><i class="fab fa-facebook-f"></i></a>
									<a href="https://www.youtube.com/CEASaclay"><i class="fab fa-youtube"></i></a>
									<a href="https://twitter.com/neurospin_91"><i class="fab fa-twitter"></i></a>
									<a href="https://gaia.neurospin.fr"><i class="fa fa-link"></i></a>
                                    <p>&copy; 2025, 
nidl developers
 <antoine.grigis@cea.fr></p>
		                    	</div>
		                    </div>
			            </div>
			        </div>
                </div>
	        
	        </div>
	        <!-- End content -->
        
        </div>
        <!-- End wrapper -->

        <!-- Javascript -->
		<script src="../../../_static/js/jquery-3.3.1.min.js"></script>
		<script src="../../../_static/js/jquery-migrate-3.0.0.min.js"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
		<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
        <script src="../../../_static/js/jquery.backstretch.min.js"></script>
        <script src="../../../_static/js/wow.min.js"></script>
        <script src="../../../_static/js/jquery.waypoints.min.js"></script>
        <script src="../../../_static/js/jquery.mCustomScrollbar.concat.min.js"></script>
        <script src="../../../_static/js/scripts.js"></script>
        <script src="../../../_static/js/jquery.mosaic.js"></script>
        <script src="../../../_static/js/search.js"></script>
        <script type="text/javascript">
	        $('.top-content').backstretch("../../../_static/img/backgrounds/banner1.png");
            $('.section-6-container').backstretch("../../../_static/img/backgrounds/footer1.png");
        </script>

    </body>

</html>