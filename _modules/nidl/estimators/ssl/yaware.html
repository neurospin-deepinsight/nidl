<!doctype html>
<html lang="en">

    <head>

		<!-- Required meta tags -->
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

        <title>nidl</title>
        
        <!-- CSS -->
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500&display=swap">
		<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
        <link rel="stylesheet" href="../../../../_static/css/jquery.mCustomScrollbar.min.css">
        <link rel="stylesheet" href="../../../../_static/css/animate.css">
        <link rel="stylesheet" href="../../../../_static/css/style.css">
        <link rel="stylesheet" href="../../../../_static/css/jquery.mosaic.css">
        <link rel="stylesheet" href="../../../../_static/sg_gallery.css">
        <link rel="stylesheet" href="../../../../_static/css/media-queries.css">
        <link rel="stylesheet" href="../../../../_static/css/pygment.css">

        <!-- Favicon and touch icons -->
        <link rel="shortcut icon" href="../../../../_static/ico/favicon.png">
        <link rel="apple-touch-icon-precomposed" sizes="144x144" href="../../../../_static/ico/apple-touch-icon-144-precomposed.png">
        <link rel="apple-touch-icon-precomposed" sizes="114x114" href="../../../../_static/ico/apple-touch-icon-114-precomposed.png">
        <link rel="apple-touch-icon-precomposed" sizes="72x72" href="../../../../_static/ico/apple-touch-icon-72-precomposed.png">
        <link rel="apple-touch-icon-precomposed" href="../../../../_static/ico/apple-touch-icon-57-precomposed.png">

    </head>

    <body>

		<!-- Wrapper -->
    	<div class="wrapper">

			<!-- Sidebar -->
			<nav class="sidebar">
				
				<!-- close sidebar menu -->
				<div class="dismiss">
					<i class="fas fa-arrow-left"></i>
				</div>
				
				<!-- <div class="logo"">
					<h3><a href="../../../../index.html">Sidebar Menu</a></h3>
				</div> -->

                <!-- info setup -->
                    <p class="doc-version">
                        This documentation is for nidl <strong>version 0.0.0</strong>
                    </p>
                <p class="citing">
                    If you use the software, please do not hesitate to 
                    <a &mdash; <a href="https://github.com/neurospin-deepinsight/nidl">
                    Report a Bug</a>.
                </p>
				
                <!-- links -->
                
                
				<ul class="list-unstyled menu-elements">
					<li class="active">
						<a href="../../../../index.html"><i class="fas fa-home"></i> Home</a>
					</li>
					<li>
						<a href="../../../../generated/installation.html"><i class="fas fa-cog"></i> Installation</a>
					</li>
					<li>
						<a href="../../../../auto_gallery/index.html"><i class="fas fa-eye"></i> Gallery</a>
					</li>
					<li>
						<a href="../../../../generated/documentation.html"><i class="fas fa-pencil-alt"></i> API documentation</a>
					</li>
					<li>
						<a href="../../../../generated/search.html"><i class="fas fa-search"></i> Search</a>
					</li>
					<!-- <li>
						<a href="https://github.com/AGrigis/pysphinxdoc"><i class="fas fa-external-link-alt"></i> PYSPHINXDOC</a>
					</li> -->
					<!-- <li>
						<a href="#otherSections" data-toggle="collapse" aria-expanded="false" class="dropdown-toggle" role="button" aria-controls="otherSections">
							<i class="fas fa-sync"></i>Sections Shortcuts
						</a>
						<ul class="collapse list-unstyled" id="otherSections">
                            <li>LINKS</li><li><a href='https://github.com/neurospin-deepinsight/surfify'>surfify</a></li>
                            
                            <li>API</li>
                            <li><a href="../../../../generated/nidl.html">nidl</a></li><li><a href="../../../../generated/nidl.callbacks.html">nidl.callbacks</a></li><li><a href="../../../../generated/nidl.datasets.html">nidl.datasets</a></li><li><a href="../../../../generated/nidl.estimators.html">nidl.estimators</a></li><li><a href="../../../../generated/nidl.estimators.linear.html">nidl.estimators.linear</a></li><li><a href="../../../../generated/nidl.estimators.ssl.html">nidl.estimators.ssl</a></li><li><a href="../../../../generated/nidl.estimators.ssl.utils.html">nidl.estimators.ssl.utils</a></li><li><a href="../../../../generated/nidl.losses.html">nidl.losses</a></li><li><a href="../../../../generated/nidl.metrics.html">nidl.metrics</a></li><li><a href="../../../../generated/nidl.utils.html">nidl.utils</a></li><li><a href="../../../../generated/nidl.volume.html">nidl.volume</a></li><li><a href="../../../../generated/nidl.volume.backbones.html">nidl.volume.backbones</a></li><li><a href="../../../../generated/nidl.volume.transforms.html">nidl.volume.transforms</a></li><li><a href="../../../../generated/nidl.volume.transforms.augmentation.html">nidl.volume.transforms.augmentation</a></li><li><a href="../../../../generated/nidl.volume.transforms.augmentation.intensity.html">nidl.volume.transforms.augmentation.intensity</a></li><li><a href="../../../../generated/nidl.volume.transforms.augmentation.spatial.html">nidl.volume.transforms.augmentation.spatial</a></li><li><a href="../../../../generated/nidl.volume.transforms.preprocessing.html">nidl.volume.transforms.preprocessing</a></li><li><a href="../../../../generated/nidl.volume.transforms.preprocessing.intensity.html">nidl.volume.transforms.preprocessing.intensity</a></li><li><a href="../../../../generated/nidl.volume.transforms.preprocessing.spatial.html">nidl.volume.transforms.preprocessing.spatial</a></li><li><a href="../../../../generated/surfify.html">surfify</a></li><li><a href="../../../../generated/surfify.augmentation.html">surfify.augmentation</a></li><li><a href="../../../../generated/surfify.datasets.html">surfify.datasets</a></li><li><a href="../../../../generated/surfify.losses.html">surfify.losses</a></li><li><a href="../../../../generated/surfify.models.html">surfify.models</a></li><li><a href="../../../../generated/surfify.nn.html">surfify.nn</a></li><li><a href="../../../../generated/surfify.plotting.html">surfify.plotting</a></li><li><a href="../../../../generated/surfify.utils.html">surfify.utils</a></li>
						</ul>
					</li> -->
				</ul>
				
                <!-- go top page -->
				<!-- <div class="to-top">
					<a class="btn btn-primary btn-customized-3" href="#" role="button">
	                    <i class="fas fa-arrow-up"></i> Top
	                </a>
				</div> -->
			
                <!-- change color -->
				<!-- <div class="dark-light-buttons">
					<a class="btn btn-primary btn-customized-4 btn-customized-dark" href="#" role="button">Dark</a>
					<a class="btn btn-primary btn-customized-4 btn-customized-light" href="#" role="button">Light</a>
				</div> -->
			
			</nav>
			<!-- End sidebar -->
			
			<!-- Dark overlay -->
    		<div class="overlay"></div>

			<!-- Content -->
			<div class="content">
			
				<!-- open sidebar menu -->
				<a class="btn btn-primary btn-customized open-menu" href="#" role="button">
                    <i class="fas fa-align-left"></i> <span>Menu</span>
                </a>

		        <!-- Top content -->
		        <div class="top-content section-container" id="top-content">
			        <div class="container">
			            <div class="row">
                            <div class="col-md-3 section-5-box banner-logo">
                                <img alt="Logo" src="../../../../_static/nidl.png">
                            </div>
			                <div class="col-md-7 section-5-box">
			                	<h1 class="wow fadeIn">    <p>Deep learning for NeuroImaging in Python.</p></h1>
			                </div>
			            </div>
			        </div>
		        </div>
                    
                    <div class="document">
                        <h1>Source code for nidl.estimators.ssl.yaware</h1><div class='divider-1 wow fadeInUp' style='margin-top: -20px;'><span></span></div><div class="highlight"><pre>
<span></span><span class="c1">##########################################################################</span>
<span class="c1"># NSAp - Copyright (C) CEA, 2025</span>
<span class="c1"># Distributed under the terms of the CeCILL-B license, as published by</span>
<span class="c1"># the CEA-CNRS-INRIA. Refer to the LICENSE file or to</span>
<span class="c1"># http://www.cecill.info/licences/Licence_CeCILL-B_V1-en.html</span>
<span class="c1"># for details.</span>
<span class="c1">##########################################################################</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sequence</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pytorch_lightning.utilities.types</span><span class="w"> </span><span class="kn">import</span> <span class="n">LRSchedulerPLType</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optimizer</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">...losses</span><span class="w"> </span><span class="kn">import</span> <span class="n">KernelMetric</span><span class="p">,</span> <span class="n">YAwareInfoNCE</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..base</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.utils.projection_heads</span><span class="w"> </span><span class="kn">import</span> <span class="n">YAwareProjectionHead</span>


<div class="viewcode-block" id="YAwareContrastiveLearning">
<a class="viewcode-back" href="../../../../generated/nidl.estimators.ssl.yaware.YAwareContrastiveLearning.html#nidl.estimators.ssl.YAwareContrastiveLearning">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">YAwareContrastiveLearning</span><span class="p">(</span><span class="n">TransformerMixin</span><span class="p">,</span> <span class="n">BaseEstimator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;y-Aware Contrastive Learning implementation [1]</span>

<span class="sd">    y-Aware Contrastive Learning is a self-supervised learning framework for</span>
<span class="sd">    learning visual representations with auxiliary variables. It leverages</span>
<span class="sd">    contrastive learning by maximizing the agreement between differently</span>
<span class="sd">    augmented views of images with similar auxiliary variables while minimizing</span>
<span class="sd">    agreement between different images. The framework consists of:</span>

<span class="sd">    1) Data Augmentation - Generates two augmented views of an image.</span>
<span class="sd">    2) Kernel - Similarity function between auxiliary variables.</span>
<span class="sd">    3) Encoder (Backbone Network) - Maps images to feature embeddings</span>
<span class="sd">       (e.g., 3D-ResNet).</span>
<span class="sd">    4) Projection Head - Maps features to a latent space for contrastive</span>
<span class="sd">       loss optimization.</span>
<span class="sd">    5) Contrastive Loss (y-Aware) - Encourages augmented views of</span>
<span class="sd">       i) the same image and ii) images with close auxiliary variables</span>
<span class="sd">       to be closer while pushing dissimilar ones apart.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Contrastive Learning with Continuous Proxy Meta-Data for 3D MRI</span>
<span class="sd">        Classification, Dufumier et al., MICCAI 2021</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    encoder : nn.Module or class</span>
<span class="sd">        Which deep architecture to use for encoding the input.</span>
<span class="sd">        A PyTorch :class:`~torch.nn.Module` is expected.</span>
<span class="sd">        In general, the uninstantiated class should be passed, although</span>
<span class="sd">        instantiated modules will also work.</span>

<span class="sd">    encoder_kwargs : dict or None, default=None</span>
<span class="sd">        Options for building the encoder (depends on each architecture).</span>
<span class="sd">        Examples:</span>

<span class="sd">        - encoder=torchvision.ops.MLP, encoder_kwargs={&quot;in_channels&quot;: 10,</span>
<span class="sd">          &quot;hidden_channels&quot;: [4, 3, 2]} builds an MLP with 3 hidden layers,</span>
<span class="sd">          input dim 10, output dim 2.</span>
<span class="sd">        - encoder=nidl.volume.backbones.resnet3d.resnet18,</span>
<span class="sd">          encoder_kwargs={&quot;n_embedding&quot;: 10} builds a ResNet-18 model with</span>
<span class="sd">          10 output dimension.</span>

<span class="sd">        Ignored if `encoder` is instantiated.</span>

<span class="sd">    projection_head : nn.Module or class or None, default=YAwareProjectionHead</span>
<span class="sd">        Which projection head to use for the model. If None, no projection head</span>
<span class="sd">        is used and the encoder output is directly used for loss computation.</span>
<span class="sd">        Otherwise, a :class:`~torch.nn.Module` is expected. In general,</span>
<span class="sd">        the uninstantiated class should be passed, although instantiated</span>
<span class="sd">        modules will also work. By default, a 2-layer MLP with ReLU activation,</span>
<span class="sd">        2048-d hidden units, and 128-d output dimensions is used.</span>

<span class="sd">    projection_head_kwargs : dict or None, default=None</span>
<span class="sd">        Arguments for building the projection head. By default, input dimension</span>
<span class="sd">        is 2048-d and output dimension is 128-d. These can be changed by</span>
<span class="sd">        passing a dictionary with keys &#39;input_dim&#39; and &#39;output_dim&#39;.</span>
<span class="sd">        &#39;input_dim&#39; must be equal to the encoder&#39;s output dimension.</span>
<span class="sd">        Ignored if `projection_head` is instantiated.</span>

<span class="sd">    temperature : float, default=0.1</span>
<span class="sd">        Temperature value in y-Aware InfoNCE loss. Small values imply more</span>
<span class="sd">        uniformity between samples&#39; embeddings, whereas high values impose</span>
<span class="sd">        clustered embedding more sensitive to augmentations.</span>

<span class="sd">    kernel : {&#39;gaussian&#39;, &#39;epanechnikov&#39;, &#39;exponential&#39;, &#39;linear&#39;, &#39;cosine&#39;}, \</span>
<span class="sd">        default=&quot;gaussian&quot;</span>
<span class="sd">        Kernel used as a similarity function between auxiliary variables.</span>

<span class="sd">    bandwidth : Union[float, int, List[float], array, KernelMetric], \</span>
<span class="sd">        default=1.0</span>
<span class="sd">        The method used to calculate the bandwidth (&quot;sigma&quot; in [1]) between</span>
<span class="sd">        auxiliary variables:</span>

<span class="sd">        - If `bandwidth` is a scalar (int or float), it sets the bandwidth to</span>
<span class="sd">          a diagnonal matrix with equal values.</span>
<span class="sd">        - If `bandwidth` is a 1d array, it sets the bandwidth to a</span>
<span class="sd">          diagonal matrix and it must be of size equal to the number of</span>
<span class="sd">          features in `y`.</span>
<span class="sd">        - If bandwidth is a 2d array, it must be of shape</span>
<span class="sd">          `(n_features, n_features)` where `n_features` is the number of</span>
<span class="sd">          features in `y`.</span>
<span class="sd">        - If `bandwidth` is :class:`~KernelMetric`, it uses the `pairwise`</span>
<span class="sd">          method to compute the similarity matrix between auxiliary variables.</span>

<span class="sd">    optimizer : {&#39;sgd&#39;, &#39;adam&#39;, &#39;adamW&#39;} or torch.optim.Optimizer or type, \</span>
<span class="sd">        default=&quot;adam&quot;</span>
<span class="sd">        Optimizer for training the model. Can be:</span>

<span class="sd">        - A string:</span>
<span class="sd">        </span>
<span class="sd">            - &#39;sgd&#39;: Stochastic Gradient Descent (with optional momentum).</span>
<span class="sd">            - &#39;adam&#39;: First-order gradient-based optimizer (default).</span>
<span class="sd">            - &#39;adamW&#39;: Adam with decoupled weight decay regularization</span>
<span class="sd">              (see &quot;Decoupled Weight Decay Regularization&quot;, Loshchilov and</span>
<span class="sd">              Hutter, ICLR 2019).</span>
<span class="sd">              </span>
<span class="sd">        - An instance or subclass of ``torch.optim.Optimizer``.</span>

<span class="sd">    optimizer_kwargs : dict or None, default=None</span>
<span class="sd">        Arguments for the optimizer (&#39;adam&#39; by default). By default:</span>
<span class="sd">        {&#39;betas&#39;: (0.9, 0.99), &#39;weight_decay&#39;: 5e-05} where &#39;betas&#39; are the</span>
<span class="sd">        exponential decay rates for first and second moment estimates.</span>

<span class="sd">        Ignored if `optimizer` is instantiated.</span>

<span class="sd">    learning_rate : float, default=1e-4</span>
<span class="sd">        Initial learning rate.</span>

<span class="sd">    lr_scheduler : LRSchedulerPLType or class or None, default=None</span>
<span class="sd">        Learning rate scheduler to use.</span>

<span class="sd">    lr_scheduler_kwargs : dict or None, default=None</span>
<span class="sd">        Additional keyword arguments for the scheduler.</span>

<span class="sd">        Ignored if `lr_scheduler` is instantiated.</span>

<span class="sd">    **kwargs : dict, optional</span>
<span class="sd">        Additional keyword arguments for the BaseEstimator class, such as</span>
<span class="sd">        `max_epochs`, `max_steps`, `num_sanity_val_steps`,</span>
<span class="sd">        `check_val_every_n_epoch`, `callbacks`, etc.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    encoder : torch.nn.Module</span>
<span class="sd">        Deep neural network mapping input data to low-dimensional vectors.</span>

<span class="sd">    projection_head : torch.nn.Module</span>
<span class="sd">        Maps encoder output to latent space for contrastive loss optimization.</span>

<span class="sd">    loss : yAwareInfoNCE</span>
<span class="sd">        The yAwareInfoNCE loss function used for training.</span>

<span class="sd">    optimizer : torch.optim.Optimizer</span>
<span class="sd">        Optimizer used for training.</span>

<span class="sd">    lr_scheduler : LRSchedulerPLType or None</span>
<span class="sd">        Learning rate scheduler used for training.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">encoder</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="nb">type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]],</span>
        <span class="n">encoder_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">projection_head</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="nb">type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">],</span> <span class="kc">None</span>
        <span class="p">]</span> <span class="o">=</span> <span class="n">YAwareProjectionHead</span><span class="p">,</span>
        <span class="n">projection_head_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="n">kernel</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;gaussian&quot;</span><span class="p">,</span>
        <span class="n">bandwidth</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">KernelMetric</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Optimizer</span><span class="p">,</span> <span class="nb">type</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">]]</span> <span class="o">=</span> <span class="s2">&quot;adam&quot;</span><span class="p">,</span>
        <span class="n">optimizer_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">lr_scheduler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">Union</span><span class="p">[</span><span class="n">LRSchedulerPLType</span><span class="p">,</span> <span class="nb">type</span><span class="p">[</span><span class="n">LRSchedulerPLType</span><span class="p">]]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">lr_scheduler_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">optimizer_kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">optimizer_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;betas&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">),</span> <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="mf">5e-05</span><span class="p">}</span>
        <span class="n">ignore</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="n">ignore</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;encoder&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">projection_head</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="n">ignore</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;projection_head&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">ignore</span><span class="o">=</span><span class="n">ignore</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_kwargs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">encoder_kwargs</span> <span class="k">if</span> <span class="n">encoder_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_encoder</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection_head_kwargs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">projection_head_kwargs</span>
            <span class="k">if</span> <span class="n">projection_head_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="p">{}</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection_head</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_projection_head</span><span class="p">(</span>
            <span class="n">projection_head</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_head_kwargs</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bandwidth</span> <span class="o">=</span> <span class="n">bandwidth</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_loss</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bandwidth</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_kwargs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">lr_scheduler_kwargs</span> <span class="k">if</span> <span class="n">lr_scheduler_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_kwargs</span> <span class="o">=</span> <span class="n">optimizer_kwargs</span>

<div class="viewcode-block" id="YAwareContrastiveLearning.training_step">
<a class="viewcode-back" href="../../../../generated/nidl.estimators.ssl.yaware.YAwareContrastiveLearning.html#nidl.estimators.ssl.YAwareContrastiveLearning.training_step">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform one training step and computes training loss.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        batch: Any</span>
<span class="sd">            A batch of data that has been generated from train_dataloader.</span>
<span class="sd">            It can be a pair of `torch.Tensor` (V1, V2) or a pair</span>
<span class="sd">            ((V1, V2), y) where V1 and V2 are the two views of the same sample</span>
<span class="sd">            and y is the auxiliary variable.</span>

<span class="sd">        batch_idx: int</span>
<span class="sd">            The index of the current batch.</span>

<span class="sd">        Returns</span>
<span class="sd">        ----------</span>
<span class="sd">        loss: Tensor</span>
<span class="sd">            Training loss computed on this batch of data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">V1</span><span class="p">,</span> <span class="n">V2</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">Z1</span><span class="p">,</span> <span class="n">Z2</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">projection_head</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">V1</span><span class="p">)),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">projection_head</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">V2</span><span class="p">)),</span>
        <span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">Z1</span><span class="p">,</span> <span class="n">Z2</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;loss/train&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
            <span class="s2">&quot;Z1&quot;</span><span class="p">:</span> <span class="n">Z1</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
            <span class="s2">&quot;Z2&quot;</span><span class="p">:</span> <span class="n">Z2</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
            <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="n">y</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="c1"># Returns everything needed for further logging/metrics computation</span>
        <span class="k">return</span> <span class="n">outputs</span></div>


<div class="viewcode-block" id="YAwareContrastiveLearning.validation_step">
<a class="viewcode-back" href="../../../../generated/nidl.estimators.ssl.yaware.YAwareContrastiveLearning.html#nidl.estimators.ssl.YAwareContrastiveLearning.validation_step">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform one validation step and computes validation loss.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        batch: Any</span>
<span class="sd">            A batch of data that has been generated from val_dataloader.</span>
<span class="sd">            It can be a pair of `torch.Tensor` (V1, V2) or a pair</span>
<span class="sd">            ((V1, V2), y) where V1 and V2 are the two views of the same</span>
<span class="sd">            sample and y is the auxiliary variable.</span>

<span class="sd">        batch_idx: int</span>
<span class="sd">            The index of the current batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">V1</span><span class="p">,</span> <span class="n">V2</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">Z1</span><span class="p">,</span> <span class="n">Z2</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">projection_head</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">V1</span><span class="p">)),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">projection_head</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">V2</span><span class="p">)),</span>
        <span class="p">)</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">Z1</span><span class="p">,</span> <span class="n">Z2</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">val_loss</span><span class="p">,</span>
            <span class="s2">&quot;Z1&quot;</span><span class="p">:</span> <span class="n">Z1</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
            <span class="s2">&quot;Z2&quot;</span><span class="p">:</span> <span class="n">Z2</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
            <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="n">y</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;loss/val&quot;</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># Returns everything needed for further logging/metrics computation</span>
        <span class="k">return</span> <span class="n">outputs</span></div>


<div class="viewcode-block" id="YAwareContrastiveLearning.transform_step">
<a class="viewcode-back" href="../../../../generated/nidl.estimators.ssl.yaware.YAwareContrastiveLearning.html#nidl.estimators.ssl.YAwareContrastiveLearning.transform_step">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">batch</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">dataloader_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span></div>


<div class="viewcode-block" id="YAwareContrastiveLearning.parse_batch">
<a class="viewcode-back" href="../../../../generated/nidl.estimators.ssl.yaware.YAwareContrastiveLearning.html#nidl.estimators.ssl.YAwareContrastiveLearning.parse_batch">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">parse_batch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Parses the batch to extract the two views and the auxiliary</span>
<span class="sd">        variable.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        batch: Any</span>
<span class="sd">            Parse a batch input and return V1, V2, and y.</span>
<span class="sd">            The batch can be either:</span>

<span class="sd">            - (V1, V2): two views of the same sample.</span>
<span class="sd">            - ((V1, V2), y): two views and an auxiliary label or variable.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        V1 : torch.Tensor</span>
<span class="sd">            First view of the input.</span>
<span class="sd">        V2 : torch.Tensor</span>
<span class="sd">            Second view of the input.</span>
<span class="sd">        y : Optional[torch.Tensor]</span>
<span class="sd">            Auxiliary label or variable, if present. Otherwise, None.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">first</span><span class="p">,</span> <span class="n">second</span> <span class="o">=</span> <span class="n">batch</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">first</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">first</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="c1"># Case: ((V1, V2), y)</span>
                <span class="n">V1</span><span class="p">,</span> <span class="n">V2</span> <span class="o">=</span> <span class="n">first</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">second</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Case: (V1, V2)</span>
                <span class="n">V1</span><span class="p">,</span> <span class="n">V2</span> <span class="o">=</span> <span class="n">first</span><span class="p">,</span> <span class="n">second</span>
                <span class="n">y</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;batch should be a pair (V1, V2), or a pair &quot;</span>
                <span class="s2">&quot;((V1, V2), y) where V1 and V2 are the two &quot;</span>
                <span class="s2">&quot;views of the same sample and y is the auxiliary &quot;</span>
                <span class="s2">&quot;variable.&quot;</span>
            <span class="p">)</span>
        <span class="n">V1</span> <span class="o">=</span> <span class="n">V1</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">V2</span> <span class="o">=</span> <span class="n">V2</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">V1</span><span class="p">,</span> <span class="n">V2</span><span class="p">,</span> <span class="n">y</span></div>


<div class="viewcode-block" id="YAwareContrastiveLearning.configure_optimizers">
<a class="viewcode-back" href="../../../../generated/nidl.estimators.ssl.yaware.YAwareContrastiveLearning.html#nidl.estimators.ssl.YAwareContrastiveLearning.configure_optimizers">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">known_optimizers</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;adam&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span>
            <span class="s2">&quot;adamW&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">,</span>
            <span class="s2">&quot;sgd&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">projection_head</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">known_optimizers</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Optimizer &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="si">}</span><span class="s2">&#39; is not implemented. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Please use one of the available optimizers: &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">known_optimizers</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">known_optimizers</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">](</span>
                <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer_kwargs</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">Optimizer</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer_kwargs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;optimizer is already instantiated, ignoring &quot;</span>
                    <span class="s2">&quot;&#39;optimizer_kwargs&#39;&quot;</span>
                <span class="p">)</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="nb">type</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">Optimizer</span>
        <span class="p">):</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">(</span>
                <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer_kwargs</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Optimizer must be a string, a PyTorch Optimizer, or a class &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;inheriting from Optimizer, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">scheduler</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">LRSchedulerPLType</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_kwargs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;lr_scheduler is already instantiated, ignoring &quot;</span>
                    <span class="s2">&quot;&#39;lr_scheduler_kwargs&#39;&quot;</span>
                <span class="p">)</span>
            <span class="n">scheduler</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="p">,</span> <span class="nb">type</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">LRSchedulerPLType</span>
        <span class="p">):</span>
            <span class="n">scheduler</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="p">(</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_kwargs</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">scheduler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">optimizer</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">optimizer</span><span class="p">],</span> <span class="p">[</span><span class="n">scheduler</span><span class="p">]</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_build_encoder</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">encoder</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="nb">type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]],</span>
        <span class="n">encoder_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">encoder_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoder_kwargs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;encoder is already instantiated, ignoring &quot;</span>
                    <span class="s2">&quot;&#39;encoder_kwargs&#39;&quot;</span>
                <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="nb">type</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="o">**</span><span class="n">encoder_kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Encoder must be a string, a PyTorch nn.Module, or a class &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;inheriting from nn.Module, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">encoder</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">encoder</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_build_projection_head</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">projection_head</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="nb">type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]],</span>
        <span class="n">projection_head_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">projection_head</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">projection_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">projection_head</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">projection_head_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">projection_head_kwargs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="p">):</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;projection head is already instantiated, ignoring &quot;</span>
                    <span class="s2">&quot;&#39;projection_head_kwargs&#39;&quot;</span>
                <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">projection_head</span><span class="p">,</span> <span class="nb">type</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span>
            <span class="n">projection_head</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span>
        <span class="p">):</span>
            <span class="n">projection_head</span> <span class="o">=</span> <span class="n">projection_head</span><span class="p">(</span><span class="o">**</span><span class="n">projection_head_kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Projection head must be None, a string, a PyTorch nn.Module, &quot;</span>
                <span class="s2">&quot;or a class inheriting from nn.Module, got &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">projection_head</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">projection_head</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_build_loss</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">kernel</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">bandwidth</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Builds the y-Aware InfoNCE loss function with the</span>
<span class="sd">        specified temperature, kernel and bandwidth.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        temperature: float</span>
<span class="sd">            The temperature parameter for the InfoNCE loss.</span>

<span class="sd">        kernel: {&#39;gaussian&#39;, &#39;epanechnikov&#39;, &#39;exponential&#39;, &#39;linear&#39;, &#39;cosine&#39;}</span>
<span class="sd">            Kernel used as similarity function between auxiliary variables.</span>

<span class="sd">        bandwidth: float, list of float, array or KernelMetric</span>
<span class="sd">            The method used to calculate the bandwidth in kernel.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        loss: nn.Module</span>
<span class="sd">            The y-Aware InfoNCE loss function.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">YAwareInfoNCE</span><span class="p">(</span>
            <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">bandwidth</span><span class="o">=</span><span class="n">bandwidth</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span>
        <span class="p">)</span></div>

</pre></div>
                    </div>
                <div class="spacer"></div>
		        
		        <!-- Footer -->
		        <div class="section-6-container section-container section-container-image-bg" id="section-6">
			        <div class="container">
			            <div class="row">
		                    <div class="col-md-5 offset-md-1 section-6-box wow fadeInDown">
                                <div class="section-6-title">
		                    	    <p>Follow us</p>
                                </div>
		                    	<div class="section-6-social">
			                    	<a href="https://www.facebook.com/pages/NeuroSpin/171075046414933"><i class="fab fa-facebook-f"></i></a>
									<a href="https://www.youtube.com/CEASaclay"><i class="fab fa-youtube"></i></a>
									<a href="https://twitter.com/neurospin_91"><i class="fab fa-twitter"></i></a>
									<a href="https://gaia.neurospin.fr"><i class="fa fa-link"></i></a>
                                    <p>&copy; 2025, 
nidl developers
 <antoine.grigis@cea.fr></p>
		                    	</div>
		                    </div>
			            </div>
			        </div>
                </div>
	        
	        </div>
	        <!-- End content -->
        
        </div>
        <!-- End wrapper -->

        <!-- Javascript -->
		<script src="../../../../_static/js/jquery-3.3.1.min.js"></script>
		<script src="../../../../_static/js/jquery-migrate-3.0.0.min.js"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
		<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
        <script src="../../../../_static/js/jquery.backstretch.min.js"></script>
        <script src="../../../../_static/js/wow.min.js"></script>
        <script src="../../../../_static/js/jquery.waypoints.min.js"></script>
        <script src="../../../../_static/js/jquery.mCustomScrollbar.concat.min.js"></script>
        <script src="../../../../_static/js/scripts.js"></script>
        <script src="../../../../_static/js/jquery.mosaic.js"></script>
        <script src="../../../../_static/js/search.js"></script>
        <script type="text/javascript">
	        $('.top-content').backstretch("../../../../_static/img/backgrounds/banner1.png");
            $('.section-6-container').backstretch("../../../../_static/img/backgrounds/footer1.png");
        </script>

    </body>

</html>