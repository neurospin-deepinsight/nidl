<!doctype html>
<html lang="en">

    <head>

		<!-- Required meta tags -->
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

        <title>nidl</title>
        
        <!-- CSS -->
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500&display=swap">
		<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
        <link rel="stylesheet" href="../_static/css/jquery.mCustomScrollbar.min.css">
        <link rel="stylesheet" href="../_static/css/animate.css">
        <link rel="stylesheet" href="../_static/css/style.css">
        <link rel="stylesheet" href="../_static/css/jquery.mosaic.css">
        <link rel="stylesheet" href="../_static/sg_gallery.css">
        <link rel="stylesheet" href="../_static/css/media-queries.css">
        <link rel="stylesheet" href="../_static/css/pygment.css">

        <!-- Favicon and touch icons -->
        <link rel="shortcut icon" href="../_static/ico/favicon.png">
        <link rel="apple-touch-icon-precomposed" sizes="144x144" href="../_static/ico/apple-touch-icon-144-precomposed.png">
        <link rel="apple-touch-icon-precomposed" sizes="114x114" href="../_static/ico/apple-touch-icon-114-precomposed.png">
        <link rel="apple-touch-icon-precomposed" sizes="72x72" href="../_static/ico/apple-touch-icon-72-precomposed.png">
        <link rel="apple-touch-icon-precomposed" href="../_static/ico/apple-touch-icon-57-precomposed.png">

    </head>

    <body>

		<!-- Wrapper -->
    	<div class="wrapper">

			<!-- Sidebar -->
			<nav class="sidebar">
				
				<!-- close sidebar menu -->
				<div class="dismiss">
					<i class="fas fa-arrow-left"></i>
				</div>
				
				<!-- <div class="logo"">
					<h3><a href="../index.html">Sidebar Menu</a></h3>
				</div> -->

                <!-- info setup -->
                    <p class="doc-version">
                        This documentation is for nidl <strong>version 0.0.0</strong>
                    </p>
                <p class="citing">
                    If you use the software, please do not hesitate to 
                    <a &mdash; <a href="https://github.com/neurospin-deepinsight/nidl">
                    Report a Bug</a>.
                </p>
				
                <!-- links -->
                
                
                    
                
				<ul class="list-unstyled menu-elements">
					<li class="active">
						<a href="../index.html"><i class="fas fa-home"></i> Home</a>
					</li>
					<li>
						<a href="../generated/installation.html"><i class="fas fa-cog"></i> Installation</a>
					</li>
					<li>
						<a href="index.html"><i class="fas fa-eye"></i> Gallery</a>
					</li>
					<li>
						<a href="../generated/documentation.html"><i class="fas fa-pencil-alt"></i> API documentation</a>
					</li>
					<li>
						<a href="../generated/search.html"><i class="fas fa-search"></i> Search</a>
					</li>
					<!-- <li>
						<a href="https://github.com/AGrigis/pysphinxdoc"><i class="fas fa-external-link-alt"></i> PYSPHINXDOC</a>
					</li> -->
					<!-- <li>
						<a href="#otherSections" data-toggle="collapse" aria-expanded="false" class="dropdown-toggle" role="button" aria-controls="otherSections">
							<i class="fas fa-sync"></i>Sections Shortcuts
						</a>
						<ul class="collapse list-unstyled" id="otherSections">
                            <li>LINKS</li><li><a href='https://github.com/neurospin-deepinsight/surfify'>surfify</a></li>
                            
                                
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                
                                
                                    <li>SECTIONS</li>
                                    
						                <li> <a href='#setup'>Setup</a> </li>                                    
                                    
						                <li> <a href='#unsupervised-contrastive-learning-on-mnist'>Unsupervised Contrastive Learning On Mnist</a> </li>                                    
                                    
						                <li> <a href='#dataset-and-data-augmentations-for-contrastive-learning'>Dataset And Data Augmentations For Contrastive Learning</a> </li>                                    
                                    
						                <li> <a href='#simclr-training-with-classification-probing-callback'>Simclr Training With Classification Probing Callback</a> </li>                                    
                                    
						                <li> <a href='#visualization-of-the-classification-metrics-during-training'>Visualization Of The Classification Metrics During Training</a> </li>                                    
                                    
						                <li> <a href='#probing-of-y-aware-representation-on-age-and-sex-prediction'>Probing Of Y-Aware Representation On Age And Sex Prediction</a> </li>                                    
                                    
						                <li> <a href='#openbhb-dataset-and-data-augmentations'>Openbhb Dataset And Data Augmentations</a> </li>                                    
                                    
						                <li> <a href='#y-aware-cl-training-with-multitask-probing-callback'>Y-Aware Cl Training With Multitask Probing Callback</a> </li>                                    
                                    
						                <li> <a href='#visualization-of-the-classification-and-regression-metrics-during-training'>Visualization Of The Classification And Regression Metrics During Training</a> </li>                                    
                                    
						                <li> <a href='#conclusions'>Conclusions</a> </li>                                    
                                    
                                
                            
                            <li>API</li>
                            <li><a href="../generated/nidl.html">nidl</a></li><li><a href="../generated/nidl.callbacks.html">nidl.callbacks</a></li><li><a href="../generated/nidl.datasets.html">nidl.datasets</a></li><li><a href="../generated/nidl.estimators.html">nidl.estimators</a></li><li><a href="../generated/nidl.estimators.linear.html">nidl.estimators.linear</a></li><li><a href="../generated/nidl.estimators.ssl.html">nidl.estimators.ssl</a></li><li><a href="../generated/nidl.estimators.ssl.utils.html">nidl.estimators.ssl.utils</a></li><li><a href="../generated/nidl.losses.html">nidl.losses</a></li><li><a href="../generated/nidl.metrics.html">nidl.metrics</a></li><li><a href="../generated/nidl.utils.html">nidl.utils</a></li><li><a href="../generated/nidl.volume.html">nidl.volume</a></li><li><a href="../generated/nidl.volume.backbones.html">nidl.volume.backbones</a></li><li><a href="../generated/nidl.volume.transforms.html">nidl.volume.transforms</a></li><li><a href="../generated/nidl.volume.transforms.augmentation.html">nidl.volume.transforms.augmentation</a></li><li><a href="../generated/nidl.volume.transforms.augmentation.intensity.html">nidl.volume.transforms.augmentation.intensity</a></li><li><a href="../generated/nidl.volume.transforms.augmentation.spatial.html">nidl.volume.transforms.augmentation.spatial</a></li><li><a href="../generated/nidl.volume.transforms.preprocessing.html">nidl.volume.transforms.preprocessing</a></li><li><a href="../generated/nidl.volume.transforms.preprocessing.intensity.html">nidl.volume.transforms.preprocessing.intensity</a></li><li><a href="../generated/nidl.volume.transforms.preprocessing.spatial.html">nidl.volume.transforms.preprocessing.spatial</a></li><li><a href="../generated/surfify.html">surfify</a></li><li><a href="../generated/surfify.augmentation.html">surfify.augmentation</a></li><li><a href="../generated/surfify.datasets.html">surfify.datasets</a></li><li><a href="../generated/surfify.losses.html">surfify.losses</a></li><li><a href="../generated/surfify.models.html">surfify.models</a></li><li><a href="../generated/surfify.nn.html">surfify.nn</a></li><li><a href="../generated/surfify.plotting.html">surfify.plotting</a></li><li><a href="../generated/surfify.utils.html">surfify.utils</a></li>
						</ul>
					</li> -->
				</ul>
				
                <!-- go top page -->
				<!-- <div class="to-top">
					<a class="btn btn-primary btn-customized-3" href="#" role="button">
	                    <i class="fas fa-arrow-up"></i> Top
	                </a>
				</div> -->
			
                <!-- change color -->
				<!-- <div class="dark-light-buttons">
					<a class="btn btn-primary btn-customized-4 btn-customized-dark" href="#" role="button">Dark</a>
					<a class="btn btn-primary btn-customized-4 btn-customized-light" href="#" role="button">Light</a>
				</div> -->
			
			</nav>
			<!-- End sidebar -->
			
			<!-- Dark overlay -->
    		<div class="overlay"></div>

			<!-- Content -->
			<div class="content">
			
				<!-- open sidebar menu -->
				<a class="btn btn-primary btn-customized open-menu" href="#" role="button">
                    <i class="fas fa-align-left"></i> <span>Menu</span>
                </a>

		        <!-- Top content -->
		        <div class="top-content section-container" id="top-content">
			        <div class="container">
			            <div class="row">
                            <div class="col-md-3 section-5-box banner-logo">
                                <img alt="Logo" src="../_static/nidl.png">
                            </div>
			                <div class="col-md-7 section-5-box">
			                	<h1 class="wow fadeIn">    <p>Deep learning for NeuroImaging in Python.</p></h1>
			                </div>
			            </div>
			        </div>
		        </div>
                    
                    <div class="document">
                        <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-gallery-model-probing-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="model-probing-callback-of-embedding-estimators">
<span id="sphx-glr-auto-gallery-model-probing-py"></span><h1>Model probing callback of embedding estimators<a class="headerlink" href="#model-probing-callback-of-embedding-estimators" title="Link to this heading">¶</a></h1><div class='divider-1 wow fadeInUp' style='margin-top: -20px;'><span></span></div>
<p>This notebook will show you how to investigate the <strong>data representation given
by an embedding estimator during training</strong>  (such as SimCLR, y-Aware
Contrastive Learning or Barlow Twins) using the notion of “probing”.
A standard machine learning model (e.g. linear or SVM) is trained and evaluated
on the data embedding for a given task as the model is being fitted. It allows
the user to understand what concepts are learned by the model.</p>
<p>This has been first introduced by Guillaume Alain and Yoshua Bengio in 2017
<a class="footnote-reference brackets" href="#id2" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> to understand the internal behavior of a deep neural network along
the different layers. This technique aimed at answering questions like: what is
the intermediate representation of a neural network? What information is
contained for a given layer ?</p>
<p>Then, it has been adapted to benchmark self-supervised vision models
(like SimCLR, Barlow Twins, DINO, DINOv2) on classical datasets (ImageNet,
CIFAR, …) by implementing linear probing and K-Nearest Neighbors probing
on the ouput representation of the models.</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id2" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Guillaume Alain and Yoshua Bengio, <em>Understanding intermediate layers
using linear classifier probes</em>, ICLR 2017 Workshop.</p>
</aside>
</aside>
<section id="setup">
<h2 style='border-bottom: 1px solid #d3dbd5'>Setup<a class="headerlink" href="#setup" title="Link to this heading">¶</a></h2>
<p>This notebook requires some packages besides nidl. Let’s first start with
importing our standard libraries below:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">func</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">Ridge</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorboard.backend.event_processing</span><span class="w"> </span><span class="kn">import</span> <span class="n">event_accumulator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">MNIST</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.ops</span><span class="w"> </span><span class="kn">import</span> <span class="n">MLP</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">make_grid</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">nidl.callbacks.model_probing</span><span class="w"> </span><span class="kn">import</span> <a href="../generated/nidl.callbacks.model_probing.ClassificationProbingCallback.html#nidl.callbacks.model_probing.ClassificationProbingCallback" title="nidl.callbacks.model_probing.ClassificationProbingCallback" class="sphx-glr-backref-module-nidl-callbacks-model_probing sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ClassificationProbingCallback</span></a>
<span class="kn">from</span><span class="w"> </span><span class="nn">nidl.callbacks.multitask_probing</span><span class="w"> </span><span class="kn">import</span> <a href="../generated/nidl.callbacks.multitask_probing.MultitaskModelProbing.html#nidl.callbacks.multitask_probing.MultitaskModelProbing" title="nidl.callbacks.multitask_probing.MultitaskModelProbing" class="sphx-glr-backref-module-nidl-callbacks-multitask_probing sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">MultitaskModelProbing</span></a>
<span class="kn">from</span><span class="w"> </span><span class="nn">nidl.datasets</span><span class="w"> </span><span class="kn">import</span> <a href="../generated/nidl.datasets.OpenBHB.html#nidl.datasets.OpenBHB" title="nidl.datasets.OpenBHB" class="sphx-glr-backref-module-nidl-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">OpenBHB</span></a>
<span class="kn">from</span><span class="w"> </span><span class="nn">nidl.estimators.ssl</span><span class="w"> </span><span class="kn">import</span> <a href="../generated/nidl.estimators.ssl.SimCLR.html#nidl.estimators.ssl.SimCLR" title="nidl.estimators.ssl.SimCLR" class="sphx-glr-backref-module-nidl-estimators-ssl sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">SimCLR</span></a><span class="p">,</span> <a href="../generated/nidl.estimators.ssl.YAwareContrastiveLearning.html#nidl.estimators.ssl.YAwareContrastiveLearning" title="nidl.estimators.ssl.YAwareContrastiveLearning" class="sphx-glr-backref-module-nidl-estimators-ssl sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">YAwareContrastiveLearning</span></a>
<span class="kn">from</span><span class="w"> </span><span class="nn">nidl.transforms</span><span class="w"> </span><span class="kn">import</span> <a href="../generated/nidl.transforms.MultiViewsTransform.html#nidl.transforms.MultiViewsTransform" title="nidl.transforms.MultiViewsTransform" class="sphx-glr-backref-module-nidl-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">MultiViewsTransform</span></a>
</pre></div>
</div>
<p>We define some global parameters that will be used throughout the notebook:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">data_dir</span> <span class="o">=</span> <span class="s2">&quot;/tmp/mnist&quot;</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">num_workers</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">latent_size</span> <span class="o">=</span> <span class="mi">32</span>
</pre></div>
</div>
</section>
<section id="unsupervised-contrastive-learning-on-mnist">
<h2 style='border-bottom: 1px solid #d3dbd5'>Unsupervised Contrastive Learning on MNIST<a class="headerlink" href="#unsupervised-contrastive-learning-on-mnist" title="Link to this heading">¶</a></h2>
<p>For illustration purposes on how to use the probing callback, we will focus
on the handwritten digits dataset MNIST. It contains 60k training images and
10k test images of size 28x28 pixels. Each image contains a digit from 0 to
9. It is rather small-scale compared to modern datasets like ImageNet but
sufficient to illustrate the probing technique.
We will train a SimCLR model on these data and probe the learned
representation using a logistic regression classifier on the digit
classification task. It will show how the data embedding evolves during
training to become more linearly separable for each digit class.</p>
<p>We start by loading the MNIST dataset dataset with standard scaling
transforms. These datasets are used for training and testing the probing.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">scale_transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
    <span class="p">[</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,))]</span>
<span class="p">)</span>
<span class="n">train_xy_dataset</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">scale_transforms</span><span class="p">)</span>
<span class="n">test_xy_dataset</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span>
    <span class="n">data_dir</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">scale_transforms</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="dataset-and-data-augmentations-for-contrastive-learning">
<h2 style='border-bottom: 1px solid #d3dbd5'>Dataset and data augmentations for contrastive learning<a class="headerlink" href="#dataset-and-data-augmentations-for-contrastive-learning" title="Link to this heading">¶</a></h2>
<p>To perform contrastive learning, we need to define a set of data
augmentations to create multiple views of the same image. Since we work
with grayscale images, we will use random resized crop and Gaussian blur. We
reduce the size of the Gaussian kernel to 3x3 since MNIST images are only
28x28 pixels.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">contrast_transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">28</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">GaussianBlur</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,)),</span>
    <span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
<p>We create a custom dataset that returns only the images (without labels).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">SSLMNIST</span><span class="p">(</span><span class="n">MNIST</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">img</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span>


<span class="n">ssl_dataset</span> <span class="o">=</span> <span class="n">SSLMNIST</span><span class="p">(</span>
    <span class="n">data_dir</span><span class="p">,</span>
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><a href="../generated/nidl.transforms.MultiViewsTransform.html#nidl.transforms.MultiViewsTransform" title="nidl.transforms.MultiViewsTransform" class="sphx-glr-backref-module-nidl-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">MultiViewsTransform</span></a><span class="p">(</span><span class="n">contrast_transforms</span><span class="p">,</span> <span class="n">n_views</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">test_ssl_dataset</span> <span class="o">=</span> <span class="n">SSLMNIST</span><span class="p">(</span>
    <span class="n">data_dir</span><span class="p">,</span>
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><a href="../generated/nidl.transforms.MultiViewsTransform.html#nidl.transforms.MultiViewsTransform" title="nidl.transforms.MultiViewsTransform" class="sphx-glr-backref-module-nidl-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">MultiViewsTransform</span></a><span class="p">(</span><span class="n">contrast_transforms</span><span class="p">,</span> <span class="n">n_views</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
<p>And finally we create the data loaders for training and testing the models.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">train_xy_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">train_xy_dataset</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">test_xy_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">test_xy_dataset</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">train_ssl_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">ssl_dataset</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">test_ssl_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">test_ssl_dataset</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Before starting training the SimCLR model, let’s visualize some
examples of the dataset.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">show_images</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">make_grid</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">nrow</span><span class="o">=</span><span class="n">nrow</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pad_value</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
    <span class="k">if</span> <span class="n">title</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="c1"># Original and augmented images</span>
<span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">test_xy_loader</span><span class="p">))</span>
<span class="n">augmented_views</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">test_ssl_loader</span><span class="p">))</span>
<span class="n">view1</span><span class="p">,</span> <span class="n">view2</span> <span class="o">=</span> <span class="n">augmented_views</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">augmented_views</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Original (label=</span><span class="si">{</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>

    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">view1</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Augmented View 1&quot;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>

    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">view2</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Augmented View 2&quot;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="simclr-training-with-classification-probing-callback">
<h2 style='border-bottom: 1px solid #d3dbd5'>SimCLR training with classification probing callback<a class="headerlink" href="#simclr-training-with-classification-probing-callback" title="Link to this heading">¶</a></h2>
<p>We can now create the probing callback that will train a logistic regression
classifier on the learned representation during SimCLR training. The probing
is performed every epoch on the training and test sets. The classification
metrics are logged to TensorBoard by default.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">callback</span> <span class="o">=</span> <a href="../generated/nidl.callbacks.model_probing.ClassificationProbingCallback.html#nidl.callbacks.model_probing.ClassificationProbingCallback" title="nidl.callbacks.model_probing.ClassificationProbingCallback" class="sphx-glr-backref-module-nidl-callbacks-model_probing sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ClassificationProbingCallback</span></a><span class="p">(</span>
    <span class="n">train_xy_loader</span><span class="p">,</span>
    <span class="n">test_xy_loader</span><span class="p">,</span>
    <span class="n">probe</span><span class="o">=</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">),</span>
    <span class="n">every_n_train_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Since MNIST images are small, we can use a simple LeNet-like architecture
as encoder for SimCLR, with few parameters. The output dimension of the
encoder is set to 32, which is approximately 30 times smaller that the input,
but larger than the number of input classes (10).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">LeNetEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_size</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_size</span> <span class="o">=</span> <span class="n">latent_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="n">latent_size</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="n">encoder</span> <span class="o">=</span> <span class="n">LeNetEncoder</span><span class="p">(</span><span class="n">latent_size</span><span class="p">)</span>
</pre></div>
</div>
<p>We can now create the SimCLR model with the encoder and the probing callback.
We limit the training to 10 epochs for the sake of time and because it is
enough for checking the evolution of the embedding geometry across training.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <a href="../generated/nidl.estimators.ssl.SimCLR.html#nidl.estimators.ssl.SimCLR" title="nidl.estimators.ssl.SimCLR" class="sphx-glr-backref-module-nidl-estimators-ssl sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">SimCLR</span></a><span class="p">(</span>
    <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="n">limit_train_batches</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">hidden_dims</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
    <span class="n">enable_checkpointing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="n">callback</span><span class="p">,</span>  <span class="c1"># &lt;-- key part for probing</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_ssl_loader</span><span class="p">,</span> <span class="n">test_ssl_loader</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="visualization-of-the-classification-metrics-during-training">
<h2 style='border-bottom: 1px solid #d3dbd5'>Visualization of the classification metrics during training<a class="headerlink" href="#visualization-of-the-classification-metrics-during-training" title="Link to this heading">¶</a></h2>
<p>After training, we can visualize the classification metrics logged
by the linear probe using TensorBoard. The logged metrics are stored
in the <cite>lightning_logs</cite> folder by default. They contain the accuracy,
balanced accuracy, F1-score (weighted and macro), precision (macro)
and recall (macro).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_last_log_version</span><span class="p">(</span><span class="n">logs_dir</span><span class="o">=</span><span class="s2">&quot;lightning_logs&quot;</span><span class="p">):</span>
    <span class="n">versions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">logs_dir</span><span class="p">):</span>
        <span class="n">match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;version_(\d+)&quot;</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">match</span><span class="p">:</span>
            <span class="n">versions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span>
    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">versions</span><span class="p">)</span> <span class="k">if</span> <span class="n">versions</span> <span class="k">else</span> <span class="kc">None</span>


<span class="n">log_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;lightning_logs/version_</span><span class="si">{</span><span class="n">get_last_log_version</span><span class="p">()</span><span class="si">}</span><span class="s2">/&quot;</span>
<span class="n">ea</span> <span class="o">=</span> <span class="n">event_accumulator</span><span class="o">.</span><span class="n">EventAccumulator</span><span class="p">(</span><span class="n">log_dir</span><span class="p">)</span>
<span class="n">ea</span><span class="o">.</span><span class="n">Reload</span><span class="p">()</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;LogisticRegression/accuracy&quot;</span><span class="p">,</span>
    <span class="s2">&quot;LogisticRegression/balanced_accuracy&quot;</span><span class="p">,</span>
    <span class="s2">&quot;LogisticRegression/f1_weighted&quot;</span><span class="p">,</span>
    <span class="s2">&quot;LogisticRegression/f1_macro&quot;</span><span class="p">,</span>
    <span class="s2">&quot;LogisticRegression/precision_macro&quot;</span><span class="p">,</span>
    <span class="s2">&quot;LogisticRegression/recall_macro&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">scalars</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">m</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;LogisticRegression/&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">):</span> <span class="n">ea</span><span class="o">.</span><span class="n">Scalars</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">metrics</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Once all the metrics are loaded, we plot them as the number of training steps
increases:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="k">for</span> <span class="n">m</span><span class="p">,</span> <span class="n">events</span> <span class="ow">in</span> <span class="n">scalars</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">steps</span> <span class="o">=</span> <span class="p">[</span><span class="n">e</span><span class="o">.</span><span class="n">step</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">events</span><span class="p">]</span>
    <span class="n">values</span> <span class="o">=</span> <span class="p">[</span><span class="n">e</span><span class="o">.</span><span class="n">value</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">events</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">m</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Nb steps (batch size=</span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Metric score&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Classification metrics during SimCLR training&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Observations</strong>: we can see that the classification metrics increase
steadily during training, showing that the learned representation becomes
more and more linearly separable for the digit classes. The accuracy
reaches more than 80% after 10 epochs, which is quite good for such a simple
model trained <em>without supervision</em> and a small number of epochs.</p>
</section>
<section id="probing-of-y-aware-representation-on-age-and-sex-prediction">
<h2 style='border-bottom: 1px solid #d3dbd5'>Probing of y-Aware representation on age and sex prediction<a class="headerlink" href="#probing-of-y-aware-representation-on-age-and-sex-prediction" title="Link to this heading">¶</a></h2>
<p>We have previously seen a simple case where only one classification task is
being monitored during training. We can also monitor a mixed of classification
and regression tasks at the same time during training of an embedding model.
This could be useful if several target variables should be monitored from the
representation.
We will show how to perform this with NIDL using the <strong>MultitaskModelProbing</strong>
callback on the OpenBHB dataset to monitor age and sex decoding from brain
imaging data. <em>We refer to the example on OpenBHB for more details on this
neuroimaging dataset.</em></p>
<p>We define the relevant global parameters for this example:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">data_dir</span> <span class="o">=</span> <span class="s2">&quot;/tmp/openbhb&quot;</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">num_workers</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">latent_size</span> <span class="o">=</span> <span class="mi">32</span>
</pre></div>
</div>
</section>
<section id="openbhb-dataset-and-data-augmentations">
<h2 style='border-bottom: 1px solid #d3dbd5'>OpenBHB dataset and data augmentations<a class="headerlink" href="#openbhb-dataset-and-data-augmentations" title="Link to this heading">¶</a></h2>
<p>We consider the gray matter and CSF volumes on some <strong>regions of
interests</strong> in the Neuromorphometrics atlas across subjects in
OpenBHB (“vbm_roi” modality). These data are tabular (not images) but
they are still well suited for contrastive learning and they are very light
compared to the raw images (284-d vector for each subject).
We start by loading these data for training and testing the probing callback.
The target variables are age (regression) and sex (classification).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">target_transforms</span><span class="p">(</span><span class="n">labels</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">labels</span><span class="p">[</span><span class="s2">&quot;age&quot;</span><span class="p">],</span> <span class="n">labels</span><span class="p">[</span><span class="s2">&quot;sex&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;female&quot;</span><span class="p">])</span>


<span class="n">train_xy_dataset</span> <span class="o">=</span> <a href="../generated/nidl.datasets.OpenBHB.html#nidl.datasets.OpenBHB" title="nidl.datasets.OpenBHB" class="sphx-glr-backref-module-nidl-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">OpenBHB</span></a><span class="p">(</span>
    <span class="n">data_dir</span><span class="p">,</span>
    <span class="n">modality</span><span class="o">=</span><span class="s2">&quot;vbm_roi&quot;</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;age&quot;</span><span class="p">,</span> <span class="s2">&quot;sex&quot;</span><span class="p">],</span>
    <span class="n">transforms</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
    <span class="n">target_transforms</span><span class="o">=</span><span class="n">target_transforms</span><span class="p">,</span>
    <span class="n">streaming</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">test_xy_dataset</span> <span class="o">=</span> <a href="../generated/nidl.datasets.OpenBHB.html#nidl.datasets.OpenBHB" title="nidl.datasets.OpenBHB" class="sphx-glr-backref-module-nidl-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">OpenBHB</span></a><span class="p">(</span>
    <span class="n">data_dir</span><span class="p">,</span>
    <span class="n">modality</span><span class="o">=</span><span class="s2">&quot;vbm_roi&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;age&quot;</span><span class="p">,</span> <span class="s2">&quot;sex&quot;</span><span class="p">],</span>
    <span class="n">transforms</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
    <span class="n">target_transforms</span><span class="o">=</span><span class="n">target_transforms</span><span class="p">,</span>
    <span class="n">streaming</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>To perform contrastive learning, we will use random masking and Gaussian
noise as data augmentations. These are well suited for tabular data.
We will train a <strong>y-Aware Contrastive Learning</strong> model on these data, using
<strong>age as auxiliary variable</strong>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">mask_prob</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">noise_std</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">contrast_transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
        <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">mask_prob</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="o">*</span> <span class="n">x</span><span class="p">,</span>  <span class="c1"># random masking</span>
        <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span>
        <span class="o">+</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">noise_std</span>
        <span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>  <span class="c1"># random Gaussian noise</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">ssl_dataset</span> <span class="o">=</span> <a href="../generated/nidl.datasets.OpenBHB.html#nidl.datasets.OpenBHB" title="nidl.datasets.OpenBHB" class="sphx-glr-backref-module-nidl-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">OpenBHB</span></a><span class="p">(</span>
    <span class="n">data_dir</span><span class="p">,</span>
    <span class="n">modality</span><span class="o">=</span><span class="s2">&quot;vbm_roi&quot;</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">&quot;age&quot;</span><span class="p">,</span>
    <span class="n">transforms</span><span class="o">=</span><a href="../generated/nidl.transforms.MultiViewsTransform.html#nidl.transforms.MultiViewsTransform" title="nidl.transforms.MultiViewsTransform" class="sphx-glr-backref-module-nidl-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">MultiViewsTransform</span></a><span class="p">(</span><span class="n">contrast_transforms</span><span class="p">,</span> <span class="n">n_views</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">test_ssl_dataset</span> <span class="o">=</span> <a href="../generated/nidl.datasets.OpenBHB.html#nidl.datasets.OpenBHB" title="nidl.datasets.OpenBHB" class="sphx-glr-backref-module-nidl-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">OpenBHB</span></a><span class="p">(</span>
    <span class="n">data_dir</span><span class="p">,</span>
    <span class="n">modality</span><span class="o">=</span><span class="s2">&quot;vbm_roi&quot;</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">&quot;age&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">,</span>
    <span class="n">transforms</span><span class="o">=</span><a href="../generated/nidl.transforms.MultiViewsTransform.html#nidl.transforms.MultiViewsTransform" title="nidl.transforms.MultiViewsTransform" class="sphx-glr-backref-module-nidl-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">MultiViewsTransform</span></a><span class="p">(</span><span class="n">contrast_transforms</span><span class="p">,</span> <span class="n">n_views</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
<p>As before, we create the data loaders for training and testing the models.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">train_xy_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">train_xy_dataset</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">test_xy_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">test_xy_dataset</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">train_ssl_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">ssl_dataset</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">test_ssl_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">test_ssl_dataset</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="y-aware-cl-training-with-multitask-probing-callback">
<h2 style='border-bottom: 1px solid #d3dbd5'>y-Aware CL training with multitask probing callback<a class="headerlink" href="#y-aware-cl-training-with-multitask-probing-callback" title="Link to this heading">¶</a></h2>
<p>We can now create the multitask probing callback that will train a ridge
regression on age and a logistic regression classifier on sex. The probing
is performed every epoch on the training and test sets. The metrics are
logged to TensorBoard by default.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">callback</span> <span class="o">=</span> <a href="../generated/nidl.callbacks.multitask_probing.MultitaskModelProbing.html#nidl.callbacks.multitask_probing.MultitaskModelProbing" title="nidl.callbacks.multitask_probing.MultitaskModelProbing" class="sphx-glr-backref-module-nidl-callbacks-multitask_probing sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">MultitaskModelProbing</span></a><span class="p">(</span>
    <span class="n">train_xy_loader</span><span class="p">,</span>
    <span class="n">test_xy_loader</span><span class="p">,</span>
    <span class="n">probes</span><span class="o">=</span><span class="p">[</span><span class="n">Ridge</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">)],</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Since we work with tabular data, we can use a simple MLP as encoder for
y-Aware Contrastive Learning. The input dimension is 284 and we compress the
data to a 32-d latent space.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">encoder</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">284</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="n">latent_size</span><span class="p">])</span>
</pre></div>
</div>
<p>We can now create the y-Aware Contrastive Learning model with the MLP encoder
and the multitask probing callback. We limit the training to 10 epochs for
the sake of time and we use a small bandwidth for the Gaussian kernel in the
y-Aware model compared to the variance of the age in OpenBHB (sigma=4).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">sigma</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">model</span> <span class="o">=</span> <a href="../generated/nidl.estimators.ssl.YAwareContrastiveLearning.html#nidl.estimators.ssl.YAwareContrastiveLearning" title="nidl.estimators.ssl.YAwareContrastiveLearning" class="sphx-glr-backref-module-nidl-estimators-ssl sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">YAwareContrastiveLearning</span></a><span class="p">(</span>
    <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span>
    <span class="n">projection_head_kwargs</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;input_dim&quot;</span><span class="p">:</span> <span class="n">latent_size</span><span class="p">,</span>
        <span class="s2">&quot;hidden_dim&quot;</span><span class="p">:</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">latent_size</span><span class="p">,</span>
        <span class="s2">&quot;output_dim&quot;</span><span class="p">:</span> <span class="n">latent_size</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="n">bandwidth</span><span class="o">=</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
    <span class="n">enable_checkpointing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="n">callback</span><span class="p">,</span>  <span class="c1"># &lt;-- add callback to monitor the training</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_ssl_loader</span><span class="p">,</span> <span class="n">test_ssl_loader</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="visualization-of-the-classification-and-regression-metrics-during-training">
<h2 style='border-bottom: 1px solid #d3dbd5'>Visualization of the classification and regression metrics during training<a class="headerlink" href="#visualization-of-the-classification-and-regression-metrics-during-training" title="Link to this heading">¶</a></h2>
<p>After training, we can visualize the classification and regression metrics
logged by the multitask probing using TensorBoard. The logged metrics are
stored in the <cite>lightning_logs</cite> folder by default. They contain the R2 score
(coefficient of determination), the explained variance (EVar), the Pearson
Correlation Coefficient (PCC) for age regression and the accuracy, balanced
accuracy, F1-score (weighted and macro), precision (macro) and recall (macro)
for sex classification.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_last_log_version</span><span class="p">(</span><span class="n">logs_dir</span><span class="o">=</span><span class="s2">&quot;lightning_logs&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return the last Lightning log version as an integer.&quot;&quot;&quot;</span>
    <span class="n">versions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">logs_dir</span><span class="p">):</span>
        <span class="n">match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;version_(\d+)&quot;</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">match</span><span class="p">:</span>
            <span class="n">versions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span>
    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">versions</span><span class="p">)</span> <span class="k">if</span> <span class="n">versions</span> <span class="k">else</span> <span class="kc">None</span>


<span class="n">log_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;lightning_logs/version_</span><span class="si">{</span><span class="n">get_last_log_version</span><span class="p">()</span><span class="si">}</span><span class="s2">/&quot;</span>

<span class="c1"># Reload the log file</span>
<span class="n">ea</span> <span class="o">=</span> <span class="n">event_accumulator</span><span class="o">.</span><span class="n">EventAccumulator</span><span class="p">(</span><span class="n">log_dir</span><span class="p">)</span>
<span class="n">ea</span><span class="o">.</span><span class="n">Reload</span><span class="p">()</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;task0/R2&quot;</span><span class="p">,</span>
    <span class="s2">&quot;task0/PCC&quot;</span><span class="p">,</span>  <span class="c1"># Pearson Correlaction Coefficient</span>
    <span class="s2">&quot;task0/EVar&quot;</span><span class="p">,</span>
    <span class="s2">&quot;task1/accuracy&quot;</span><span class="p">,</span>
    <span class="s2">&quot;task1/balanced_accuracy&quot;</span><span class="p">,</span>
    <span class="s2">&quot;task1/f1_macro&quot;</span><span class="p">,</span>
    <span class="s2">&quot;task1/precision_macro&quot;</span><span class="p">,</span>
    <span class="s2">&quot;task1/recall_macro&quot;</span><span class="p">,</span>
    <span class="s2">&quot;task1/f1_weighted&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="c1"># fetch all events</span>
<span class="n">scalars</span> <span class="o">=</span> <span class="p">{</span><span class="n">m</span><span class="p">:</span> <span class="n">ea</span><span class="o">.</span><span class="n">Scalars</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">}</span>
</pre></div>
</div>
<p>Once all the metrics are loaded, we plot them as the number of training steps
increases. We create two subplots, one for each task (age regression and sex
classification).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">plot_task</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">task_prefix</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
    <span class="n">task_metrics</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">metrics</span> <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">task_prefix</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">task_metrics</span><span class="p">:</span>
        <span class="n">steps</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">step</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">scalars</span><span class="p">[</span><span class="n">m</span><span class="p">]]</span>
        <span class="n">values</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">value</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">scalars</span><span class="p">[</span><span class="n">m</span><span class="p">]]</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Step&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Metric Value&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>


<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plot_task</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;task0&quot;</span><span class="p">,</span> <span class="s2">&quot;Task 0: Age Regression&quot;</span><span class="p">)</span>
<span class="n">plot_task</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;task1&quot;</span><span class="p">,</span> <span class="s2">&quot;Task 1: Sex Classification&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="conclusions">
<h2 style='border-bottom: 1px solid #d3dbd5'>Conclusions<a class="headerlink" href="#conclusions" title="Link to this heading">¶</a></h2>
<p>In this notebook, we have shown how to use the model probing callbacks
available in NIDL to monitor the evolution of the data representation
during training of embedding models such as SimCLR and y-Aware Contrastive
Learning. We have seen how to use the <cite>ClassificationProbingCallback</cite> for
single-task probing and the <cite>MultitaskModelProbing</cite> for multi-task probing.
These callbacks allow to train standard machine learning models (e.g.
logistic regression, ridge regression, SVM) on the learned representation
at regular intervals during training and log the relevant metrics to
TensorBoard. This provides insights on what concepts are being learned by
the model and how the representation evolves to become more suitable for
downstream tasks.</p>
<p><strong>Estimated memory usage:</strong>  0 MB</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-gallery-model-probing-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/cbc2e7cdaa07c077bdac94dd974459a9/model_probing.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">model_probing.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/cebdbf68b0a67f82c3d359da059255eb/model_probing.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">model_probing.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/2ec027de8efeaccc9b255743bf412638/model_probing.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">model_probing.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>

                    </div>
                <div class="spacer"></div>
		        
		        <!-- Footer -->
		        <div class="section-6-container section-container section-container-image-bg" id="section-6">
			        <div class="container">
			            <div class="row">
		                    <div class="col-md-5 offset-md-1 section-6-box wow fadeInDown">
                                <div class="section-6-title">
		                    	    <p>Follow us</p>
                                </div>
		                    	<div class="section-6-social">
			                    	<a href="https://www.facebook.com/pages/NeuroSpin/171075046414933"><i class="fab fa-facebook-f"></i></a>
									<a href="https://www.youtube.com/CEASaclay"><i class="fab fa-youtube"></i></a>
									<a href="https://twitter.com/neurospin_91"><i class="fab fa-twitter"></i></a>
									<a href="https://gaia.neurospin.fr"><i class="fa fa-link"></i></a>
                                    <p>&copy; 2025, 
nidl developers
 <antoine.grigis@cea.fr></p>
		                    	</div>
		                    </div>
			            </div>
			        </div>
                </div>
	        
	        </div>
	        <!-- End content -->
        
        </div>
        <!-- End wrapper -->

        <!-- Javascript -->
		<script src="../_static/js/jquery-3.3.1.min.js"></script>
		<script src="../_static/js/jquery-migrate-3.0.0.min.js"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
		<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
        <script src="../_static/js/jquery.backstretch.min.js"></script>
        <script src="../_static/js/wow.min.js"></script>
        <script src="../_static/js/jquery.waypoints.min.js"></script>
        <script src="../_static/js/jquery.mCustomScrollbar.concat.min.js"></script>
        <script src="../_static/js/scripts.js"></script>
        <script src="../_static/js/jquery.mosaic.js"></script>
        <script src="../_static/js/search.js"></script>
        <script type="text/javascript">
	        $('.top-content').backstretch("../_static/img/backgrounds/banner1.png");
            $('.section-6-container').backstretch("../_static/img/backgrounds/footer1.png");
        </script>

    </body>

</html>