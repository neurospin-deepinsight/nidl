{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCLR Example with MNIST\n",
    "\n",
    "This notebook demonstrates how to use the SimCLR estimator from the nidl library to train a small encoder on the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "SimCLR (Simple Framework for Contrastive Learning of Visual Representations) is a self-supervised learning framework that learns useful features without labels. It works by making different augmented views of the same image close in a representation space, while pushing apart representations of different images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from nidl.estimators.ssl import SimCLR\n",
    "from nidl.transforms import MultiViewsTransform\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.models import googlenet\n",
    "from torchvision.transforms import Compose, RandomHorizontalFlip, GaussianBlur, ToTensor, Normalize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "contrast_transforms = transforms.Compose(\n",
    "    [   transforms.RandomHorizontalFlip(),\n",
    "        transforms.GaussianBlur(kernel_size=5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = MNIST(root='./data', train=True, download=True,\n",
    "                      transform=MultiViewsTransform(contrast_transforms,\n",
    "                                                        n_views=2))\n",
    "indices = np.random.choice(np.arange(len(train_dataset)),\n",
    "                           size=10000)\n",
    "train_indices = indices[:9000]\n",
    "val_indices = indices[9000:]\n",
    "val_dataset = Subset(train_dataset, indices=val_indices)\n",
    "train_dataset = Subset(train_dataset, indices=train_indices)\n",
    "test_dataset = MNIST(root='./data', train=False, download=True,\n",
    "                     transform=transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the encoder (GoogLeNet)\n",
    "class GoogLeNetEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = googlenet(weights=None)\n",
    "        self.model.fc = nn.Identity()  # Remove the final fully connected layer\n",
    "        #self.latent_size = 1024  # Set the latent size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize the encoder\n",
    "encoder = GoogLeNetEncoder()\n",
    "\n",
    "# Define the SimCLR model\n",
    "simclr = SimCLR(\n",
    "    encoder=encoder,\n",
    "    projection_head_kwargs={\n",
    "        \"input_dim\": latent_size,\n",
    "        \"hidden_dim\": 2 * latent_size,\n",
    "        \"output_dim\": latent_size,\n",
    "    },\n",
    "    lr=1e-4,\n",
    "    temperature=0.1,\n",
    "    weight_decay=0.001,\n",
    "    max_epochs=10,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4, drop_last=False)\n",
    "\n",
    "# Fit\n",
    "simclr.fit(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "simclr.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        V1, V2 = batch\n",
    "        outputs = simclr.validation_step((V1, V2), 0)\n",
    "        test_loss += outputs['loss'].item()\n",
    "test_loss /= len(val_loader)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
