<!doctype html>
<html lang="en">

    <head>

		<!-- Required meta tags -->
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

        <title>nidl</title>
        
        <!-- CSS -->
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500&display=swap">
		<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
        <link rel="stylesheet" href="../_static/css/jquery.mCustomScrollbar.min.css">
        <link rel="stylesheet" href="../_static/css/animate.css">
        <link rel="stylesheet" href="../_static/css/style.css">
        <link rel="stylesheet" href="../_static/css/jquery.mosaic.css">
        <link rel="stylesheet" href="../_static/sg_gallery.css">
        <link rel="stylesheet" href="../_static/css/media-queries.css">
        <link rel="stylesheet" href="../_static/css/pygment.css">

        <!-- Favicon and touch icons -->
        <link rel="shortcut icon" href="../_static/ico/favicon.png">
        <link rel="apple-touch-icon-precomposed" sizes="144x144" href="../_static/ico/apple-touch-icon-144-precomposed.png">
        <link rel="apple-touch-icon-precomposed" sizes="114x114" href="../_static/ico/apple-touch-icon-114-precomposed.png">
        <link rel="apple-touch-icon-precomposed" sizes="72x72" href="../_static/ico/apple-touch-icon-72-precomposed.png">
        <link rel="apple-touch-icon-precomposed" href="../_static/ico/apple-touch-icon-57-precomposed.png">

    </head>

    <body>

		<!-- Wrapper -->
    	<div class="wrapper">

			<!-- Sidebar -->
			<nav class="sidebar">
				
				<!-- close sidebar menu -->
				<div class="dismiss">
					<i class="fas fa-arrow-left"></i>
				</div>
				
				<!-- <div class="logo"">
					<h3><a href="../index.html">Sidebar Menu</a></h3>
				</div> -->

                <!-- info setup -->
                    <p class="doc-version">
                        This documentation is for nidl <strong>version 0.0.0</strong>
                    </p>
                <p class="citing">
                    If you use the software, please do not hesitate to 
                    <a &mdash; <a href="https://github.com/neurospin-deepinsight/nidl">
                    Report a Bug</a>.
                </p>
				
                <!-- links -->
                
                
                    
                
				<ul class="list-unstyled menu-elements">
					<li class="active">
						<a href="../index.html"><i class="fas fa-home"></i> Home</a>
					</li>
					<li>
						<a href="installation.html"><i class="fas fa-cog"></i> Installation</a>
					</li>
					<li>
						<a href="../auto_gallery/index.html"><i class="fas fa-eye"></i> Gallery</a>
					</li>
					<li>
						<a href="documentation.html"><i class="fas fa-pencil-alt"></i> API documentation</a>
					</li>
					<li>
						<a href="search.html"><i class="fas fa-search"></i> Search</a>
					</li>
					<!-- <li>
						<a href="https://github.com/AGrigis/pysphinxdoc"><i class="fas fa-external-link-alt"></i> PYSPHINXDOC</a>
					</li> -->
					<!-- <li>
						<a href="#otherSections" data-toggle="collapse" aria-expanded="false" class="dropdown-toggle" role="button" aria-controls="otherSections">
							<i class="fas fa-sync"></i>Sections Shortcuts
						</a>
						<ul class="collapse list-unstyled" id="otherSections">
                            <li>LINKS</li><li><a href='https://github.com/neurospin-deepinsight/surfify'>surfify</a></li>
                            
                                
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                
                                
                                    <li>SECTIONS</li>
                                    
						                <li> <a href='#nidl.estimators.autoencoders.VAE.configure_optimizers'>Vae.configure_optimizers()</a> </li>                                    
                                    
						                <li> <a href='#nidl.estimators.autoencoders.VAE.forward'>Vae.forward()</a> </li>                                    
                                    
						                <li> <a href='#nidl.estimators.autoencoders.VAE.sample'>Vae.sample()</a> </li>                                    
                                    
						                <li> <a href='#nidl.estimators.autoencoders.VAE.training_step'>Vae.training_step()</a> </li>                                    
                                    
						                <li> <a href='#nidl.estimators.autoencoders.VAE.transform_step'>Vae.transform_step()</a> </li>                                    
                                    
						                <li> <a href='#nidl.estimators.autoencoders.VAE.validation_step'>Vae.validation_step()</a> </li>                                    
                                    
                                
                            
                            <li>API</li>
                            <li><a href="nidl.html">nidl</a></li><li><a href="nidl.callbacks.html">nidl.callbacks</a></li><li><a href="nidl.datasets.html">nidl.datasets</a></li><li><a href="nidl.estimators.html">nidl.estimators</a></li><li><a href="nidl.estimators.autoencoders.html">nidl.estimators.autoencoders</a></li><li><a href="nidl.estimators.linear.html">nidl.estimators.linear</a></li><li><a href="nidl.estimators.ssl.html">nidl.estimators.ssl</a></li><li><a href="nidl.estimators.ssl.utils.html">nidl.estimators.ssl.utils</a></li><li><a href="nidl.losses.html">nidl.losses</a></li><li><a href="nidl.metrics.html">nidl.metrics</a></li><li><a href="nidl.utils.html">nidl.utils</a></li><li><a href="nidl.volume.html">nidl.volume</a></li><li><a href="nidl.volume.backbones.html">nidl.volume.backbones</a></li><li><a href="nidl.volume.transforms.html">nidl.volume.transforms</a></li><li><a href="nidl.volume.transforms.augmentation.html">nidl.volume.transforms.augmentation</a></li><li><a href="nidl.volume.transforms.augmentation.intensity.html">nidl.volume.transforms.augmentation.intensity</a></li><li><a href="nidl.volume.transforms.augmentation.spatial.html">nidl.volume.transforms.augmentation.spatial</a></li><li><a href="nidl.volume.transforms.preprocessing.html">nidl.volume.transforms.preprocessing</a></li><li><a href="nidl.volume.transforms.preprocessing.intensity.html">nidl.volume.transforms.preprocessing.intensity</a></li><li><a href="nidl.volume.transforms.preprocessing.spatial.html">nidl.volume.transforms.preprocessing.spatial</a></li><li><a href="surfify.html">surfify</a></li><li><a href="surfify.augmentation.html">surfify.augmentation</a></li><li><a href="surfify.datasets.html">surfify.datasets</a></li><li><a href="surfify.losses.html">surfify.losses</a></li><li><a href="surfify.models.html">surfify.models</a></li><li><a href="surfify.nn.html">surfify.nn</a></li><li><a href="surfify.plotting.html">surfify.plotting</a></li><li><a href="surfify.utils.html">surfify.utils</a></li>
						</ul>
					</li> -->
				</ul>
				
                <!-- go top page -->
				<!-- <div class="to-top">
					<a class="btn btn-primary btn-customized-3" href="#" role="button">
	                    <i class="fas fa-arrow-up"></i> Top
	                </a>
				</div> -->
			
                <!-- change color -->
				<!-- <div class="dark-light-buttons">
					<a class="btn btn-primary btn-customized-4 btn-customized-dark" href="#" role="button">Dark</a>
					<a class="btn btn-primary btn-customized-4 btn-customized-light" href="#" role="button">Light</a>
				</div> -->
			
			</nav>
			<!-- End sidebar -->
			
			<!-- Dark overlay -->
    		<div class="overlay"></div>

			<!-- Content -->
			<div class="content">
			
				<!-- open sidebar menu -->
				<a class="btn btn-primary btn-customized open-menu" href="#" role="button">
                    <i class="fas fa-align-left"></i> <span>Menu</span>
                </a>

		        <!-- Top content -->
		        <div class="top-content section-container" id="top-content">
			        <div class="container">
			            <div class="row">
                            <div class="col-md-3 section-5-box banner-logo">
                                <img alt="Logo" src="../_static/nidl.png">
                            </div>
			                <div class="col-md-7 section-5-box">
			                	<h1 class="wow fadeIn">    <p>Deep learning for NeuroImaging in Python.</p></h1>
			                </div>
			            </div>
			        </div>
		        </div>
                    
                    <div class="document">
                        <div class="admonition note">
<p class="admonition-title">Note</p>
<p>This page is a reference documentation. It only explains the class signature, and not how to use it. Please refer to the <a class="reference internal" href="../auto_gallery/index.html#sphx-glr-auto-gallery"><span class="std std-ref">gallery</span></a> for the big picture.</p>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="nidl.estimators.autoencoders.VAE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nidl.estimators.autoencoders.</span></span><span class="sig-name descname"><span class="pre">VAE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_out_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_dist</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'normal'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stochastic_transform</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nidl/estimators/autoencoders/vae.html#VAE"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nidl.estimators.autoencoders.VAE" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="nidl.estimators.base.TransformerMixin.html#nidl.estimators.base.TransformerMixin" title="nidl.estimators.base.TransformerMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">TransformerMixin</span></code></a>, <a class="reference internal" href="nidl.estimators.base.BaseEstimator.html#nidl.estimators.base.BaseEstimator" title="nidl.estimators.base.BaseEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseEstimator</span></code></a></p>
<p>Variational Auto-Encoder (VAE) <a class="reference internal" href="#r3" id="id1"><span>[R3]</span></a> <a class="reference internal" href="#r4" id="id2"><span>[R4]</span></a>.</p>
<p>See Also: <code class="xref py py-class docutils literal notranslate"><span class="pre">BetaVAELoss</span></code></p>
<p>A VAE is a probabilistic generative model that learns a latent
representation of input data and reconstructs it. It implements <cite>fit</cite> and
<cite>transform</cite> methods to respectively train the model and obtain the latent
embeddings.</p>
<p>The VAE consists of three main components:</p>
<ul class="simple">
<li><p>Encoder: maps input <cite>x</cite> to latent mean <img class="math" src="../_images/math/4a3598141469c2555591e66606a1b86d4ec6dca9.png" alt="\mu"/> and log-variance
<img class="math" src="../_images/math/4484cd605abcf9dbd30eb84030e092dcb935e3d0.png" alt="\log \sigma^2"/></p></li>
<li><p>Reparameterization trick: samples latent vector
<img class="math" src="../_images/math/041db1b0dec86498ebef319ac5f1d55b2fcdb80a.png" alt="z \sim q(z | x) = \mathcal{N}(\mu, \sigma^2 I)"/></p></li>
<li><p>Decoder: reconstructs input <img class="math" src="../_images/math/a787de15b9b3e025c3790414ce6a3bcc427b1715.png" alt="\hat{x}"/> from latent vector <img class="math" src="../_images/math/8d051150f8669295ecdbe92367941012175a824d.png" alt="z"/></p></li>
</ul>
<p>The model is trained by minimizing the sum of two components:</p>
<ul>
<li><p><strong>Reconstruction loss</strong>: Measures how well the decoder reconstructs the
input.</p>
<blockquote>
<div><ul class="simple">
<li><p>For binary data: Binary Cross-Entropy (BCE) loss</p></li>
<li><p>For continuous data: Mean Squared Error (MSE) loss</p></li>
</ul>
<div class="math">
<p><img src="../_images/math/28fe2cb97c84b5d2f91bb831a3c943c9c784c0ba.png" alt="\mathcal{L}_{recon} = - \mathbb{E}_{q(z|x)} [ \log p(x|z) ]"/></p>
</div></div></blockquote>
</li>
<li><p><strong>KL Divergence loss</strong>: Encourages the latent distribution <img class="math" src="../_images/math/a03cf64d6f624661b1339c8c5b8ad88a17dc73b6.png" alt="q(z|x)"/>
to be close to the prior <img class="math" src="../_images/math/7a98e5d8f56c5f45af1275d2f479bfd72b0780e9.png" alt="p(z) = \mathcal{N}(0, I)"/>.</p>
<blockquote>
<div><div class="math">
<p><img src="../_images/math/e3901fb5bb119b54c4690dca17a0cf55f58268b2.png" alt="\mathcal{L}_{KL} = D_{KL}(q(z|x) | p(z))"/></p>
</div></div></blockquote>
</li>
</ul>
<p>The total loss is a weighted sum of these two components:</p>
<div class="math">
<p><img src="../_images/math/bd94bb8e436797cc96e72a090838730e5dfb92e8.png" alt="\mathcal{L}_{total} = \mathcal{L}_{recon} + \beta \mathcal{L}_{KL}"/></p>
</div><dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>encoder</strong> : class:<cite>~torch.nn.Module</cite></p>
<blockquote>
<div><p>The encoder mapping input <code class="docutils literal notranslate"><span class="pre">x</span></code> to the representation space. The mean
<img class="math" src="../_images/math/4a3598141469c2555591e66606a1b86d4ec6dca9.png" alt="\mu"/> and log-variance  <img class="math" src="../_images/math/4484cd605abcf9dbd30eb84030e092dcb935e3d0.png" alt="\log \sigma^2"/> layers
are automatically added according to the <code class="docutils literal notranslate"><span class="pre">latent_dim</span></code> parameter.</p>
</div></blockquote>
<p><strong>decoder</strong> : class:<cite>~torch.nn.Module</cite></p>
<blockquote>
<div><p>The decoder backbone outputting <img class="math" src="../_images/math/773c491923c4fb213d6888e45d4872568d3d3579.png" alt="p(x | z)"/> as a
<cite>torch.distributions</cite> or a <cite>torch.Tensor</cite> representing the mean of a
Normal (default) or Laplace distribution.</p>
</div></blockquote>
<p><strong>encoder_out_dim</strong> : int</p>
<blockquote>
<div><p>The output size of the encoder.</p>
</div></blockquote>
<p><strong>latent_dim</strong> : int</p>
<blockquote>
<div><p>The number of latent dimensions (which is the size of the mean and
variance of the posterior distribution).</p>
</div></blockquote>
<p><strong>beta</strong> : float, default=1.</p>
<blockquote>
<div><p>Scaling factor for Kullback-Leibler distance (beta-VAE).</p>
</div></blockquote>
<p><strong>default_dist</strong> : str, default=”normal”</p>
<blockquote>
<div><p>Default decoder distribution. It defines the reconstruction loss
(L2 for Normal, L1 for Laplace, cross-entropy for Bernoulli).</p>
</div></blockquote>
<p><strong>stochastic_transform</strong> : bool, default=True</p>
<blockquote>
<div><p>If True (default), the transformed data are obtained by sampling
according to the posterior distribution <img class="math" src="../_images/math/02e4bf7c6ea69ab22c2505086bd00c7c75baca71.png" alt="q(z | x)"/>.If False,
the mean of the posterior distribution is returned.</p>
</div></blockquote>
<p><strong>lr</strong> : float</p>
<blockquote>
<div><p>the learning rate.</p>
</div></blockquote>
<p><strong>weight_decay</strong> : float</p>
<blockquote>
<div><p>the Adam optimizer weight decay parameter.</p>
</div></blockquote>
<p><strong>random_state</strong> : int, default=None</p>
<blockquote>
<div><p>setting a seed for reproducibility.</p>
</div></blockquote>
<p><strong>kwargs</strong> : dict</p>
<blockquote>
<div><p>trainer parameters.</p>
</div></blockquote>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>R3<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id3">2</a>)</span>
<p>Diederik P. Kingma, Max Welling, “Auto-Encoding Variational Bayes”,
ICLR 2014.</p>
</div>
<div class="citation" id="r4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>R4<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id2">1</a>,<a role="doc-backlink" href="#id4">2</a>)</span>
<p>Irina Higgins et al., “beta-VAE: Learning Basic Visual Concepts with
a Constrained Variational Framework”, ICLR 2017.</p>
</div>
</div>
<p class="rubric">Attributes</p>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>encoder</p></td>
<td><p>(<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>) The encoder network.</p></td>
</tr>
<tr class="row-even"><td><p>decoder</p></td>
<td><p>(<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>) The decoder network.</p></td>
</tr>
<tr class="row-odd"><td><p>fc_mu</p></td>
<td><p>(<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>) The linear layer mapping the encoder output to the mean <img class="math" src="../_images/math/4a3598141469c2555591e66606a1b86d4ec6dca9.png" alt="\mu"/> of the posterior distribution.</p></td>
</tr>
<tr class="row-even"><td><p>fc_logvar</p></td>
<td><p>(<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>) The linear layer mapping the encoder output to the log-variance <img class="math" src="../_images/math/4484cd605abcf9dbd30eb84030e092dcb935e3d0.png" alt="\log \sigma^2"/> of the posterior distribution.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="nidl.estimators.autoencoders.VAE.configure_optimizers">
<span class="sig-name descname"><span class="pre">configure_optimizers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nidl/estimators/autoencoders/vae.html#VAE.configure_optimizers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nidl.estimators.autoencoders.VAE.configure_optimizers" title="Link to this definition">¶</a></dt>
<dd><p>Declare an <code class="xref py py-class docutils literal notranslate"><span class="pre">AdamW</span></code> optimizer.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nidl.estimators.autoencoders.VAE.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/nidl/estimators/autoencoders/vae.html#VAE.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nidl.estimators.autoencoders.VAE.forward" title="Link to this definition">¶</a></dt>
<dd><p>Encode the input and sample from the posterior distribution q(z|x).</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> : torch.Tensor</p>
<blockquote>
<div><p>Input data given to the encoder.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>z</strong> : torch.Tensor, shape (batch_size, latent_dim)</p>
<blockquote>
<div><p>Latent vector sampled from the posterior distribution.</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nidl.estimators.autoencoders.VAE.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_samples</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nidl/estimators/autoencoders/vae.html#VAE.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nidl.estimators.autoencoders.VAE.sample" title="Link to this definition">¶</a></dt>
<dd><p>Generate <cite>n_samples</cite> by sampling from the latent space.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>nsamples</strong> : int</p>
<blockquote>
<div><p>Number of samples to generate.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>x</strong> : torch.Tensor</p>
<blockquote>
<div><p>Generated samples.</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nidl.estimators.autoencoders.VAE.training_step">
<span class="sig-name descname"><span class="pre">training_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nidl/estimators/autoencoders/vae.html#VAE.training_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nidl.estimators.autoencoders.VAE.training_step" title="Link to this definition">¶</a></dt>
<dd><p>Perform one training step and computes and logs training losses.</p>
<p>Three losses are logged: the beta-VAE loss (“loss”), the reconstruction
loss (“rec_loss”) and the KL divergence loss (“kl_loss”).</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> : torch.Tensor</p>
<blockquote>
<div><p>The input data given to the encoder.</p>
</div></blockquote>
<p><strong>batch_idx</strong> : int</p>
<blockquote>
<div><p>Ignored.</p>
</div></blockquote>
<p><strong>dataloader_idx</strong> : Optional[int], default=0</p>
<blockquote>
<div><p>Ignored.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>losses</strong> : dict</p>
<blockquote>
<div><p>Dictionary with “loss”, “rec_loss”, “kl_loss” as keys.</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nidl.estimators.autoencoders.VAE.transform_step">
<span class="sig-name descname"><span class="pre">transform_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nidl/estimators/autoencoders/vae.html#VAE.transform_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nidl.estimators.autoencoders.VAE.transform_step" title="Link to this definition">¶</a></dt>
<dd><p>Transform the input data to the latent space.</p>
<p>By default, the latent vector is obtained by sampling according to the
posterior distribution <img class="math" src="../_images/math/02e4bf7c6ea69ab22c2505086bd00c7c75baca71.png" alt="q(z | x)"/>. It is just the mean of the
distribution if <code class="docutils literal notranslate"><span class="pre">stochastic_transform</span></code> is False.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> : torch.Tensor</p>
<blockquote>
<div><p>The input data given to the encoder.</p>
</div></blockquote>
<p><strong>batch_idx</strong> : int</p>
<blockquote>
<div><p>Ignored.</p>
</div></blockquote>
<p><strong>dataloader_idx</strong> : Optional[int], default=0</p>
<blockquote>
<div><p>Ignored.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>z</strong> : torch.Tensor, shape (batch_size, latent_dim)</p>
<blockquote>
<div><p>The latent vector.</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nidl.estimators.autoencoders.VAE.validation_step">
<span class="sig-name descname"><span class="pre">validation_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nidl/estimators/autoencoders/vae.html#VAE.validation_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nidl.estimators.autoencoders.VAE.validation_step" title="Link to this definition">¶</a></dt>
<dd><p>Perform one validation step and computes and logs validation
losses.</p>
<p>Three losses are logged: the beta-VAE loss (“loss”), the reconstruction
loss (“rec_loss”) and the KL divergence loss (“kl_loss”).</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> : torch.Tensor</p>
<blockquote>
<div><p>The input data given to the encoder.</p>
</div></blockquote>
<p><strong>batch_idx</strong> : int</p>
<blockquote>
<div><p>Ignored.</p>
</div></blockquote>
<p><strong>dataloader_idx</strong> : Optional[int], default=0</p>
<blockquote>
<div><p>Ignored.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>losses</strong> : dict</p>
<blockquote>
<div><p>Dictionary with “loss”, “rec_loss”, “kl_loss” as keys.</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

</dd></dl>


                    </div>
                <div class="spacer"></div>
		        
		        <!-- Footer -->
		        <div class="section-6-container section-container section-container-image-bg" id="section-6">
			        <div class="container">
			            <div class="row">
		                    <div class="col-md-5 offset-md-1 section-6-box wow fadeInDown">
                                <div class="section-6-title">
		                    	    <p>Follow us</p>
                                </div>
		                    	<div class="section-6-social">
			                    	<a href="https://www.facebook.com/pages/NeuroSpin/171075046414933"><i class="fab fa-facebook-f"></i></a>
									<a href="https://www.youtube.com/CEASaclay"><i class="fab fa-youtube"></i></a>
									<a href="https://twitter.com/neurospin_91"><i class="fab fa-twitter"></i></a>
									<a href="https://gaia.neurospin.fr"><i class="fa fa-link"></i></a>
                                    <p>&copy; 2025, 
nidl developers
 <antoine.grigis@cea.fr></p>
		                    	</div>
		                    </div>
			            </div>
			        </div>
                </div>
	        
	        </div>
	        <!-- End content -->
        
        </div>
        <!-- End wrapper -->

        <!-- Javascript -->
		<script src="../_static/js/jquery-3.3.1.min.js"></script>
		<script src="../_static/js/jquery-migrate-3.0.0.min.js"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
		<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
        <script src="../_static/js/jquery.backstretch.min.js"></script>
        <script src="../_static/js/wow.min.js"></script>
        <script src="../_static/js/jquery.waypoints.min.js"></script>
        <script src="../_static/js/jquery.mCustomScrollbar.concat.min.js"></script>
        <script src="../_static/js/scripts.js"></script>
        <script src="../_static/js/jquery.mosaic.js"></script>
        <script src="../_static/js/search.js"></script>
        <script type="text/javascript">
	        $('.top-content').backstretch("../_static/img/backgrounds/banner1.png");
            $('.section-6-container').backstretch("../_static/img/backgrounds/footer1.png");
        </script>

    </body>

</html>