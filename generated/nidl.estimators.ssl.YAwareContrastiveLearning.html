<!doctype html>
<html lang="en">

    <head>

		<!-- Required meta tags -->
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

        <title>nidl</title>
        
        <!-- CSS -->
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500&display=swap">
		<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
        <link rel="stylesheet" href="../_static/css/jquery.mCustomScrollbar.min.css">
        <link rel="stylesheet" href="../_static/css/animate.css">
        <link rel="stylesheet" href="../_static/css/style.css">
        <link rel="stylesheet" href="../_static/css/jquery.mosaic.css">
        <link rel="stylesheet" href="../_static/sg_gallery.css">
        <link rel="stylesheet" href="../_static/css/media-queries.css">
        <link rel="stylesheet" href="../_static/css/pygment.css">

        <!-- Favicon and touch icons -->
        <link rel="shortcut icon" href="../_static/ico/favicon.png">
        <link rel="apple-touch-icon-precomposed" sizes="144x144" href="../_static/ico/apple-touch-icon-144-precomposed.png">
        <link rel="apple-touch-icon-precomposed" sizes="114x114" href="../_static/ico/apple-touch-icon-114-precomposed.png">
        <link rel="apple-touch-icon-precomposed" sizes="72x72" href="../_static/ico/apple-touch-icon-72-precomposed.png">
        <link rel="apple-touch-icon-precomposed" href="../_static/ico/apple-touch-icon-57-precomposed.png">

    </head>

    <body>

		<!-- Wrapper -->
    	<div class="wrapper">

			<!-- Sidebar -->
			<nav class="sidebar">
				
				<!-- close sidebar menu -->
				<div class="dismiss">
					<i class="fas fa-arrow-left"></i>
				</div>
				
				<!-- <div class="logo"">
					<h3><a href="../index.html">Sidebar Menu</a></h3>
				</div> -->

                <!-- info setup -->
                    <p class="doc-version">
                        This documentation is for nidl <strong>version 0.0.0</strong>
                    </p>
                <p class="citing">
                    If you use the software, please do not hesitate to 
                    <a &mdash; <a href="https://github.com/neurospin-deepinsight/nidl">
                    Report a Bug</a>.
                </p>
				
                <!-- links -->
                
                
                    
                
				<ul class="list-unstyled menu-elements">
					<li class="active">
						<a href="../index.html"><i class="fas fa-home"></i> Home</a>
					</li>
					<li>
						<a href="installation.html"><i class="fas fa-cog"></i> Installation</a>
					</li>
					<li>
						<a href="../auto_gallery/index.html"><i class="fas fa-eye"></i> Gallery</a>
					</li>
					<li>
						<a href="documentation.html"><i class="fas fa-pencil-alt"></i> API documentation</a>
					</li>
					<li>
						<a href="search.html"><i class="fas fa-search"></i> Search</a>
					</li>
					<!-- <li>
						<a href="https://github.com/AGrigis/pysphinxdoc"><i class="fas fa-external-link-alt"></i> PYSPHINXDOC</a>
					</li> -->
					<!-- <li>
						<a href="#otherSections" data-toggle="collapse" aria-expanded="false" class="dropdown-toggle" role="button" aria-controls="otherSections">
							<i class="fas fa-sync"></i>Sections Shortcuts
						</a>
						<ul class="collapse list-unstyled" id="otherSections">
                            <li>LINKS</li><li><a href='https://github.com/neurospin-deepinsight/surfify'>surfify</a></li>
                            
                                
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                
                                
                                    <li>SECTIONS</li>
                                    
						                <li> <a href='#nidl.estimators.ssl.YAwareContrastiveLearning.configure_optimizers'>Yawarecontrastivelearning.configure_optimizers()</a> </li>                                    
                                    
						                <li> <a href='#nidl.estimators.ssl.YAwareContrastiveLearning.parse_batch'>Yawarecontrastivelearning.parse_batch()</a> </li>                                    
                                    
						                <li> <a href='#nidl.estimators.ssl.YAwareContrastiveLearning.training_step'>Yawarecontrastivelearning.training_step()</a> </li>                                    
                                    
						                <li> <a href='#nidl.estimators.ssl.YAwareContrastiveLearning.transform_step'>Yawarecontrastivelearning.transform_step()</a> </li>                                    
                                    
						                <li> <a href='#nidl.estimators.ssl.YAwareContrastiveLearning.validation_step'>Yawarecontrastivelearning.validation_step()</a> </li>                                    
                                    
                                
                            
                            <li>API</li>
                            <li><a href="nidl.html">nidl</a></li><li><a href="nidl.callbacks.html">nidl.callbacks</a></li><li><a href="nidl.datasets.html">nidl.datasets</a></li><li><a href="nidl.estimators.html">nidl.estimators</a></li><li><a href="nidl.estimators.linear.html">nidl.estimators.linear</a></li><li><a href="nidl.estimators.ssl.html">nidl.estimators.ssl</a></li><li><a href="nidl.estimators.ssl.utils.html">nidl.estimators.ssl.utils</a></li><li><a href="nidl.losses.html">nidl.losses</a></li><li><a href="nidl.metrics.html">nidl.metrics</a></li><li><a href="nidl.transforms.html">nidl.transforms</a></li><li><a href="nidl.utils.html">nidl.utils</a></li><li><a href="nidl.volume.html">nidl.volume</a></li><li><a href="nidl.volume.backbones.html">nidl.volume.backbones</a></li><li><a href="surfify.html">surfify</a></li><li><a href="surfify.augmentation.html">surfify.augmentation</a></li><li><a href="surfify.datasets.html">surfify.datasets</a></li><li><a href="surfify.losses.html">surfify.losses</a></li><li><a href="surfify.models.html">surfify.models</a></li><li><a href="surfify.nn.html">surfify.nn</a></li><li><a href="surfify.plotting.html">surfify.plotting</a></li><li><a href="surfify.utils.html">surfify.utils</a></li>
						</ul>
					</li> -->
				</ul>
				
                <!-- go top page -->
				<!-- <div class="to-top">
					<a class="btn btn-primary btn-customized-3" href="#" role="button">
	                    <i class="fas fa-arrow-up"></i> Top
	                </a>
				</div> -->
			
                <!-- change color -->
				<!-- <div class="dark-light-buttons">
					<a class="btn btn-primary btn-customized-4 btn-customized-dark" href="#" role="button">Dark</a>
					<a class="btn btn-primary btn-customized-4 btn-customized-light" href="#" role="button">Light</a>
				</div> -->
			
			</nav>
			<!-- End sidebar -->
			
			<!-- Dark overlay -->
    		<div class="overlay"></div>

			<!-- Content -->
			<div class="content">
			
				<!-- open sidebar menu -->
				<a class="btn btn-primary btn-customized open-menu" href="#" role="button">
                    <i class="fas fa-align-left"></i> <span>Menu</span>
                </a>

		        <!-- Top content -->
		        <div class="top-content section-container" id="top-content">
			        <div class="container">
			            <div class="row">
                            <div class="col-md-3 section-5-box banner-logo">
                                <img alt="Logo" src="../_static/nidl.png">
                            </div>
			                <div class="col-md-7 section-5-box">
			                	<h1 class="wow fadeIn">    <p>Deep learning for NeuroImaging in Python.</p></h1>
			                </div>
			            </div>
			        </div>
		        </div>
                    
                    <div class="document">
                        <div class="admonition note">
<p class="admonition-title">Note</p>
<p>This page is a reference documentation. It only explains the class signature, and not how to use it. Please refer to the <a class="reference internal" href="../auto_gallery/index.html#sphx-glr-auto-gallery"><span class="std std-ref">gallery</span></a> for the big picture.</p>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="nidl.estimators.ssl.YAwareContrastiveLearning">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nidl.estimators.ssl.</span></span><span class="sig-name descname"><span class="pre">YAwareContrastiveLearning</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">encoder:</span> <span class="pre">~torch.nn.modules.module.Module</span> <span class="pre">|</span> <span class="pre">type[~torch.nn.modules.module.Module],</span> <span class="pre">encoder_kwargs:</span> <span class="pre">dict[str,</span> <span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">projection_head:</span> <span class="pre">~torch.nn.modules.module.Module</span> <span class="pre">|</span> <span class="pre">type[~torch.nn.modules.module.Module]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">&lt;class</span> <span class="pre">'nidl.estimators.ssl.utils.projection_heads.YAwareProjectionHead'&gt;,</span> <span class="pre">projection_head_kwargs:</span> <span class="pre">dict[str,</span> <span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">temperature:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">0.1,</span> <span class="pre">kernel:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'gaussian',</span> <span class="pre">bandwidth:</span> <span class="pre">float</span> <span class="pre">|</span> <span class="pre">list[float]</span> <span class="pre">|</span> <span class="pre">~numpy.ndarray</span> <span class="pre">|</span> <span class="pre">~nidl.losses.yaware_infonce.KernelMetric</span> <span class="pre">=</span> <span class="pre">1.0,</span> <span class="pre">optimizer:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">~torch.optim.optimizer.Optimizer</span> <span class="pre">|</span> <span class="pre">type[~torch.optim.optimizer.Optimizer]</span> <span class="pre">=</span> <span class="pre">'adam',</span> <span class="pre">optimizer_kwargs:</span> <span class="pre">dict[str,</span> <span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">learning_rate:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">0.0001,</span> <span class="pre">lr_scheduler:</span> <span class="pre">~torch.optim.lr_scheduler.LRScheduler</span> <span class="pre">|</span> <span class="pre">~torch.optim.lr_scheduler.ReduceLROnPlateau</span> <span class="pre">|</span> <span class="pre">type[~torch.optim.lr_scheduler.LRScheduler</span> <span class="pre">|</span> <span class="pre">~torch.optim.lr_scheduler.ReduceLROnPlateau]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">lr_scheduler_kwargs:</span> <span class="pre">dict[str,</span> <span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">**kwargs:</span> <span class="pre">~typing.Any</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nidl/estimators/ssl/yaware.html#YAwareContrastiveLearning"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nidl.estimators.ssl.YAwareContrastiveLearning" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="nidl.estimators.base.TransformerMixin.html#nidl.estimators.base.TransformerMixin" title="nidl.estimators.base.TransformerMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">TransformerMixin</span></code></a>, <a class="reference internal" href="nidl.estimators.base.BaseEstimator.html#nidl.estimators.base.BaseEstimator" title="nidl.estimators.base.BaseEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseEstimator</span></code></a></p>
<p>y-Aware Contrastive Learning implementation [1]</p>
<p>y-Aware Contrastive Learning is a self-supervised learning framework for
learning visual representations with auxiliary variables. It leverages
contrastive learning by maximizing the agreement between differently
augmented views of images with similar auxiliary variables while minimizing
agreement between different images. The framework consists of:</p>
<ol class="arabic simple">
<li><p>Data Augmentation - Generates two augmented views of an image.</p></li>
<li><p>Kernel - Similarity function between auxiliary variables.</p></li>
<li><p>Encoder (Backbone Network) - Maps images to feature embeddings
(e.g., 3D-ResNet).</p></li>
<li><p>Projection Head - Maps features to a latent space for contrastive
loss optimization.</p></li>
<li><p>Contrastive Loss (y-Aware) - Encourages augmented views of
i) the same image and ii) images with close auxiliary variables
to be closer while pushing dissimilar ones apart.</p></li>
</ol>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>encoder</strong> : nn.Module or class</p>
<blockquote>
<div><p>Which deep architecture to use for encoding the input.
A PyTorch <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> is expected.
In general, the uninstantiated class should be passed, although
instantiated modules will also work.</p>
</div></blockquote>
<p><strong>encoder_kwargs</strong> : dict or None, default=None</p>
<blockquote>
<div><p>Options for building the encoder (depends on each architecture).
Examples:</p>
<ul class="simple">
<li><p>encoder=torchvision.ops.MLP, encoder_kwargs={“in_channels”: 10,
“hidden_channels”: [4, 3, 2]} builds an MLP with 3 hidden layers,
input dim 10, output dim 2.</p></li>
<li><p>encoder=nidl.volume.backbones.resnet3d.resnet18,
encoder_kwargs={“n_embedding”: 10} builds a ResNet-18 model with
10 output dimension.</p></li>
</ul>
<p>Ignored if <cite>encoder</cite> is instantiated.</p>
</div></blockquote>
<p><strong>projection_head</strong> : nn.Module or class or None, default=YAwareProjectionHead</p>
<blockquote>
<div><p>Which projection head to use for the model. If None, no projection head
is used and the encoder output is directly used for loss computation.
Otherwise, a <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> is expected. In general,
the uninstantiated class should be passed, although instantiated
modules will also work. By default, a 2-layer MLP with ReLU activation,
2048-d hidden units, and 128-d output dimensions is used.</p>
</div></blockquote>
<p><strong>projection_head_kwargs</strong> : dict or None, default=None</p>
<blockquote>
<div><p>Arguments for building the projection head. By default, input dimension
is 2048-d and output dimension is 128-d. These can be changed by
passing a dictionary with keys ‘input_dim’ and ‘output_dim’.
‘input_dim’ must be equal to the encoder’s output dimension.
Ignored if <cite>projection_head</cite> is instantiated.</p>
</div></blockquote>
<p><strong>temperature</strong> : float, default=0.1</p>
<blockquote>
<div><p>Temperature value in y-Aware InfoNCE loss. Small values imply more
uniformity between samples’ embeddings, whereas high values impose
clustered embedding more sensitive to augmentations.</p>
</div></blockquote>
<p><strong>kernel</strong> : {‘gaussian’, ‘epanechnikov’, ‘exponential’, ‘linear’, ‘cosine’},         default=”gaussian”</p>
<blockquote>
<div><p>Kernel used as a similarity function between auxiliary variables.</p>
</div></blockquote>
<p><strong>bandwidth</strong> : Union[float, int, List[float], array, KernelMetric],         default=1.0</p>
<blockquote>
<div><p>The method used to calculate the bandwidth (“sigma” in [1]) between
auxiliary variables:</p>
<ul class="simple">
<li><p>If <cite>bandwidth</cite> is a scalar (int or float), it sets the bandwidth to
a diagnonal matrix with equal values.</p></li>
<li><p>If <cite>bandwidth</cite> is a 1d array, it sets the bandwidth to a
diagonal matrix and it must be of size equal to the number of
features in <cite>y</cite>.</p></li>
<li><p>If bandwidth is a 2d array, it must be of shape
<cite>(n_features, n_features)</cite> where <cite>n_features</cite> is the number of
features in <cite>y</cite>.</p></li>
<li><p>If <cite>bandwidth</cite> is <code class="xref py py-class docutils literal notranslate"><span class="pre">KernelMetric</span></code>, it uses the <cite>pairwise</cite>
method to compute the similarity matrix between auxiliary variables.</p></li>
</ul>
</div></blockquote>
<p><strong>optimizer</strong> : {‘sgd’, ‘adam’, ‘adamW’} or torch.optim.Optimizer or type,         default=”adam”</p>
<blockquote>
<div><p>Optimizer for training the model. Can be:</p>
<ul>
<li><p>A string:</p>
<blockquote>
<div><ul class="simple">
<li><p>‘sgd’: Stochastic Gradient Descent (with optional momentum).</p></li>
<li><p>‘adam’: First-order gradient-based optimizer (default).</p></li>
<li><p>‘adamW’: Adam with decoupled weight decay regularization
(see “Decoupled Weight Decay Regularization”, Loshchilov and
Hutter, ICLR 2019).</p></li>
</ul>
</div></blockquote>
</li>
<li><p>An instance or subclass of <code class="docutils literal notranslate"><span class="pre">torch.optim.Optimizer</span></code>.</p></li>
</ul>
</div></blockquote>
<p><strong>optimizer_kwargs</strong> : dict or None, default=None</p>
<blockquote>
<div><p>Arguments for the optimizer (‘adam’ by default). By default:
{‘betas’: (0.9, 0.99), ‘weight_decay’: 5e-05} where ‘betas’ are the
exponential decay rates for first and second moment estimates.</p>
<p>Ignored if <cite>optimizer</cite> is instantiated.</p>
</div></blockquote>
<p><strong>learning_rate</strong> : float, default=1e-4</p>
<blockquote>
<div><p>Initial learning rate.</p>
</div></blockquote>
<p><strong>lr_scheduler</strong> : LRSchedulerPLType or class or None, default=None</p>
<blockquote>
<div><p>Learning rate scheduler to use.</p>
</div></blockquote>
<p><strong>lr_scheduler_kwargs</strong> : dict or None, default=None</p>
<blockquote>
<div><p>Additional keyword arguments for the scheduler.</p>
<p>Ignored if <cite>lr_scheduler</cite> is instantiated.</p>
</div></blockquote>
<p><strong>**kwargs</strong> : dict, optional</p>
<blockquote>
<div><p>Additional keyword arguments for the BaseEstimator class, such as
<cite>max_epochs</cite>, <cite>max_steps</cite>, <cite>num_sanity_val_steps</cite>,
<cite>check_val_every_n_epoch</cite>, <cite>callbacks</cite>, etc.</p>
</div></blockquote>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="simple">
<dt>[1] Contrastive Learning with Continuous Proxy Meta-Data for 3D MRI</dt><dd><p>Classification, Dufumier et al., MICCAI 2021</p>
</dd>
</dl>
<p class="rubric">Attributes</p>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>encoder</p></td>
<td><p>(torch.nn.Module) Deep neural network mapping input data to low-dimensional vectors.</p></td>
</tr>
<tr class="row-even"><td><p>projection_head</p></td>
<td><p>(torch.nn.Module) Maps encoder output to latent space for contrastive loss optimization.</p></td>
</tr>
<tr class="row-odd"><td><p>loss</p></td>
<td><p>(yAwareInfoNCE) The yAwareInfoNCE loss function used for training.</p></td>
</tr>
<tr class="row-even"><td><p>optimizer</p></td>
<td><p>(torch.optim.Optimizer) Optimizer used for training.</p></td>
</tr>
<tr class="row-odd"><td><p>lr_scheduler</p></td>
<td><p>(LRSchedulerPLType or None) Learning rate scheduler used for training.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="nidl.estimators.ssl.YAwareContrastiveLearning.configure_optimizers">
<span class="sig-name descname"><span class="pre">configure_optimizers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nidl/estimators/ssl/yaware.html#YAwareContrastiveLearning.configure_optimizers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nidl.estimators.ssl.YAwareContrastiveLearning.configure_optimizers" title="Link to this definition">¶</a></dt>
<dd><p>Choose what optimizers and learning-rate schedulers to use in your optimization. Normally you’d need one.
But in the case of GANs or similar you might have multiple. Optimization with multiple optimizers only works in
the manual optimization mode.</p>
<dl class="simple">
<dt>Return:</dt><dd><p>Any of these 6 options.</p>
<ul class="simple">
<li><p><strong>Single optimizer</strong>.</p></li>
<li><p><strong>List or Tuple</strong> of optimizers.</p></li>
<li><p><strong>Two lists</strong> - The first list has multiple optimizers, and the second has multiple LR schedulers
(or multiple <code class="docutils literal notranslate"><span class="pre">lr_scheduler_config</span></code>).</p></li>
<li><p><strong>Dictionary</strong>, with an <code class="docutils literal notranslate"><span class="pre">&quot;optimizer&quot;</span></code> key, and (optionally) a <code class="docutils literal notranslate"><span class="pre">&quot;lr_scheduler&quot;</span></code>
key whose value is a single LR scheduler or <code class="docutils literal notranslate"><span class="pre">lr_scheduler_config</span></code>.</p></li>
<li><p><strong>None</strong> - Fit will run without any optimizer.</p></li>
</ul>
</dd>
</dl>
<p>The <code class="docutils literal notranslate"><span class="pre">lr_scheduler_config</span></code> is a dictionary which contains the scheduler and its associated configuration.
The default configuration is shown below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">lr_scheduler_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># REQUIRED: The scheduler instance</span>
    <span class="s2">&quot;scheduler&quot;</span><span class="p">:</span> <span class="n">lr_scheduler</span><span class="p">,</span>
    <span class="c1"># The unit of the scheduler&#39;s step size, could also be &#39;step&#39;.</span>
    <span class="c1"># &#39;epoch&#39; updates the scheduler on epoch end whereas &#39;step&#39;</span>
    <span class="c1"># updates it after a optimizer update.</span>
    <span class="s2">&quot;interval&quot;</span><span class="p">:</span> <span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
    <span class="c1"># How many epochs/steps should pass between calls to</span>
    <span class="c1"># `scheduler.step()`. 1 corresponds to updating the learning</span>
    <span class="c1"># rate after every epoch/step.</span>
    <span class="s2">&quot;frequency&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="c1"># Metric to monitor for schedulers like `ReduceLROnPlateau`</span>
    <span class="s2">&quot;monitor&quot;</span><span class="p">:</span> <span class="s2">&quot;val_loss&quot;</span><span class="p">,</span>
    <span class="c1"># If set to `True`, will enforce that the value specified &#39;monitor&#39;</span>
    <span class="c1"># is available when the scheduler is updated, thus stopping</span>
    <span class="c1"># training if not found. If set to `False`, it will only produce a warning</span>
    <span class="s2">&quot;strict&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="c1"># If using the `LearningRateMonitor` callback to monitor the</span>
    <span class="c1"># learning rate progress, this keyword can be used to specify</span>
    <span class="c1"># a custom logged name</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>When there are schedulers in which the <code class="docutils literal notranslate"><span class="pre">.step()</span></code> method is conditioned on a value, such as the
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.optim.lr_scheduler.ReduceLROnPlateau</span></code> scheduler, Lightning requires that the
<code class="docutils literal notranslate"><span class="pre">lr_scheduler_config</span></code> contains the keyword <code class="docutils literal notranslate"><span class="pre">&quot;monitor&quot;</span></code> set to the metric name that the scheduler
should be conditioned on.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># The ReduceLROnPlateau scheduler requires a monitor</span>
<span class="k">def</span><span class="w"> </span><span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;optimizer&quot;</span><span class="p">:</span> <span class="n">optimizer</span><span class="p">,</span>
        <span class="s2">&quot;lr_scheduler&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;scheduler&quot;</span><span class="p">:</span> <span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="o">...</span><span class="p">),</span>
            <span class="s2">&quot;monitor&quot;</span><span class="p">:</span> <span class="s2">&quot;metric_to_track&quot;</span><span class="p">,</span>
            <span class="s2">&quot;frequency&quot;</span><span class="p">:</span> <span class="s2">&quot;indicates how often the metric is updated&quot;</span><span class="p">,</span>
            <span class="c1"># If &quot;monitor&quot; references validation metrics, then &quot;frequency&quot; should be set to a</span>
            <span class="c1"># multiple of &quot;trainer.check_val_every_n_epoch&quot;.</span>
        <span class="p">},</span>
    <span class="p">}</span>

<span class="c1"># In the case of two optimizers, only one using the ReduceLROnPlateau scheduler</span>
<span class="k">def</span><span class="w"> </span><span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">optimizer1</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="n">optimizer2</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="n">scheduler1</span> <span class="o">=</span> <span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer1</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
    <span class="n">scheduler2</span> <span class="o">=</span> <span class="n">LambdaLR</span><span class="p">(</span><span class="n">optimizer2</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;optimizer&quot;</span><span class="p">:</span> <span class="n">optimizer1</span><span class="p">,</span>
            <span class="s2">&quot;lr_scheduler&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;scheduler&quot;</span><span class="p">:</span> <span class="n">scheduler1</span><span class="p">,</span>
                <span class="s2">&quot;monitor&quot;</span><span class="p">:</span> <span class="s2">&quot;metric_to_track&quot;</span><span class="p">,</span>
            <span class="p">},</span>
        <span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;optimizer&quot;</span><span class="p">:</span> <span class="n">optimizer2</span><span class="p">,</span> <span class="s2">&quot;lr_scheduler&quot;</span><span class="p">:</span> <span class="n">scheduler2</span><span class="p">},</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>Metrics can be made available to monitor by simply logging it using
<code class="docutils literal notranslate"><span class="pre">self.log('metric_to_track',</span> <span class="pre">metric_val)</span></code> in your <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code>.</p>
<dl class="simple">
<dt>Note:</dt><dd><p>Some things to know:</p>
<ul class="simple">
<li><p>Lightning calls <code class="docutils literal notranslate"><span class="pre">.backward()</span></code> and <code class="docutils literal notranslate"><span class="pre">.step()</span></code> automatically in case of automatic optimization.</p></li>
<li><p>If a learning rate scheduler is specified in <code class="docutils literal notranslate"><span class="pre">configure_optimizers()</span></code> with key
<code class="docutils literal notranslate"><span class="pre">&quot;interval&quot;</span></code> (default “epoch”) in the scheduler configuration, Lightning will call
the scheduler’s <code class="docutils literal notranslate"><span class="pre">.step()</span></code> method automatically in case of automatic optimization.</p></li>
<li><p>If you use 16-bit precision (<code class="docutils literal notranslate"><span class="pre">precision=16</span></code>), Lightning will automatically handle the optimizer.</p></li>
<li><p>If you use <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.optim.LBFGS</span></code>, Lightning handles the closure function automatically for you.</p></li>
<li><p>If you use multiple optimizers, you will have to switch to ‘manual optimization’ mode and step them
yourself.</p></li>
<li><p>If you need to control how often the optimizer steps, override the <code class="xref py py-meth docutils literal notranslate"><span class="pre">optimizer_step()</span></code> hook.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nidl.estimators.ssl.YAwareContrastiveLearning.parse_batch">
<span class="sig-name descname"><span class="pre">parse_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/nidl/estimators/ssl/yaware.html#YAwareContrastiveLearning.parse_batch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nidl.estimators.ssl.YAwareContrastiveLearning.parse_batch" title="Link to this definition">¶</a></dt>
<dd><p>Parses the batch to extract the two views and the auxiliary
variable.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> : Any</p>
<blockquote>
<div><p>Parse a batch input and return V1, V2, and y.
The batch can be either:</p>
<ul class="simple">
<li><p>(V1, V2): two views of the same sample.</p></li>
<li><p>((V1, V2), y): two views and an auxiliary label or variable.</p></li>
</ul>
</div></blockquote>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>V1</strong> : torch.Tensor</p>
<blockquote>
<div><p>First view of the input.</p>
</div></blockquote>
<p><strong>V2</strong> : torch.Tensor</p>
<blockquote>
<div><p>Second view of the input.</p>
</div></blockquote>
<p><strong>y</strong> : Optional[torch.Tensor]</p>
<blockquote>
<div><p>Auxiliary label or variable, if present. Otherwise, None.</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nidl.estimators.ssl.YAwareContrastiveLearning.training_step">
<span class="sig-name descname"><span class="pre">training_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nidl/estimators/ssl/yaware.html#YAwareContrastiveLearning.training_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nidl.estimators.ssl.YAwareContrastiveLearning.training_step" title="Link to this definition">¶</a></dt>
<dd><p>Perform one training step and computes training loss.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> : Any</p>
<blockquote>
<div><p>A batch of data that has been generated from train_dataloader.
It can be a pair of <cite>torch.Tensor</cite> (V1, V2) or a pair
((V1, V2), y) where V1 and V2 are the two views of the same sample
and y is the auxiliary variable.</p>
</div></blockquote>
<p><strong>batch_idx</strong> : int</p>
<blockquote>
<div><p>The index of the current batch.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>loss</strong> : Tensor</p>
<blockquote>
<div><p>Training loss computed on this batch of data.</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nidl.estimators.ssl.YAwareContrastiveLearning.transform_step">
<span class="sig-name descname"><span class="pre">transform_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nidl/estimators/ssl/yaware.html#YAwareContrastiveLearning.transform_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nidl.estimators.ssl.YAwareContrastiveLearning.transform_step" title="Link to this definition">¶</a></dt>
<dd><p>Define a transform step.</p>
<p>Share the same API as <code class="xref py py-meth docutils literal notranslate"><span class="pre">BaseEstimator.predict_step()</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nidl.estimators.ssl.YAwareContrastiveLearning.validation_step">
<span class="sig-name descname"><span class="pre">validation_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nidl/estimators/ssl/yaware.html#YAwareContrastiveLearning.validation_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nidl.estimators.ssl.YAwareContrastiveLearning.validation_step" title="Link to this definition">¶</a></dt>
<dd><p>Perform one validation step and computes validation loss.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> : Any</p>
<blockquote>
<div><p>A batch of data that has been generated from val_dataloader.
It can be a pair of <cite>torch.Tensor</cite> (V1, V2) or a pair
((V1, V2), y) where V1 and V2 are the two views of the same
sample and y is the auxiliary variable.</p>
</div></blockquote>
<p><strong>batch_idx</strong> : int</p>
<blockquote>
<div><p>The index of the current batch.</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

</dd></dl>


                    </div>
                <div class="spacer"></div>
		        
		        <!-- Footer -->
		        <div class="section-6-container section-container section-container-image-bg" id="section-6">
			        <div class="container">
			            <div class="row">
		                    <div class="col-md-5 offset-md-1 section-6-box wow fadeInDown">
                                <div class="section-6-title">
		                    	    <p>Follow us</p>
                                </div>
		                    	<div class="section-6-social">
			                    	<a href="https://www.facebook.com/pages/NeuroSpin/171075046414933"><i class="fab fa-facebook-f"></i></a>
									<a href="https://www.youtube.com/CEASaclay"><i class="fab fa-youtube"></i></a>
									<a href="https://twitter.com/neurospin_91"><i class="fab fa-twitter"></i></a>
									<a href="https://gaia.neurospin.fr"><i class="fa fa-link"></i></a>
                                    <p>&copy; 2025, 
nidl developers
 <antoine.grigis@cea.fr></p>
		                    	</div>
		                    </div>
			            </div>
			        </div>
                </div>
	        
	        </div>
	        <!-- End content -->
        
        </div>
        <!-- End wrapper -->

        <!-- Javascript -->
		<script src="../_static/js/jquery-3.3.1.min.js"></script>
		<script src="../_static/js/jquery-migrate-3.0.0.min.js"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
		<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
        <script src="../_static/js/jquery.backstretch.min.js"></script>
        <script src="../_static/js/wow.min.js"></script>
        <script src="../_static/js/jquery.waypoints.min.js"></script>
        <script src="../_static/js/jquery.mCustomScrollbar.concat.min.js"></script>
        <script src="../_static/js/scripts.js"></script>
        <script src="../_static/js/jquery.mosaic.js"></script>
        <script src="../_static/js/search.js"></script>
        <script type="text/javascript">
	        $('.top-content').backstretch("../_static/img/backgrounds/banner1.png");
            $('.section-6-container').backstretch("../_static/img/backgrounds/footer1.png");
        </script>

    </body>

</html>