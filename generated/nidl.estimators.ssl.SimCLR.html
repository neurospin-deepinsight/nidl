<!doctype html>
<html lang="en">

    <head>

		<!-- Required meta tags -->
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

        <title>nidl</title>
        
        <!-- CSS -->
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500&display=swap">
		<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
        <link rel="stylesheet" href="../_static/css/jquery.mCustomScrollbar.min.css">
        <link rel="stylesheet" href="../_static/css/animate.css">
        <link rel="stylesheet" href="../_static/css/style.css">
        <link rel="stylesheet" href="../_static/css/jquery.mosaic.css">
        <link rel="stylesheet" href="../_static/sg_gallery.css">
        <link rel="stylesheet" href="../_static/css/media-queries.css">
        <link rel="stylesheet" href="../_static/css/pygment.css">

        <!-- Favicon and touch icons -->
        <link rel="shortcut icon" href="../_static/ico/favicon.png">
        <link rel="apple-touch-icon-precomposed" sizes="144x144" href="../_static/ico/apple-touch-icon-144-precomposed.png">
        <link rel="apple-touch-icon-precomposed" sizes="114x114" href="../_static/ico/apple-touch-icon-114-precomposed.png">
        <link rel="apple-touch-icon-precomposed" sizes="72x72" href="../_static/ico/apple-touch-icon-72-precomposed.png">
        <link rel="apple-touch-icon-precomposed" href="../_static/ico/apple-touch-icon-57-precomposed.png">

    </head>

    <body>

		<!-- Wrapper -->
    	<div class="wrapper">

			<!-- Sidebar -->
			<nav class="sidebar">
				
				<!-- close sidebar menu -->
				<div class="dismiss">
					<i class="fas fa-arrow-left"></i>
				</div>
				
				<!-- <div class="logo"">
					<h3><a href="../index.html">Sidebar Menu</a></h3>
				</div> -->

                <!-- info setup -->
                    <p class="doc-version">
                        This documentation is for nidl <strong>version 0.0.0</strong>
                    </p>
                <p class="citing">
                    If you use the software, please do not hesitate to 
                    <a &mdash; <a href="https://github.com/neurospin-deepinsight/nidl">
                    Report a Bug</a>.
                </p>
				
                <!-- links -->
                
                
                    
                
				<ul class="list-unstyled menu-elements">
					<li class="active">
						<a href="../index.html"><i class="fas fa-home"></i> Home</a>
					</li>
					<li>
						<a href="installation.html"><i class="fas fa-cog"></i> Installation</a>
					</li>
					<li>
						<a href="../auto_gallery/index.html"><i class="fas fa-eye"></i> Gallery</a>
					</li>
					<li>
						<a href="documentation.html"><i class="fas fa-pencil-alt"></i> API documentation</a>
					</li>
					<li>
						<a href="search.html"><i class="fas fa-search"></i> Search</a>
					</li>
					<!-- <li>
						<a href="https://github.com/AGrigis/pysphinxdoc"><i class="fas fa-external-link-alt"></i> PYSPHINXDOC</a>
					</li> -->
					<!-- <li>
						<a href="#otherSections" data-toggle="collapse" aria-expanded="false" class="dropdown-toggle" role="button" aria-controls="otherSections">
							<i class="fas fa-sync"></i>Sections Shortcuts
						</a>
						<ul class="collapse list-unstyled" id="otherSections">
                            <li>LINKS</li><li><a href='https://github.com/neurospin-deepinsight/surfify'>surfify</a></li>
                            
                                
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                        
                                        
                                        
                                            
                                            
                                    
                                
                                    
                                        
                                        
                                        
                                    
                                
                                
                                    <li>SECTIONS</li>
                                    
						                <li> <a href='#nidl.estimators.ssl.SimCLR.configure_optimizers'>Simclr.configure_optimizers()</a> </li>                                    
                                    
						                <li> <a href='#nidl.estimators.ssl.SimCLR.info_nce_loss'>Simclr.info_nce_loss()</a> </li>                                    
                                    
						                <li> <a href='#nidl.estimators.ssl.SimCLR.training_step'>Simclr.training_step()</a> </li>                                    
                                    
						                <li> <a href='#nidl.estimators.ssl.SimCLR.transform_step'>Simclr.transform_step()</a> </li>                                    
                                    
						                <li> <a href='#nidl.estimators.ssl.SimCLR.validation_step'>Simclr.validation_step()</a> </li>                                    
                                    
						                <li> <a href='#examples'>Examples</a> </li>                                    
                                    
                                
                            
                            <li>API</li>
                            <li><a href="nidl.html">nidl</a></li><li><a href="nidl.callbacks.html">nidl.callbacks</a></li><li><a href="nidl.datasets.html">nidl.datasets</a></li><li><a href="nidl.estimators.html">nidl.estimators</a></li><li><a href="nidl.estimators.linear.html">nidl.estimators.linear</a></li><li><a href="nidl.estimators.ssl.html">nidl.estimators.ssl</a></li><li><a href="nidl.estimators.ssl.utils.html">nidl.estimators.ssl.utils</a></li><li><a href="nidl.losses.html">nidl.losses</a></li><li><a href="nidl.metrics.html">nidl.metrics</a></li><li><a href="nidl.utils.html">nidl.utils</a></li><li><a href="nidl.volume.html">nidl.volume</a></li><li><a href="nidl.volume.backbones.html">nidl.volume.backbones</a></li><li><a href="nidl.volume.transforms.html">nidl.volume.transforms</a></li><li><a href="nidl.volume.transforms.augmentation.html">nidl.volume.transforms.augmentation</a></li><li><a href="nidl.volume.transforms.augmentation.intensity.html">nidl.volume.transforms.augmentation.intensity</a></li><li><a href="nidl.volume.transforms.augmentation.spatial.html">nidl.volume.transforms.augmentation.spatial</a></li><li><a href="nidl.volume.transforms.preprocessing.html">nidl.volume.transforms.preprocessing</a></li><li><a href="nidl.volume.transforms.preprocessing.intensity.html">nidl.volume.transforms.preprocessing.intensity</a></li><li><a href="nidl.volume.transforms.preprocessing.spatial.html">nidl.volume.transforms.preprocessing.spatial</a></li><li><a href="surfify.html">surfify</a></li><li><a href="surfify.augmentation.html">surfify.augmentation</a></li><li><a href="surfify.datasets.html">surfify.datasets</a></li><li><a href="surfify.losses.html">surfify.losses</a></li><li><a href="surfify.models.html">surfify.models</a></li><li><a href="surfify.nn.html">surfify.nn</a></li><li><a href="surfify.plotting.html">surfify.plotting</a></li><li><a href="surfify.utils.html">surfify.utils</a></li>
						</ul>
					</li> -->
				</ul>
				
                <!-- go top page -->
				<!-- <div class="to-top">
					<a class="btn btn-primary btn-customized-3" href="#" role="button">
	                    <i class="fas fa-arrow-up"></i> Top
	                </a>
				</div> -->
			
                <!-- change color -->
				<!-- <div class="dark-light-buttons">
					<a class="btn btn-primary btn-customized-4 btn-customized-dark" href="#" role="button">Dark</a>
					<a class="btn btn-primary btn-customized-4 btn-customized-light" href="#" role="button">Light</a>
				</div> -->
			
			</nav>
			<!-- End sidebar -->
			
			<!-- Dark overlay -->
    		<div class="overlay"></div>

			<!-- Content -->
			<div class="content">
			
				<!-- open sidebar menu -->
				<a class="btn btn-primary btn-customized open-menu" href="#" role="button">
                    <i class="fas fa-align-left"></i> <span>Menu</span>
                </a>

		        <!-- Top content -->
		        <div class="top-content section-container" id="top-content">
			        <div class="container">
			            <div class="row">
                            <div class="col-md-3 section-5-box banner-logo">
                                <img alt="Logo" src="../_static/nidl.png">
                            </div>
			                <div class="col-md-7 section-5-box">
			                	<h1 class="wow fadeIn">    <p>Deep learning for NeuroImaging in Python.</p></h1>
			                </div>
			            </div>
			        </div>
		        </div>
                    
                    <div class="document">
                        <div class="admonition note">
<p class="admonition-title">Note</p>
<p>This page is a reference documentation. It only explains the class signature, and not how to use it. Please refer to the <a class="reference internal" href="../auto_gallery/index.html#sphx-glr-auto-gallery"><span class="std std-ref">gallery</span></a> for the big picture.</p>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="nidl.estimators.ssl.SimCLR">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nidl.estimators.ssl.</span></span><span class="sig-name descname"><span class="pre">SimCLR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nidl/estimators/ssl/simclr.html#SimCLR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nidl.estimators.ssl.SimCLR" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="nidl.estimators.base.TransformerMixin.html#nidl.estimators.base.TransformerMixin" title="nidl.estimators.base.TransformerMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">TransformerMixin</span></code></a>, <a class="reference internal" href="nidl.estimators.base.BaseEstimator.html#nidl.estimators.base.BaseEstimator" title="nidl.estimators.base.BaseEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseEstimator</span></code></a></p>
<p>SimCLR implementation.</p>
<p>At each iteration, we get for every data x two differently augmented
versions, which we refer to as x_i and x_j. Both of these images are
encoded into a one-dimensional feature vector, between which we want to
maximize similarity which minimizes it to all other data in the batch.
The encoder network is split into two parts: a base encoder network f(.),
and a projection head g(.). The base network is usually a deep CNN or SCNN,
and is responsible for extracting a representation vector from the
augmented data examples. Let’s denote the representations obtained from the
encoder h=f(x). The projection head g(.) maps the representation h into a
space where we apply the contrastive loss, i.e., compare similarities
between vectors. In the original SimCLR paper g(.) was defined as a
two-layer MLP with ReLU activation in the hidden layer. Note that in the
follow-up paper, SimCLRv2, the authors mention that larger/wider MLPs can
boost the performance considerably.</p>
<p>After finishing the training with contrastive learning, we will remove
the projection head g(.), and use f(.) as a pretrained feature extractor.
The representations z that come out of the projection head g(.) have been
shown to perform worse than those of the base network f(.) when
finetuning the network for a new task. This is likely because the
representations z are trained to become invariant to many features that
can be important for downstream tasks. Thus, g(.) is only needed for the
contrastive learning stage.</p>
<p>Now that the architecture is described, let’s take a closer look at how we
train the model. As mentioned before, we want to maximize the similarity
between the representations of the two augmented versions of the same
image, i.e., z_i and z_j, while minimizing it to all other examples in the
batch. SimCLR thereby applies the InfoNCE loss, originally proposed by
Aaron van den Oord et al. for contrastive learning. In short, the InfoNCE
loss compares the similarity of z_i and z_j to the similarity of z_i to
any other representation in the batch by performing a softmax over the
similarity values. The loss can be formally written as:</p>
<div class="math">
<p><img src="../_images/math/7a85bb32c2a48b2cecc525ca341bf85198c5035d.png" alt="\ell_{i,j} = -\log \frac{\exp(\text{sim}(z_i,z_j)/\tau)}{
             \sum_{k=1}^{2N}\mathbb{1}_{[k\neq i]}
                \exp(\text{sim}(z_i,z_k)/\tau)}
           = -\text{sim}(z_i,z_j)/\tau
             +\log\left[\sum_{k=1}^{2N}\mathbb{1}_{[k\neq i]}
                \exp(\text{sim}(z_i,z_k)/\tau)\right]"/></p>
</div><p>The function text{sim} is a similarity metric, and the hyperparameter
tau is called temperature determining how peaked the distribution is.
Since many similarity metrics are bounded, the temperature parameter
allows us to balance the influence of many dissimilar image patches versus
one similar patch. The similarity metric that is used in SimCLR is cosine
similarity, as defined below:</p>
<div class="math">
<p><img src="../_images/math/18a8ddec389dc33fc5114f51c36d2e38f52adbce.png" alt="\text{sim}(z_i,z_j) = \frac{z_i^\top \cdot z_j}{||z_i||\cdot||z_j||}"/></p>
</div><p>The maximum cosine similarity possible is 1, while the minimum is -1. In
general, we will see that the features of two different images will
converge to a cosine similarity around zero since the minimum, -1, would
require z_i and z_j to be in the exact opposite direction in all feature
dimensions, which does not allow for great flexibility.</p>
<p>Alternatively to performing the validation on the contrastive learning
loss as well, we could also take a simple, small downstream task, and
track the performance of the base network f(.) on that.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>encoder</strong> : nn.Module</p>
<blockquote>
<div><p>the encoder f(.). It must store the size of the encoded one-dimensional
feature vector in a <cite>latent_size</cite> parameter.</p>
</div></blockquote>
<p><strong>hidden_dims</strong> : list of str</p>
<blockquote>
<div><p>the projector g(.) MLP architecture.</p>
</div></blockquote>
<p><strong>lr</strong> : float</p>
<blockquote>
<div><p>the learning rate.</p>
</div></blockquote>
<p><strong>temperature</strong> : float</p>
<blockquote>
<div><p>the SimCLR loss temperature parameter.</p>
</div></blockquote>
<p><strong>weight_decay</strong> : float</p>
<blockquote>
<div><p>the Adam optimizer weight decay parameter.</p>
</div></blockquote>
<p><strong>max_epochs</strong> : int, default=None</p>
<blockquote>
<div><p>optionaly, use a CosineAnnealingLR scheduler.</p>
</div></blockquote>
<p><strong>random_state</strong> : int, default=None</p>
<blockquote>
<div><p>setting a seed for reproducibility.</p>
</div></blockquote>
<p><strong>kwargs</strong> : dict</p>
<blockquote>
<div><p>Trainer parameters.</p>
</div></blockquote>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>A batch of data must contains two elements: two tensors with contrasted
images, and a list of tensors containing auxiliary variables.</p>
<p class="rubric">Attributes</p>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>f</p></td>
<td><p>a <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> containing the encoder.</p></td>
</tr>
<tr class="row-even"><td><p>g</p></td>
<td><p>a <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> containing the projection head.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="nidl.estimators.ssl.SimCLR.configure_optimizers">
<span class="sig-name descname"><span class="pre">configure_optimizers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nidl/estimators/ssl/simclr.html#SimCLR.configure_optimizers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nidl.estimators.ssl.SimCLR.configure_optimizers" title="Link to this definition">¶</a></dt>
<dd><p>Declare a <code class="xref py py-class docutils literal notranslate"><span class="pre">AdamW</span></code> optimizer and, optionnaly
(<code class="docutils literal notranslate"><span class="pre">max_epochs</span></code> is defined), a
<code class="xref py py-class docutils literal notranslate"><span class="pre">CosineAnnealingLR</span></code> learning-rate
scheduler.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nidl.estimators.ssl.SimCLR.info_nce_loss">
<span class="sig-name descname"><span class="pre">info_nce_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nidl/estimators/ssl/simclr.html#SimCLR.info_nce_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nidl.estimators.ssl.SimCLR.info_nce_loss" title="Link to this definition">¶</a></dt>
<dd><p>Compute and log the InfoNCE loss using
<a class="reference internal" href="nidl.losses.InfoNCE.html#nidl.losses.InfoNCE" title="nidl.losses.InfoNCE"><code class="xref py py-class docutils literal notranslate"><span class="pre">InfoNCE</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nidl.estimators.ssl.SimCLR.training_step">
<span class="sig-name descname"><span class="pre">training_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nidl/estimators/ssl/simclr.html#SimCLR.training_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nidl.estimators.ssl.SimCLR.training_step" title="Link to this definition">¶</a></dt>
<dd><p>Here you compute and return the training loss and some additional
metrics for e.g. the progress bar or logger.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> : iterable, normally a <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code></p>
<blockquote>
<div><p>the current data.</p>
</div></blockquote>
<p><strong>batch_idx</strong> : int</p>
<blockquote>
<div><p>the index of this batch.</p>
</div></blockquote>
<p><strong>dataloader_idx</strong> : int, default=0</p>
<blockquote>
<div><p>the index of the dataloader that produced this batch (only if
multiple dataloaders are used).</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>loss</strong> : STEP_OUTPUT</p>
<blockquote>
<div><p>the computed loss:</p>
<ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> - the loss tensor.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dict</span></code> - a dictionary which can include any keys, but must
include the key <code class="docutils literal notranslate"><span class="pre">'loss'</span></code> in the case of automatic optimization.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> - in automatic optimization, this will skip to the
next batch (but is not supported for multi-GPU, TPU, or
DeepSpeed). For manual optimization, this has no special
meaning, as returning the loss is not required.</p></li>
</ul>
</div></blockquote>
<p>To use multiple optimizers, you can switch to ‘manual optimization’</p>
<p>and control their stepping:</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>When <code class="docutils literal notranslate"><span class="pre">accumulate_grad_batches</span></code> &gt; 1, the loss returned here will be
automatically normalized by <code class="docutils literal notranslate"><span class="pre">accumulate_grad_batches</span></code> internally.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="bp">self</span><span class="o">.</span><span class="n">automatic_optimization</span> <span class="o">=</span> <span class="kc">False</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Multiple optimizers (e.g.: GANs)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">opt1</span><span class="p">,</span> <span class="n">opt2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="c1"># do training_step with encoder</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">opt1</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="c1"># do training_step with decoder</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">opt2</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nidl.estimators.ssl.SimCLR.transform_step">
<span class="sig-name descname"><span class="pre">transform_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nidl/estimators/ssl/simclr.html#SimCLR.transform_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nidl.estimators.ssl.SimCLR.transform_step" title="Link to this definition">¶</a></dt>
<dd><p>Define a transform step.</p>
<p>Share the same API as <code class="xref py py-meth docutils literal notranslate"><span class="pre">BaseEstimator.predict_step()</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nidl.estimators.ssl.SimCLR.validation_step">
<span class="sig-name descname"><span class="pre">validation_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nidl/estimators/ssl/simclr.html#SimCLR.validation_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nidl.estimators.ssl.SimCLR.validation_step" title="Link to this definition">¶</a></dt>
<dd><p>Operates on a single batch of data from the validation set. In
this step you’d might generate examples or calculate anything of
interest like accuracy.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> : iterable, normally a <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code></p>
<blockquote>
<div><p>the current data.</p>
</div></blockquote>
<p><strong>batch_idx</strong> : int</p>
<blockquote>
<div><p>the index of this batch.</p>
</div></blockquote>
<p><strong>dataloader_idx</strong> : int, default=0</p>
<blockquote>
<div><p>the index of the dataloader that produced this batch (only if
multiple dataloaders are used).</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>loss</strong> : STEP_OUTPUT</p>
<blockquote>
<div><p>the computed loss:</p>
<ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> - the loss tensor.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dict</span></code> - a dictionary. can include any keys, but must include
the key <code class="docutils literal notranslate"><span class="pre">'loss'</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> - skip to the next batch.</p></li>
</ul>
</div></blockquote>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>When the <a class="reference internal" href="#nidl.estimators.ssl.SimCLR.validation_step" title="nidl.estimators.ssl.SimCLR.validation_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">validation_step()</span></code></a> is called, the model has been put in
eval mode and PyTorch gradients have been disabled. At the end of
validation,  the model goes back to training mode and gradients are
enabled.</p>
</dd></dl>

</dd></dl>

<section id="examples">
<h1>Examples<a class="headerlink" href="#examples" title="Link to this heading">¶</a></h1><div class='divider-1 wow fadeInUp' style='margin-top: -20px;'><span></span></div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer section-5-box wow fadeInUp" tooltip="From: https://uvadlc-notebooks.readthedocs.io"><img alt="" src="../_images/sphx_glr_simclr_stl10_thumb.png" />
<p><a class="reference internal" href="../auto_gallery/simclr_stl10.html#sphx-glr-auto-gallery-simclr-stl10-py"><span class="std std-ref">Self-Supervised Contrastive Learning with SimCLR</span></a></p>
  <div class="sphx-glr-thumbnail-title">Self-Supervised Contrastive Learning with SimCLR</div>
</div></div></section>

                    </div>
                <div class="spacer"></div>
		        
		        <!-- Footer -->
		        <div class="section-6-container section-container section-container-image-bg" id="section-6">
			        <div class="container">
			            <div class="row">
		                    <div class="col-md-5 offset-md-1 section-6-box wow fadeInDown">
                                <div class="section-6-title">
		                    	    <p>Follow us</p>
                                </div>
		                    	<div class="section-6-social">
			                    	<a href="https://www.facebook.com/pages/NeuroSpin/171075046414933"><i class="fab fa-facebook-f"></i></a>
									<a href="https://www.youtube.com/CEASaclay"><i class="fab fa-youtube"></i></a>
									<a href="https://twitter.com/neurospin_91"><i class="fab fa-twitter"></i></a>
									<a href="https://gaia.neurospin.fr"><i class="fa fa-link"></i></a>
                                    <p>&copy; 2025, 
nidl developers
 <antoine.grigis@cea.fr></p>
		                    	</div>
		                    </div>
			            </div>
			        </div>
                </div>
	        
	        </div>
	        <!-- End content -->
        
        </div>
        <!-- End wrapper -->

        <!-- Javascript -->
		<script src="../_static/js/jquery-3.3.1.min.js"></script>
		<script src="../_static/js/jquery-migrate-3.0.0.min.js"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
		<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
        <script src="../_static/js/jquery.backstretch.min.js"></script>
        <script src="../_static/js/wow.min.js"></script>
        <script src="../_static/js/jquery.waypoints.min.js"></script>
        <script src="../_static/js/jquery.mCustomScrollbar.concat.min.js"></script>
        <script src="../_static/js/scripts.js"></script>
        <script src="../_static/js/jquery.mosaic.js"></script>
        <script src="../_static/js/search.js"></script>
        <script type="text/javascript">
	        $('.top-content').backstretch("../_static/img/backgrounds/banner1.png");
            $('.section-6-container').backstretch("../_static/img/backgrounds/footer1.png");
        </script>

    </body>

</html>