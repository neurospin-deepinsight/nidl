
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_barlowtwins_openbhb.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_barlowtwins_openbhb.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_barlowtwins_openbhb.py:


Self-supervised Learning with BarlowTwins
===================================================

This tutorial will show you how to fit and evaluate a BarlowTwins
Learning model [1]_ on the OpenBHB dataset using NIDL.

We will follow these steps using the NIDL library:

1. Load the OpenBHB dataset.
2. Define the data augmentations for self-supervised training.
3. Define the BarlowTwins model.
4. Train the model.
5. Visualize the model's embedding using MDS and evaluate its
   performance on age prediction using linear regression and KNN.

As for the neuroimaging data, we will investigate two input representations:

- Voxel-based morphometry (VBM) maps, which are preprocessed gray matter
  density maps.
- Surface-based morphometry (SBM) maps, which are cortical thickness, mean
  curvature, gray matter volume and surface area maps projected onto a
  standard surface template.

  Both representations are available in the OpenBHB dataset. To make the
  training faster and reduce the memory footprint, we will consider regions
  of interest (ROIs) instead of the whole brain. For VBM, we will
  use the mean gray matter density averaged within each ROI of the
  Neuromorphometrics atlas (284 regions). For SBM, we will use the cortical
  thickness, mean curvature, gray matter volume and surface area averaged
  within each ROI of the Desikan-Killiany atlas (68 regions).

  The BarlowTwins model will be trained individually on both
  representations and we will compare their performance on age prediction.

  .. [1] Zbontar, J., et al., "Barlow Twins: Self-Supervised Learning
           via Redundancy Reduction." PMLR, 2021.
           hhttps://proceedings.mlr.press/v139/zbontar21a

Setup
-----

This notebook requires some packages besides nidl. Let's first start with
importing our standard libraries below:

.. GENERATED FROM PYTHON SOURCE LINES 46-61

.. code-block:: Python


    import matplotlib.pyplot as plt
    import numpy as np
    import torchvision.transforms as transforms
    from sklearn.linear_model import LinearRegression
    from sklearn.manifold import MDS
    from sklearn.metrics import mean_absolute_error, r2_score
    from sklearn.neighbors import KNeighborsRegressor
    from torch.utils.data import DataLoader
    from torchvision.ops import MLP

    from nidl.datasets import OpenBHB
    from nidl.estimators.ssl import BarlowTwins
    from nidl.transforms import MultiViewsTransform








.. GENERATED FROM PYTHON SOURCE LINES 62-63

We define some global parameters that will be used throughout the notebook:

.. GENERATED FROM PYTHON SOURCE LINES 63-69

.. code-block:: Python

    data_dir = "/tmp/openbhb"
    batch_size = 128
    num_workers = 10
    latent_size = 32









.. GENERATED FROM PYTHON SOURCE LINES 70-77

OpenBHB datasets and data augmentations for Contrastive Learning
----------------------------------------------------------------

We will use the OpenBHB dataset for pre-training the models. We will focus
on the VBM ROI representation and the SBM ROI representation for this
tutorial. Since they are tabular data, we will use random masking and
adding Gaussian noise as data augmentation in contrastive learning.

.. GENERATED FROM PYTHON SOURCE LINES 77-92

.. code-block:: Python


    # Hyperparameters for data augmentations
    mask_prob = 0.8
    noise_std = 0.5
    contrast_transforms = transforms.Compose(
        [
            lambda x: x.flatten(),
            lambda x: (np.random.rand(*x.shape) > mask_prob).astype(np.float32)
            * x,  # random masking
            lambda x: x
            + (
                (np.random.rand() > 0.5) * np.random.randn(*x.shape) * noise_std
            ).astype(np.float32),  # random Gaussian noise
        ]
    )







.. GENERATED FROM PYTHON SOURCE LINES 93-95

We first create the SSL dataloaders with VBM modality and age as weak label.
We use the previous contrastive transforms for data augmentation.

.. GENERATED FROM PYTHON SOURCE LINES 95-122

.. code-block:: Python


    dataloader_ssl_vbm = DataLoader(
        OpenBHB(
            data_dir,
            modality="vbm_roi",
            target=None,
            transforms=MultiViewsTransform(contrast_transforms, n_views=2),
            streaming=False,
        ),
        batch_size=batch_size,
        num_workers=num_workers,
        shuffle=True,
    )
    dataloader_ssl_vbm_test = DataLoader(
        OpenBHB(
            data_dir,
            modality="vbm_roi",
            target=None,
            split="val",
            transforms=MultiViewsTransform(contrast_transforms, n_views=2),
            streaming=False,
        ),
        batch_size=batch_size,
        num_workers=num_workers,
        shuffle=False,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
      warnings.warn(
    /opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
      warnings.warn(




.. GENERATED FROM PYTHON SOURCE LINES 123-126

Then, we create the SSL dataloaders with SBM modality on the Desikan-Killiany
atlas and age as weak label. We only extract some surface features and we use
the same contrastive transforms as for VBM.

.. GENERATED FROM PYTHON SOURCE LINES 126-172

.. code-block:: Python


    # Extract only surface area, GM volume, cortical thickness, mean curvature for
    # SBM maps
    sbm_channels = [0, 1, 2, 5]


    def sbm_transform(x):
        return x[sbm_channels].flatten()


    def vbm_transform(x):
        return x.flatten()


    dataloader_ssl_sbm = DataLoader(
        OpenBHB(
            data_dir,
            modality="fs_desikan_roi",
            target=None,
            transforms=MultiViewsTransform(
                transforms.Compose([sbm_transform, contrast_transforms]),
                n_views=2
            ),
            streaming=False,
        ),
        batch_size=batch_size,
        num_workers=num_workers,
        shuffle=True,
    )
    dataloader_ssl_sbm_test = DataLoader(
        OpenBHB(
            data_dir,
            modality="fs_desikan_roi",
            target=None,
            split="val",
            transforms=MultiViewsTransform(
                transforms.Compose([sbm_transform, contrast_transforms]),
                n_views=2
            ),
            streaming=False,
        ),
        batch_size=batch_size,
        num_workers=num_workers,
        shuffle=False,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]    Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]    Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]
    /opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
      warnings.warn(
    Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]    Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s]    Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s]
    /opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
      warnings.warn(




.. GENERATED FROM PYTHON SOURCE LINES 173-175

Finally, we create the dataloaders for evaluating the learned representations
on age prediction. We don't apply any data augmentation here.

.. GENERATED FROM PYTHON SOURCE LINES 175-238

.. code-block:: Python


    dataloader_vbm_train = DataLoader(
        OpenBHB(
            data_dir,
            modality="vbm_roi",
            target="age",
            split="train",
            transforms=vbm_transform,
            streaming=False,
        ),
        batch_size=batch_size,
        num_workers=num_workers,
        shuffle=False,
    )

    dataloader_vbm_test = DataLoader(
        OpenBHB(
            data_dir,
            modality="vbm_roi",
            target="age",
            split="val",
            transforms=vbm_transform,
            streaming=False,
        ),
        batch_size=batch_size,
        num_workers=num_workers,
        shuffle=False,
    )

    dataloader_sbm_train = DataLoader(
        OpenBHB(
            data_dir,
            modality="fs_desikan_roi",
            target="age",
            split="train",
            transforms=sbm_transform,
            streaming=False,
        ),
        batch_size=batch_size,
        num_workers=num_workers,
        shuffle=False,
    )
    dataloader_sbm_test = DataLoader(
        OpenBHB(
            data_dir,
            modality="fs_desikan_roi",
            target="age",
            split="val",
            transforms=sbm_transform,
            streaming=False,
        ),
        batch_size=batch_size,
        num_workers=num_workers,
        shuffle=False,
    )

    # Small hack to avoid returning the target in the dataloaders since we aim
    # at transforming these datasets without their targets.
    dataloader_vbm_train.dataset.target = None
    dataloader_vbm_test.dataset.target = None
    dataloader_sbm_train.dataset.target = None
    dataloader_sbm_test.dataset.target = None





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
      warnings.warn(
    /opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
      warnings.warn(
    /opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
      warnings.warn(
    /opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
      warnings.warn(




.. GENERATED FROM PYTHON SOURCE LINES 239-244

Training of BarlowTwins models
-----------------------------------------------

We can now instantiate and train two BarlowTwins models (one
for VBM and another for SBM).

.. GENERATED FROM PYTHON SOURCE LINES 246-250

Since we work with tabular data, we can use a simple MLP as encoder. For
VBM data, the input dimension is 284 and we compress the data to a 32-d
vector. SBM data is flattened to a 272-d vector (68 regions * 4 features)
and we also compress it to a 32-d vector.

.. GENERATED FROM PYTHON SOURCE LINES 250-254

.. code-block:: Python


    vbm_encoder = MLP(in_channels=284, hidden_channels=[64, latent_size])
    sbm_encoder = MLP(in_channels=272, hidden_channels=[64, latent_size])








.. GENERATED FROM PYTHON SOURCE LINES 255-256

We limit the training to 10 epochs for the sake of time.

.. GENERATED FROM PYTHON SOURCE LINES 256-286

.. code-block:: Python


    sigma = 4
    vbm_model = BarlowTwins(
        encoder=vbm_encoder,
        projection_head_kwargs={
            "input_dim": latent_size,
            "hidden_dim": 2 * latent_size,
            "output_dim": latent_size,
        },
        lambd=0.005,
        random_state=42,
        max_epochs=10,
        learning_rate=1e-5,
        enable_checkpointing=False,
    )

    sbm_model = BarlowTwins(
        encoder=sbm_encoder,
        projection_head_kwargs={
            "input_dim": latent_size,
            "hidden_dim": 2 * latent_size,
            "output_dim": latent_size,
        },
        lambd=0.005,
        random_state=42,
        max_epochs=10,
        learning_rate=1e-5,
        enable_checkpointing=False,
    )








.. GENERATED FROM PYTHON SOURCE LINES 287-288

We train both models on their respective dataloaders.

.. GENERATED FROM PYTHON SOURCE LINES 288-298

.. code-block:: Python

    vbm_model.fit(
        dataloader_ssl_vbm,
        dataloader_ssl_vbm_test,
    )

    sbm_model.fit(
        dataloader_ssl_sbm,
        dataloader_ssl_sbm_test,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Sanity Checking: |          | 0/? [00:00<?, ?it/s]    Sanity Checking: |          | 0/? [00:00<?, ?it/s]    Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]    Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  7.67it/s]    Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 14.36it/s]                                                                               /opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
    Training: |          | 0/? [00:00<?, ?it/s]    Training: |          | 0/? [00:00<?, ?it/s]    Epoch 0:   0%|          | 0/26 [00:00<?, ?it/s]    Epoch 0:   4%|▍         | 1/26 [00:00<00:24,  1.03it/s]    Epoch 0:   4%|▍         | 1/26 [00:00<00:24,  1.03it/s, v_num=2, loss/train=30.60]    Epoch 0:   8%|▊         | 2/26 [00:01<00:12,  1.88it/s, v_num=2, loss/train=30.60]    Epoch 0:   8%|▊         | 2/26 [00:01<00:12,  1.88it/s, v_num=2, loss/train=31.40]    Epoch 0:  12%|█▏        | 3/26 [00:01<00:11,  2.09it/s, v_num=2, loss/train=31.40]    Epoch 0:  12%|█▏        | 3/26 [00:01<00:11,  2.08it/s, v_num=2, loss/train=30.40]    Epoch 0:  15%|█▌        | 4/26 [00:01<00:08,  2.73it/s, v_num=2, loss/train=30.40]    Epoch 0:  15%|█▌        | 4/26 [00:01<00:08,  2.73it/s, v_num=2, loss/train=32.40]    Epoch 0:  19%|█▉        | 5/26 [00:01<00:06,  3.39it/s, v_num=2, loss/train=32.40]    Epoch 0:  19%|█▉        | 5/26 [00:01<00:06,  3.38it/s, v_num=2, loss/train=34.50]    Epoch 0:  23%|██▎       | 6/26 [00:01<00:04,  4.00it/s, v_num=2, loss/train=34.50]    Epoch 0:  23%|██▎       | 6/26 [00:01<00:04,  4.00it/s, v_num=2, loss/train=31.00]    Epoch 0:  27%|██▋       | 7/26 [00:01<00:04,  4.62it/s, v_num=2, loss/train=31.00]    Epoch 0:  27%|██▋       | 7/26 [00:01<00:04,  4.62it/s, v_num=2, loss/train=29.90]    Epoch 0:  31%|███       | 8/26 [00:01<00:03,  5.25it/s, v_num=2, loss/train=29.90]    Epoch 0:  31%|███       | 8/26 [00:01<00:03,  5.25it/s, v_num=2, loss/train=33.10]    Epoch 0:  35%|███▍      | 9/26 [00:01<00:02,  5.88it/s, v_num=2, loss/train=33.10]    Epoch 0:  35%|███▍      | 9/26 [00:01<00:02,  5.88it/s, v_num=2, loss/train=28.20]    Epoch 0:  38%|███▊      | 10/26 [00:01<00:02,  6.51it/s, v_num=2, loss/train=28.20]    Epoch 0:  38%|███▊      | 10/26 [00:01<00:02,  6.51it/s, v_num=2, loss/train=32.50]    Epoch 0:  42%|████▏     | 11/26 [00:01<00:02,  7.12it/s, v_num=2, loss/train=32.50]    Epoch 0:  42%|████▏     | 11/26 [00:01<00:02,  7.12it/s, v_num=2, loss/train=29.40]    Epoch 0:  46%|████▌     | 12/26 [00:01<00:01,  7.74it/s, v_num=2, loss/train=29.40]    Epoch 0:  46%|████▌     | 12/26 [00:01<00:01,  7.74it/s, v_num=2, loss/train=28.90]    Epoch 0:  50%|█████     | 13/26 [00:01<00:01,  8.34it/s, v_num=2, loss/train=28.90]    Epoch 0:  50%|█████     | 13/26 [00:01<00:01,  8.34it/s, v_num=2, loss/train=30.90]    Epoch 0:  54%|█████▍    | 14/26 [00:01<00:01,  8.82it/s, v_num=2, loss/train=30.90]    Epoch 0:  54%|█████▍    | 14/26 [00:01<00:01,  8.82it/s, v_num=2, loss/train=29.00]    Epoch 0:  58%|█████▊    | 15/26 [00:01<00:01,  9.41it/s, v_num=2, loss/train=29.00]    Epoch 0:  58%|█████▊    | 15/26 [00:01<00:01,  9.41it/s, v_num=2, loss/train=32.70]    Epoch 0:  62%|██████▏   | 16/26 [00:01<00:00, 10.00it/s, v_num=2, loss/train=32.70]    Epoch 0:  62%|██████▏   | 16/26 [00:01<00:01, 10.00it/s, v_num=2, loss/train=31.30]    Epoch 0:  65%|██████▌   | 17/26 [00:01<00:00, 10.58it/s, v_num=2, loss/train=31.30]    Epoch 0:  65%|██████▌   | 17/26 [00:01<00:00, 10.58it/s, v_num=2, loss/train=30.70]    Epoch 0:  69%|██████▉   | 18/26 [00:01<00:00, 11.15it/s, v_num=2, loss/train=30.70]    Epoch 0:  69%|██████▉   | 18/26 [00:01<00:00, 11.15it/s, v_num=2, loss/train=33.80]    Epoch 0:  73%|███████▎  | 19/26 [00:01<00:00, 11.72it/s, v_num=2, loss/train=33.80]    Epoch 0:  73%|███████▎  | 19/26 [00:01<00:00, 11.72it/s, v_num=2, loss/train=32.20]    Epoch 0:  77%|███████▋  | 20/26 [00:01<00:00, 12.29it/s, v_num=2, loss/train=32.20]    Epoch 0:  77%|███████▋  | 20/26 [00:01<00:00, 12.29it/s, v_num=2, loss/train=30.70]    Epoch 0:  81%|████████  | 21/26 [00:01<00:00, 12.85it/s, v_num=2, loss/train=30.70]    Epoch 0:  81%|████████  | 21/26 [00:01<00:00, 12.85it/s, v_num=2, loss/train=33.40]    Epoch 0:  85%|████████▍ | 22/26 [00:01<00:00, 13.41it/s, v_num=2, loss/train=33.40]    Epoch 0:  85%|████████▍ | 22/26 [00:01<00:00, 13.41it/s, v_num=2, loss/train=33.50]    Epoch 0:  88%|████████▊ | 23/26 [00:01<00:00, 13.97it/s, v_num=2, loss/train=33.50]    Epoch 0:  88%|████████▊ | 23/26 [00:01<00:00, 13.96it/s, v_num=2, loss/train=31.30]    Epoch 0:  92%|█████████▏| 24/26 [00:01<00:00, 14.49it/s, v_num=2, loss/train=31.30]    Epoch 0:  92%|█████████▏| 24/26 [00:01<00:00, 14.48it/s, v_num=2, loss/train=28.90]    Epoch 0:  96%|█████████▌| 25/26 [00:01<00:00, 15.04it/s, v_num=2, loss/train=28.90]    Epoch 0:  96%|█████████▌| 25/26 [00:01<00:00, 15.03it/s, v_num=2, loss/train=31.80]    Epoch 0: 100%|██████████| 26/26 [00:01<00:00, 15.58it/s, v_num=2, loss/train=31.80]    Epoch 0: 100%|██████████| 26/26 [00:01<00:00, 15.58it/s, v_num=2, loss/train=29.30]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]
    Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 116.93it/s]
    Validation DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 156.51it/s]
    Validation DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 173.69it/s]
    Validation DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 204.36it/s]
    Validation DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 229.94it/s]
    Validation DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 247.78it/s]
                                                                               Epoch 0: 100%|██████████| 26/26 [00:02<00:00, 10.70it/s, v_num=2, loss/train=29.30, loss/val=31.80]    Epoch 0: 100%|██████████| 26/26 [00:02<00:00, 10.69it/s, v_num=2, loss/train=29.30, loss/val=31.80]    Epoch 0:   0%|          | 0/26 [00:00<?, ?it/s, v_num=2, loss/train=29.30, loss/val=31.80]             Epoch 1:   0%|          | 0/26 [00:00<?, ?it/s, v_num=2, loss/train=29.30, loss/val=31.80]    Epoch 1:   4%|▍         | 1/26 [00:01<00:40,  0.62it/s, v_num=2, loss/train=29.30, loss/val=31.80]    Epoch 1:   4%|▍         | 1/26 [00:01<00:40,  0.62it/s, v_num=2, loss/train=33.20, loss/val=31.80]    Epoch 1:   8%|▊         | 2/26 [00:01<00:20,  1.19it/s, v_num=2, loss/train=33.20, loss/val=31.80]    Epoch 1:   8%|▊         | 2/26 [00:01<00:20,  1.18it/s, v_num=2, loss/train=28.90, loss/val=31.80]    Epoch 1:  12%|█▏        | 3/26 [00:01<00:13,  1.65it/s, v_num=2, loss/train=28.90, loss/val=31.80]    Epoch 1:  12%|█▏        | 3/26 [00:01<00:13,  1.65it/s, v_num=2, loss/train=31.20, loss/val=31.80]    Epoch 1:  15%|█▌        | 4/26 [00:01<00:10,  2.14it/s, v_num=2, loss/train=31.20, loss/val=31.80]    Epoch 1:  15%|█▌        | 4/26 [00:01<00:10,  2.14it/s, v_num=2, loss/train=32.70, loss/val=31.80]    Epoch 1:  19%|█▉        | 5/26 [00:01<00:08,  2.61it/s, v_num=2, loss/train=32.70, loss/val=31.80]    Epoch 1:  19%|█▉        | 5/26 [00:01<00:08,  2.61it/s, v_num=2, loss/train=32.30, loss/val=31.80]    Epoch 1:  23%|██▎       | 6/26 [00:01<00:06,  3.08it/s, v_num=2, loss/train=32.30, loss/val=31.80]    Epoch 1:  23%|██▎       | 6/26 [00:01<00:06,  3.08it/s, v_num=2, loss/train=31.50, loss/val=31.80]    Epoch 1:  27%|██▋       | 7/26 [00:01<00:05,  3.54it/s, v_num=2, loss/train=31.50, loss/val=31.80]    Epoch 1:  27%|██▋       | 7/26 [00:01<00:05,  3.54it/s, v_num=2, loss/train=31.50, loss/val=31.80]    Epoch 1:  31%|███       | 8/26 [00:01<00:04,  4.01it/s, v_num=2, loss/train=31.50, loss/val=31.80]    Epoch 1:  31%|███       | 8/26 [00:01<00:04,  4.01it/s, v_num=2, loss/train=33.00, loss/val=31.80]    Epoch 1:  35%|███▍      | 9/26 [00:02<00:03,  4.49it/s, v_num=2, loss/train=33.00, loss/val=31.80]    Epoch 1:  35%|███▍      | 9/26 [00:02<00:03,  4.49it/s, v_num=2, loss/train=30.70, loss/val=31.80]    Epoch 1:  38%|███▊      | 10/26 [00:02<00:03,  4.97it/s, v_num=2, loss/train=30.70, loss/val=31.80]    Epoch 1:  38%|███▊      | 10/26 [00:02<00:03,  4.97it/s, v_num=2, loss/train=34.10, loss/val=31.80]    Epoch 1:  42%|████▏     | 11/26 [00:02<00:02,  5.44it/s, v_num=2, loss/train=34.10, loss/val=31.80]    Epoch 1:  42%|████▏     | 11/26 [00:02<00:02,  5.44it/s, v_num=2, loss/train=32.80, loss/val=31.80]    Epoch 1:  46%|████▌     | 12/26 [00:02<00:02,  5.92it/s, v_num=2, loss/train=32.80, loss/val=31.80]    Epoch 1:  46%|████▌     | 12/26 [00:02<00:02,  5.92it/s, v_num=2, loss/train=28.40, loss/val=31.80]    Epoch 1:  50%|█████     | 13/26 [00:02<00:02,  6.39it/s, v_num=2, loss/train=28.40, loss/val=31.80]    Epoch 1:  50%|█████     | 13/26 [00:02<00:02,  6.39it/s, v_num=2, loss/train=30.70, loss/val=31.80]    Epoch 1:  54%|█████▍    | 14/26 [00:02<00:01,  6.86it/s, v_num=2, loss/train=30.70, loss/val=31.80]    Epoch 1:  54%|█████▍    | 14/26 [00:02<00:01,  6.86it/s, v_num=2, loss/train=31.60, loss/val=31.80]    Epoch 1:  58%|█████▊    | 15/26 [00:02<00:01,  7.33it/s, v_num=2, loss/train=31.60, loss/val=31.80]    Epoch 1:  58%|█████▊    | 15/26 [00:02<00:01,  7.33it/s, v_num=2, loss/train=28.20, loss/val=31.80]    Epoch 1:  62%|██████▏   | 16/26 [00:02<00:01,  7.79it/s, v_num=2, loss/train=28.20, loss/val=31.80]    Epoch 1:  62%|██████▏   | 16/26 [00:02<00:01,  7.79it/s, v_num=2, loss/train=32.50, loss/val=31.80]    Epoch 1:  65%|██████▌   | 17/26 [00:02<00:01,  8.26it/s, v_num=2, loss/train=32.50, loss/val=31.80]    Epoch 1:  65%|██████▌   | 17/26 [00:02<00:01,  8.26it/s, v_num=2, loss/train=29.10, loss/val=31.80]    Epoch 1:  69%|██████▉   | 18/26 [00:02<00:00,  8.72it/s, v_num=2, loss/train=29.10, loss/val=31.80]    Epoch 1:  69%|██████▉   | 18/26 [00:02<00:00,  8.72it/s, v_num=2, loss/train=31.70, loss/val=31.80]    Epoch 1:  73%|███████▎  | 19/26 [00:02<00:00,  9.18it/s, v_num=2, loss/train=31.70, loss/val=31.80]    Epoch 1:  73%|███████▎  | 19/26 [00:02<00:00,  9.18it/s, v_num=2, loss/train=27.50, loss/val=31.80]    Epoch 1:  77%|███████▋  | 20/26 [00:02<00:00,  9.63it/s, v_num=2, loss/train=27.50, loss/val=31.80]    Epoch 1:  77%|███████▋  | 20/26 [00:02<00:00,  9.63it/s, v_num=2, loss/train=28.30, loss/val=31.80]    Epoch 1:  81%|████████  | 21/26 [00:02<00:00, 10.07it/s, v_num=2, loss/train=28.30, loss/val=31.80]    Epoch 1:  81%|████████  | 21/26 [00:02<00:00, 10.07it/s, v_num=2, loss/train=30.90, loss/val=31.80]    Epoch 1:  85%|████████▍ | 22/26 [00:02<00:00, 10.53it/s, v_num=2, loss/train=30.90, loss/val=31.80]    Epoch 1:  85%|████████▍ | 22/26 [00:02<00:00, 10.52it/s, v_num=2, loss/train=30.70, loss/val=31.80]    Epoch 1:  88%|████████▊ | 23/26 [00:02<00:00, 10.98it/s, v_num=2, loss/train=30.70, loss/val=31.80]    Epoch 1:  88%|████████▊ | 23/26 [00:02<00:00, 10.98it/s, v_num=2, loss/train=28.70, loss/val=31.80]    Epoch 1:  92%|█████████▏| 24/26 [00:02<00:00, 11.42it/s, v_num=2, loss/train=28.70, loss/val=31.80]    Epoch 1:  92%|█████████▏| 24/26 [00:02<00:00, 11.42it/s, v_num=2, loss/train=30.60, loss/val=31.80]    Epoch 1:  96%|█████████▌| 25/26 [00:02<00:00, 11.85it/s, v_num=2, loss/train=30.60, loss/val=31.80]    Epoch 1:  96%|█████████▌| 25/26 [00:02<00:00, 11.85it/s, v_num=2, loss/train=31.40, loss/val=31.80]    Epoch 1: 100%|██████████| 26/26 [00:02<00:00, 12.29it/s, v_num=2, loss/train=31.40, loss/val=31.80]    Epoch 1: 100%|██████████| 26/26 [00:02<00:00, 12.29it/s, v_num=2, loss/train=32.20, loss/val=31.80]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]
    Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 84.85it/s]
    Validation DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 46.81it/s]
    Validation DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 66.56it/s]
    Validation DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 84.12it/s]
    Validation DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 100.08it/s]
    Validation DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 114.14it/s]
                                                                               Epoch 1: 100%|██████████| 26/26 [00:02<00:00,  8.99it/s, v_num=2, loss/train=32.20, loss/val=30.30]    Epoch 1: 100%|██████████| 26/26 [00:02<00:00,  8.98it/s, v_num=2, loss/train=32.20, loss/val=30.30]    Epoch 1:   0%|          | 0/26 [00:00<?, ?it/s, v_num=2, loss/train=32.20, loss/val=30.30]             Epoch 2:   0%|          | 0/26 [00:00<?, ?it/s, v_num=2, loss/train=32.20, loss/val=30.30]    Epoch 2:   4%|▍         | 1/26 [00:01<00:41,  0.60it/s, v_num=2, loss/train=32.20, loss/val=30.30]    Epoch 2:   4%|▍         | 1/26 [00:01<00:41,  0.60it/s, v_num=2, loss/train=30.90, loss/val=30.30]    Epoch 2:   8%|▊         | 2/26 [00:01<00:20,  1.16it/s, v_num=2, loss/train=30.90, loss/val=30.30]    Epoch 2:   8%|▊         | 2/26 [00:01<00:20,  1.15it/s, v_num=2, loss/train=29.30, loss/val=30.30]    Epoch 2:  12%|█▏        | 3/26 [00:01<00:13,  1.65it/s, v_num=2, loss/train=29.30, loss/val=30.30]    Epoch 2:  12%|█▏        | 3/26 [00:01<00:13,  1.65it/s, v_num=2, loss/train=33.40, loss/val=30.30]    Epoch 2:  15%|█▌        | 4/26 [00:01<00:10,  2.13it/s, v_num=2, loss/train=33.40, loss/val=30.30]    Epoch 2:  15%|█▌        | 4/26 [00:01<00:10,  2.13it/s, v_num=2, loss/train=32.20, loss/val=30.30]    Epoch 2:  19%|█▉        | 5/26 [00:01<00:08,  2.62it/s, v_num=2, loss/train=32.20, loss/val=30.30]    Epoch 2:  19%|█▉        | 5/26 [00:01<00:08,  2.62it/s, v_num=2, loss/train=31.00, loss/val=30.30]    Epoch 2:  23%|██▎       | 6/26 [00:01<00:06,  3.08it/s, v_num=2, loss/train=31.00, loss/val=30.30]    Epoch 2:  23%|██▎       | 6/26 [00:01<00:06,  3.08it/s, v_num=2, loss/train=34.10, loss/val=30.30]    Epoch 2:  27%|██▋       | 7/26 [00:01<00:05,  3.55it/s, v_num=2, loss/train=34.10, loss/val=30.30]    Epoch 2:  27%|██▋       | 7/26 [00:01<00:05,  3.55it/s, v_num=2, loss/train=32.50, loss/val=30.30]    Epoch 2:  31%|███       | 8/26 [00:01<00:04,  4.03it/s, v_num=2, loss/train=32.50, loss/val=30.30]    Epoch 2:  31%|███       | 8/26 [00:01<00:04,  4.02it/s, v_num=2, loss/train=31.10, loss/val=30.30]    Epoch 2:  35%|███▍      | 9/26 [00:01<00:03,  4.50it/s, v_num=2, loss/train=31.10, loss/val=30.30]    Epoch 2:  35%|███▍      | 9/26 [00:01<00:03,  4.50it/s, v_num=2, loss/train=32.60, loss/val=30.30]    Epoch 2:  38%|███▊      | 10/26 [00:02<00:03,  4.98it/s, v_num=2, loss/train=32.60, loss/val=30.30]    Epoch 2:  38%|███▊      | 10/26 [00:02<00:03,  4.97it/s, v_num=2, loss/train=33.20, loss/val=30.30]    Epoch 2:  42%|████▏     | 11/26 [00:02<00:02,  5.44it/s, v_num=2, loss/train=33.20, loss/val=30.30]    Epoch 2:  42%|████▏     | 11/26 [00:02<00:02,  5.44it/s, v_num=2, loss/train=30.50, loss/val=30.30]    Epoch 2:  46%|████▌     | 12/26 [00:02<00:02,  5.91it/s, v_num=2, loss/train=30.50, loss/val=30.30]    Epoch 2:  46%|████▌     | 12/26 [00:02<00:02,  5.91it/s, v_num=2, loss/train=30.60, loss/val=30.30]    Epoch 2:  50%|█████     | 13/26 [00:02<00:02,  6.36it/s, v_num=2, loss/train=30.60, loss/val=30.30]    Epoch 2:  50%|█████     | 13/26 [00:02<00:02,  6.36it/s, v_num=2, loss/train=29.70, loss/val=30.30]    Epoch 2:  54%|█████▍    | 14/26 [00:02<00:01,  6.83it/s, v_num=2, loss/train=29.70, loss/val=30.30]    Epoch 2:  54%|█████▍    | 14/26 [00:02<00:01,  6.83it/s, v_num=2, loss/train=30.20, loss/val=30.30]    Epoch 2:  58%|█████▊    | 15/26 [00:02<00:01,  7.30it/s, v_num=2, loss/train=30.20, loss/val=30.30]    Epoch 2:  58%|█████▊    | 15/26 [00:02<00:01,  7.30it/s, v_num=2, loss/train=29.80, loss/val=30.30]    Epoch 2:  62%|██████▏   | 16/26 [00:02<00:01,  7.76it/s, v_num=2, loss/train=29.80, loss/val=30.30]    Epoch 2:  62%|██████▏   | 16/26 [00:02<00:01,  7.76it/s, v_num=2, loss/train=33.50, loss/val=30.30]    Epoch 2:  65%|██████▌   | 17/26 [00:02<00:01,  8.22it/s, v_num=2, loss/train=33.50, loss/val=30.30]    Epoch 2:  65%|██████▌   | 17/26 [00:02<00:01,  8.22it/s, v_num=2, loss/train=31.00, loss/val=30.30]    Epoch 2:  69%|██████▉   | 18/26 [00:02<00:00,  8.68it/s, v_num=2, loss/train=31.00, loss/val=30.30]    Epoch 2:  69%|██████▉   | 18/26 [00:02<00:00,  8.68it/s, v_num=2, loss/train=30.90, loss/val=30.30]    Epoch 2:  73%|███████▎  | 19/26 [00:02<00:00,  9.14it/s, v_num=2, loss/train=30.90, loss/val=30.30]    Epoch 2:  73%|███████▎  | 19/26 [00:02<00:00,  9.14it/s, v_num=2, loss/train=32.50, loss/val=30.30]    Epoch 2:  77%|███████▋  | 20/26 [00:02<00:00,  9.60it/s, v_num=2, loss/train=32.50, loss/val=30.30]    Epoch 2:  77%|███████▋  | 20/26 [00:02<00:00,  9.59it/s, v_num=2, loss/train=33.20, loss/val=30.30]    Epoch 2:  81%|████████  | 21/26 [00:02<00:00, 10.04it/s, v_num=2, loss/train=33.20, loss/val=30.30]    Epoch 2:  81%|████████  | 21/26 [00:02<00:00, 10.04it/s, v_num=2, loss/train=31.70, loss/val=30.30]    Epoch 2:  85%|████████▍ | 22/26 [00:02<00:00, 10.49it/s, v_num=2, loss/train=31.70, loss/val=30.30]    Epoch 2:  85%|████████▍ | 22/26 [00:02<00:00, 10.49it/s, v_num=2, loss/train=32.90, loss/val=30.30]    Epoch 2:  88%|████████▊ | 23/26 [00:02<00:00, 10.92it/s, v_num=2, loss/train=32.90, loss/val=30.30]    Epoch 2:  88%|████████▊ | 23/26 [00:02<00:00, 10.92it/s, v_num=2, loss/train=31.60, loss/val=30.30]    Epoch 2:  92%|█████████▏| 24/26 [00:02<00:00, 11.37it/s, v_num=2, loss/train=31.60, loss/val=30.30]    Epoch 2:  92%|█████████▏| 24/26 [00:02<00:00, 11.37it/s, v_num=2, loss/train=27.70, loss/val=30.30]    Epoch 2:  96%|█████████▌| 25/26 [00:02<00:00, 11.81it/s, v_num=2, loss/train=27.70, loss/val=30.30]    Epoch 2:  96%|█████████▌| 25/26 [00:02<00:00, 11.80it/s, v_num=2, loss/train=34.30, loss/val=30.30]    Epoch 2: 100%|██████████| 26/26 [00:02<00:00, 12.25it/s, v_num=2, loss/train=34.30, loss/val=30.30]    Epoch 2: 100%|██████████| 26/26 [00:02<00:00, 12.24it/s, v_num=2, loss/train=31.50, loss/val=30.30]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]
    Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 81.90it/s]
    Validation DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 103.61it/s]
    Validation DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 98.97it/s] 
    Validation DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 120.67it/s]
    Validation DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 81.76it/s] 
    Validation DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 93.16it/s]
                                                                              Epoch 2: 100%|██████████| 26/26 [00:02<00:00,  8.91it/s, v_num=2, loss/train=31.50, loss/val=30.40]    Epoch 2: 100%|██████████| 26/26 [00:02<00:00,  8.91it/s, v_num=2, loss/train=31.50, loss/val=30.40]    Epoch 2:   0%|          | 0/26 [00:00<?, ?it/s, v_num=2, loss/train=31.50, loss/val=30.40]             Epoch 3:   0%|          | 0/26 [00:00<?, ?it/s, v_num=2, loss/train=31.50, loss/val=30.40]    Epoch 3:   4%|▍         | 1/26 [00:01<00:43,  0.58it/s, v_num=2, loss/train=31.50, loss/val=30.40]    Epoch 3:   4%|▍         | 1/26 [00:01<00:43,  0.58it/s, v_num=2, loss/train=27.70, loss/val=30.40]    Epoch 3:   8%|▊         | 2/26 [00:01<00:21,  1.12it/s, v_num=2, loss/train=27.70, loss/val=30.40]    Epoch 3:   8%|▊         | 2/26 [00:01<00:21,  1.12it/s, v_num=2, loss/train=29.20, loss/val=30.40]    Epoch 3:  12%|█▏        | 3/26 [00:01<00:13,  1.66it/s, v_num=2, loss/train=29.20, loss/val=30.40]    Epoch 3:  12%|█▏        | 3/26 [00:01<00:13,  1.65it/s, v_num=2, loss/train=29.80, loss/val=30.40]    Epoch 3:  15%|█▌        | 4/26 [00:01<00:10,  2.14it/s, v_num=2, loss/train=29.80, loss/val=30.40]    Epoch 3:  15%|█▌        | 4/26 [00:01<00:10,  2.14it/s, v_num=2, loss/train=31.00, loss/val=30.40]    Epoch 3:  19%|█▉        | 5/26 [00:01<00:07,  2.64it/s, v_num=2, loss/train=31.00, loss/val=30.40]    Epoch 3:  19%|█▉        | 5/26 [00:01<00:07,  2.64it/s, v_num=2, loss/train=32.80, loss/val=30.40]    Epoch 3:  23%|██▎       | 6/26 [00:01<00:06,  3.13it/s, v_num=2, loss/train=32.80, loss/val=30.40]    Epoch 3:  23%|██▎       | 6/26 [00:01<00:06,  3.13it/s, v_num=2, loss/train=28.00, loss/val=30.40]    Epoch 3:  27%|██▋       | 7/26 [00:01<00:05,  3.61it/s, v_num=2, loss/train=28.00, loss/val=30.40]    Epoch 3:  27%|██▋       | 7/26 [00:01<00:05,  3.61it/s, v_num=2, loss/train=29.20, loss/val=30.40]    Epoch 3:  31%|███       | 8/26 [00:01<00:04,  4.11it/s, v_num=2, loss/train=29.20, loss/val=30.40]    Epoch 3:  31%|███       | 8/26 [00:01<00:04,  4.11it/s, v_num=2, loss/train=30.60, loss/val=30.40]    Epoch 3:  35%|███▍      | 9/26 [00:01<00:03,  4.60it/s, v_num=2, loss/train=30.60, loss/val=30.40]    Epoch 3:  35%|███▍      | 9/26 [00:01<00:03,  4.60it/s, v_num=2, loss/train=29.60, loss/val=30.40]    Epoch 3:  38%|███▊      | 10/26 [00:01<00:03,  5.09it/s, v_num=2, loss/train=29.60, loss/val=30.40]    Epoch 3:  38%|███▊      | 10/26 [00:01<00:03,  5.08it/s, v_num=2, loss/train=32.00, loss/val=30.40]    Epoch 3:  42%|████▏     | 11/26 [00:02<00:02,  5.49it/s, v_num=2, loss/train=32.00, loss/val=30.40]    Epoch 3:  42%|████▏     | 11/26 [00:02<00:02,  5.49it/s, v_num=2, loss/train=32.80, loss/val=30.40]    Epoch 3:  46%|████▌     | 12/26 [00:02<00:02,  5.96it/s, v_num=2, loss/train=32.80, loss/val=30.40]    Epoch 3:  46%|████▌     | 12/26 [00:02<00:02,  5.96it/s, v_num=2, loss/train=30.10, loss/val=30.40]    Epoch 3:  50%|█████     | 13/26 [00:02<00:02,  6.44it/s, v_num=2, loss/train=30.10, loss/val=30.40]    Epoch 3:  50%|█████     | 13/26 [00:02<00:02,  6.43it/s, v_num=2, loss/train=27.90, loss/val=30.40]    Epoch 3:  54%|█████▍    | 14/26 [00:02<00:01,  6.90it/s, v_num=2, loss/train=27.90, loss/val=30.40]    Epoch 3:  54%|█████▍    | 14/26 [00:02<00:01,  6.90it/s, v_num=2, loss/train=32.40, loss/val=30.40]    Epoch 3:  58%|█████▊    | 15/26 [00:02<00:01,  7.37it/s, v_num=2, loss/train=32.40, loss/val=30.40]    Epoch 3:  58%|█████▊    | 15/26 [00:02<00:01,  7.37it/s, v_num=2, loss/train=31.40, loss/val=30.40]    Epoch 3:  62%|██████▏   | 16/26 [00:02<00:01,  7.84it/s, v_num=2, loss/train=31.40, loss/val=30.40]    Epoch 3:  62%|██████▏   | 16/26 [00:02<00:01,  7.83it/s, v_num=2, loss/train=31.70, loss/val=30.40]    Epoch 3:  65%|██████▌   | 17/26 [00:02<00:01,  8.30it/s, v_num=2, loss/train=31.70, loss/val=30.40]    Epoch 3:  65%|██████▌   | 17/26 [00:02<00:01,  8.30it/s, v_num=2, loss/train=32.70, loss/val=30.40]    Epoch 3:  69%|██████▉   | 18/26 [00:02<00:00,  8.76it/s, v_num=2, loss/train=32.70, loss/val=30.40]    Epoch 3:  69%|██████▉   | 18/26 [00:02<00:00,  8.75it/s, v_num=2, loss/train=31.70, loss/val=30.40]    Epoch 3:  73%|███████▎  | 19/26 [00:02<00:00,  9.21it/s, v_num=2, loss/train=31.70, loss/val=30.40]    Epoch 3:  73%|███████▎  | 19/26 [00:02<00:00,  9.21it/s, v_num=2, loss/train=31.70, loss/val=30.40]    Epoch 3:  77%|███████▋  | 20/26 [00:02<00:00,  9.66it/s, v_num=2, loss/train=31.70, loss/val=30.40]    Epoch 3:  77%|███████▋  | 20/26 [00:02<00:00,  9.66it/s, v_num=2, loss/train=34.10, loss/val=30.40]    Epoch 3:  81%|████████  | 21/26 [00:02<00:00, 10.10it/s, v_num=2, loss/train=34.10, loss/val=30.40]    Epoch 3:  81%|████████  | 21/26 [00:02<00:00, 10.10it/s, v_num=2, loss/train=33.80, loss/val=30.40]    Epoch 3:  85%|████████▍ | 22/26 [00:02<00:00, 10.55it/s, v_num=2, loss/train=33.80, loss/val=30.40]    Epoch 3:  85%|████████▍ | 22/26 [00:02<00:00, 10.55it/s, v_num=2, loss/train=30.80, loss/val=30.40]    Epoch 3:  88%|████████▊ | 23/26 [00:02<00:00, 10.98it/s, v_num=2, loss/train=30.80, loss/val=30.40]    Epoch 3:  88%|████████▊ | 23/26 [00:02<00:00, 10.97it/s, v_num=2, loss/train=34.50, loss/val=30.40]    Epoch 3:  92%|█████████▏| 24/26 [00:02<00:00, 11.41it/s, v_num=2, loss/train=34.50, loss/val=30.40]    Epoch 3:  92%|█████████▏| 24/26 [00:02<00:00, 11.41it/s, v_num=2, loss/train=32.80, loss/val=30.40]    Epoch 3:  96%|█████████▌| 25/26 [00:02<00:00, 11.84it/s, v_num=2, loss/train=32.80, loss/val=30.40]    Epoch 3:  96%|█████████▌| 25/26 [00:02<00:00, 11.84it/s, v_num=2, loss/train=32.90, loss/val=30.40]    Epoch 3: 100%|██████████| 26/26 [00:02<00:00, 12.28it/s, v_num=2, loss/train=32.90, loss/val=30.40]    Epoch 3: 100%|██████████| 26/26 [00:02<00:00, 12.28it/s, v_num=2, loss/train=27.60, loss/val=30.40]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]
    Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 28.22it/s]
    Validation DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 36.23it/s]
    Validation DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 46.36it/s]
    Validation DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 37.97it/s]
    Validation DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 46.40it/s]
    Validation DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 54.39it/s]
                                                                              Epoch 3: 100%|██████████| 26/26 [00:02<00:00,  8.95it/s, v_num=2, loss/train=27.60, loss/val=31.40]    Epoch 3: 100%|██████████| 26/26 [00:02<00:00,  8.95it/s, v_num=2, loss/train=27.60, loss/val=31.40]    Epoch 3:   0%|          | 0/26 [00:00<?, ?it/s, v_num=2, loss/train=27.60, loss/val=31.40]             Epoch 4:   0%|          | 0/26 [00:00<?, ?it/s, v_num=2, loss/train=27.60, loss/val=31.40]    Epoch 4:   4%|▍         | 1/26 [00:01<00:38,  0.65it/s, v_num=2, loss/train=27.60, loss/val=31.40]    Epoch 4:   4%|▍         | 1/26 [00:01<00:38,  0.65it/s, v_num=2, loss/train=32.20, loss/val=31.40]    Epoch 4:   8%|▊         | 2/26 [00:01<00:21,  1.09it/s, v_num=2, loss/train=32.20, loss/val=31.40]    Epoch 4:   8%|▊         | 2/26 [00:01<00:21,  1.09it/s, v_num=2, loss/train=33.30, loss/val=31.40]    Epoch 4:  12%|█▏        | 3/26 [00:01<00:14,  1.62it/s, v_num=2, loss/train=33.30, loss/val=31.40]    Epoch 4:  12%|█▏        | 3/26 [00:01<00:14,  1.62it/s, v_num=2, loss/train=27.70, loss/val=31.40]    Epoch 4:  15%|█▌        | 4/26 [00:01<00:10,  2.14it/s, v_num=2, loss/train=27.70, loss/val=31.40]    Epoch 4:  15%|█▌        | 4/26 [00:01<00:10,  2.14it/s, v_num=2, loss/train=31.70, loss/val=31.40]    Epoch 4:  19%|█▉        | 5/26 [00:01<00:07,  2.64it/s, v_num=2, loss/train=31.70, loss/val=31.40]    Epoch 4:  19%|█▉        | 5/26 [00:01<00:07,  2.64it/s, v_num=2, loss/train=32.50, loss/val=31.40]    Epoch 4:  23%|██▎       | 6/26 [00:01<00:06,  3.02it/s, v_num=2, loss/train=32.50, loss/val=31.40]    Epoch 4:  23%|██▎       | 6/26 [00:01<00:06,  3.02it/s, v_num=2, loss/train=28.80, loss/val=31.40]    Epoch 4:  27%|██▋       | 7/26 [00:01<00:05,  3.50it/s, v_num=2, loss/train=28.80, loss/val=31.40]    Epoch 4:  27%|██▋       | 7/26 [00:01<00:05,  3.50it/s, v_num=2, loss/train=34.40, loss/val=31.40]    Epoch 4:  31%|███       | 8/26 [00:02<00:04,  3.98it/s, v_num=2, loss/train=34.40, loss/val=31.40]    Epoch 4:  31%|███       | 8/26 [00:02<00:04,  3.98it/s, v_num=2, loss/train=29.70, loss/val=31.40]    Epoch 4:  35%|███▍      | 9/26 [00:02<00:03,  4.46it/s, v_num=2, loss/train=29.70, loss/val=31.40]    Epoch 4:  35%|███▍      | 9/26 [00:02<00:03,  4.46it/s, v_num=2, loss/train=31.50, loss/val=31.40]    Epoch 4:  38%|███▊      | 10/26 [00:02<00:03,  4.93it/s, v_num=2, loss/train=31.50, loss/val=31.40]    Epoch 4:  38%|███▊      | 10/26 [00:02<00:03,  4.93it/s, v_num=2, loss/train=31.20, loss/val=31.40]    Epoch 4:  42%|████▏     | 11/26 [00:02<00:02,  5.40it/s, v_num=2, loss/train=31.20, loss/val=31.40]    Epoch 4:  42%|████▏     | 11/26 [00:02<00:02,  5.40it/s, v_num=2, loss/train=30.60, loss/val=31.40]    Epoch 4:  46%|████▌     | 12/26 [00:02<00:02,  5.84it/s, v_num=2, loss/train=30.60, loss/val=31.40]    Epoch 4:  46%|████▌     | 12/26 [00:02<00:02,  5.84it/s, v_num=2, loss/train=29.60, loss/val=31.40]    Epoch 4:  50%|█████     | 13/26 [00:02<00:02,  6.31it/s, v_num=2, loss/train=29.60, loss/val=31.40]    Epoch 4:  50%|█████     | 13/26 [00:02<00:02,  6.31it/s, v_num=2, loss/train=32.20, loss/val=31.40]    Epoch 4:  54%|█████▍    | 14/26 [00:02<00:01,  6.78it/s, v_num=2, loss/train=32.20, loss/val=31.40]    Epoch 4:  54%|█████▍    | 14/26 [00:02<00:01,  6.78it/s, v_num=2, loss/train=31.50, loss/val=31.40]    Epoch 4:  58%|█████▊    | 15/26 [00:02<00:01,  7.25it/s, v_num=2, loss/train=31.50, loss/val=31.40]    Epoch 4:  58%|█████▊    | 15/26 [00:02<00:01,  7.25it/s, v_num=2, loss/train=32.90, loss/val=31.40]    Epoch 4:  62%|██████▏   | 16/26 [00:02<00:01,  7.71it/s, v_num=2, loss/train=32.90, loss/val=31.40]    Epoch 4:  62%|██████▏   | 16/26 [00:02<00:01,  7.70it/s, v_num=2, loss/train=30.90, loss/val=31.40]    Epoch 4:  65%|██████▌   | 17/26 [00:02<00:01,  8.17it/s, v_num=2, loss/train=30.90, loss/val=31.40]    Epoch 4:  65%|██████▌   | 17/26 [00:02<00:01,  8.16it/s, v_num=2, loss/train=32.60, loss/val=31.40]    Epoch 4:  69%|██████▉   | 18/26 [00:02<00:00,  8.62it/s, v_num=2, loss/train=32.60, loss/val=31.40]    Epoch 4:  69%|██████▉   | 18/26 [00:02<00:00,  8.62it/s, v_num=2, loss/train=30.60, loss/val=31.40]    Epoch 4:  73%|███████▎  | 19/26 [00:02<00:00,  9.08it/s, v_num=2, loss/train=30.60, loss/val=31.40]    Epoch 4:  73%|███████▎  | 19/26 [00:02<00:00,  9.08it/s, v_num=2, loss/train=30.30, loss/val=31.40]    Epoch 4:  77%|███████▋  | 20/26 [00:02<00:00,  9.53it/s, v_num=2, loss/train=30.30, loss/val=31.40]    Epoch 4:  77%|███████▋  | 20/26 [00:02<00:00,  9.53it/s, v_num=2, loss/train=30.20, loss/val=31.40]    Epoch 4:  81%|████████  | 21/26 [00:02<00:00,  9.98it/s, v_num=2, loss/train=30.20, loss/val=31.40]    Epoch 4:  81%|████████  | 21/26 [00:02<00:00,  9.98it/s, v_num=2, loss/train=32.80, loss/val=31.40]    Epoch 4:  85%|████████▍ | 22/26 [00:02<00:00, 10.42it/s, v_num=2, loss/train=32.80, loss/val=31.40]    Epoch 4:  85%|████████▍ | 22/26 [00:02<00:00, 10.42it/s, v_num=2, loss/train=31.70, loss/val=31.40]    Epoch 4:  88%|████████▊ | 23/26 [00:02<00:00, 10.86it/s, v_num=2, loss/train=31.70, loss/val=31.40]    Epoch 4:  88%|████████▊ | 23/26 [00:02<00:00, 10.86it/s, v_num=2, loss/train=33.00, loss/val=31.40]    Epoch 4:  92%|█████████▏| 24/26 [00:02<00:00, 11.30it/s, v_num=2, loss/train=33.00, loss/val=31.40]    Epoch 4:  92%|█████████▏| 24/26 [00:02<00:00, 11.30it/s, v_num=2, loss/train=33.50, loss/val=31.40]    Epoch 4:  96%|█████████▌| 25/26 [00:02<00:00, 11.73it/s, v_num=2, loss/train=33.50, loss/val=31.40]    Epoch 4:  96%|█████████▌| 25/26 [00:02<00:00, 11.73it/s, v_num=2, loss/train=33.80, loss/val=31.40]    Epoch 4: 100%|██████████| 26/26 [00:02<00:00, 12.17it/s, v_num=2, loss/train=33.80, loss/val=31.40]    Epoch 4: 100%|██████████| 26/26 [00:02<00:00, 12.17it/s, v_num=2, loss/train=29.40, loss/val=31.40]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]
    Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 89.10it/s]
    Validation DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 117.30it/s]
    Validation DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 51.80it/s] 
    Validation DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 50.18it/s]
    Validation DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 61.00it/s]
    Validation DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 70.85it/s]
                                                                              Epoch 4: 100%|██████████| 26/26 [00:02<00:00,  8.92it/s, v_num=2, loss/train=29.40, loss/val=30.90]    Epoch 4: 100%|██████████| 26/26 [00:02<00:00,  8.92it/s, v_num=2, loss/train=29.40, loss/val=30.90]    Epoch 4:   0%|          | 0/26 [00:00<?, ?it/s, v_num=2, loss/train=29.40, loss/val=30.90]             Epoch 5:   0%|          | 0/26 [00:00<?, ?it/s, v_num=2, loss/train=29.40, loss/val=30.90]    Epoch 5:   4%|▍         | 1/26 [00:01<00:42,  0.58it/s, v_num=2, loss/train=29.40, loss/val=30.90]    Epoch 5:   4%|▍         | 1/26 [00:01<00:43,  0.58it/s, v_num=2, loss/train=32.40, loss/val=30.90]    Epoch 5:   8%|▊         | 2/26 [00:01<00:22,  1.05it/s, v_num=2, loss/train=32.40, loss/val=30.90]    Epoch 5:   8%|▊         | 2/26 [00:01<00:22,  1.05it/s, v_num=2, loss/train=33.70, loss/val=30.90]    Epoch 5:  12%|█▏        | 3/26 [00:01<00:14,  1.57it/s, v_num=2, loss/train=33.70, loss/val=30.90]    Epoch 5:  12%|█▏        | 3/26 [00:01<00:14,  1.57it/s, v_num=2, loss/train=31.60, loss/val=30.90]    Epoch 5:  15%|█▌        | 4/26 [00:01<00:10,  2.09it/s, v_num=2, loss/train=31.60, loss/val=30.90]    Epoch 5:  15%|█▌        | 4/26 [00:01<00:10,  2.09it/s, v_num=2, loss/train=30.10, loss/val=30.90]    Epoch 5:  19%|█▉        | 5/26 [00:01<00:08,  2.59it/s, v_num=2, loss/train=30.10, loss/val=30.90]    Epoch 5:  19%|█▉        | 5/26 [00:01<00:08,  2.59it/s, v_num=2, loss/train=30.60, loss/val=30.90]    Epoch 5:  23%|██▎       | 6/26 [00:01<00:06,  3.08it/s, v_num=2, loss/train=30.60, loss/val=30.90]    Epoch 5:  23%|██▎       | 6/26 [00:01<00:06,  3.08it/s, v_num=2, loss/train=31.10, loss/val=30.90]    Epoch 5:  27%|██▋       | 7/26 [00:01<00:05,  3.57it/s, v_num=2, loss/train=31.10, loss/val=30.90]    Epoch 5:  27%|██▋       | 7/26 [00:01<00:05,  3.57it/s, v_num=2, loss/train=34.80, loss/val=30.90]    Epoch 5:  31%|███       | 8/26 [00:01<00:04,  4.04it/s, v_num=2, loss/train=34.80, loss/val=30.90]    Epoch 5:  31%|███       | 8/26 [00:01<00:04,  4.04it/s, v_num=2, loss/train=31.90, loss/val=30.90]    Epoch 5:  35%|███▍      | 9/26 [00:01<00:03,  4.50it/s, v_num=2, loss/train=31.90, loss/val=30.90]    Epoch 5:  35%|███▍      | 9/26 [00:01<00:03,  4.50it/s, v_num=2, loss/train=28.10, loss/val=30.90]    Epoch 5:  38%|███▊      | 10/26 [00:02<00:03,  4.89it/s, v_num=2, loss/train=28.10, loss/val=30.90]    Epoch 5:  38%|███▊      | 10/26 [00:02<00:03,  4.89it/s, v_num=2, loss/train=30.20, loss/val=30.90]    Epoch 5:  42%|████▏     | 11/26 [00:02<00:02,  5.36it/s, v_num=2, loss/train=30.20, loss/val=30.90]    Epoch 5:  42%|████▏     | 11/26 [00:02<00:02,  5.36it/s, v_num=2, loss/train=33.10, loss/val=30.90]    Epoch 5:  46%|████▌     | 12/26 [00:02<00:02,  5.82it/s, v_num=2, loss/train=33.10, loss/val=30.90]    Epoch 5:  46%|████▌     | 12/26 [00:02<00:02,  5.82it/s, v_num=2, loss/train=31.10, loss/val=30.90]    Epoch 5:  50%|█████     | 13/26 [00:02<00:02,  6.27it/s, v_num=2, loss/train=31.10, loss/val=30.90]    Epoch 5:  50%|█████     | 13/26 [00:02<00:02,  6.27it/s, v_num=2, loss/train=31.00, loss/val=30.90]    Epoch 5:  54%|█████▍    | 14/26 [00:02<00:01,  6.72it/s, v_num=2, loss/train=31.00, loss/val=30.90]    Epoch 5:  54%|█████▍    | 14/26 [00:02<00:01,  6.72it/s, v_num=2, loss/train=32.50, loss/val=30.90]    Epoch 5:  58%|█████▊    | 15/26 [00:02<00:01,  7.18it/s, v_num=2, loss/train=32.50, loss/val=30.90]    Epoch 5:  58%|█████▊    | 15/26 [00:02<00:01,  7.18it/s, v_num=2, loss/train=36.40, loss/val=30.90]    Epoch 5:  62%|██████▏   | 16/26 [00:02<00:01,  7.64it/s, v_num=2, loss/train=36.40, loss/val=30.90]    Epoch 5:  62%|██████▏   | 16/26 [00:02<00:01,  7.64it/s, v_num=2, loss/train=27.80, loss/val=30.90]    Epoch 5:  65%|██████▌   | 17/26 [00:02<00:01,  8.10it/s, v_num=2, loss/train=27.80, loss/val=30.90]    Epoch 5:  65%|██████▌   | 17/26 [00:02<00:01,  8.09it/s, v_num=2, loss/train=34.00, loss/val=30.90]    Epoch 5:  69%|██████▉   | 18/26 [00:02<00:00,  8.55it/s, v_num=2, loss/train=34.00, loss/val=30.90]    Epoch 5:  69%|██████▉   | 18/26 [00:02<00:00,  8.55it/s, v_num=2, loss/train=33.40, loss/val=30.90]    Epoch 5:  73%|███████▎  | 19/26 [00:02<00:00,  9.01it/s, v_num=2, loss/train=33.40, loss/val=30.90]    Epoch 5:  73%|███████▎  | 19/26 [00:02<00:00,  9.00it/s, v_num=2, loss/train=30.90, loss/val=30.90]    Epoch 5:  77%|███████▋  | 20/26 [00:02<00:00,  9.45it/s, v_num=2, loss/train=30.90, loss/val=30.90]    Epoch 5:  77%|███████▋  | 20/26 [00:02<00:00,  9.45it/s, v_num=2, loss/train=32.20, loss/val=30.90]    Epoch 5:  81%|████████  | 21/26 [00:02<00:00,  9.89it/s, v_num=2, loss/train=32.20, loss/val=30.90]    Epoch 5:  81%|████████  | 21/26 [00:02<00:00,  9.89it/s, v_num=2, loss/train=30.80, loss/val=30.90]    Epoch 5:  85%|████████▍ | 22/26 [00:02<00:00, 10.34it/s, v_num=2, loss/train=30.80, loss/val=30.90]    Epoch 5:  85%|████████▍ | 22/26 [00:02<00:00, 10.34it/s, v_num=2, loss/train=31.90, loss/val=30.90]    Epoch 5:  88%|████████▊ | 23/26 [00:02<00:00, 10.77it/s, v_num=2, loss/train=31.90, loss/val=30.90]    Epoch 5:  88%|████████▊ | 23/26 [00:02<00:00, 10.77it/s, v_num=2, loss/train=30.50, loss/val=30.90]    Epoch 5:  92%|█████████▏| 24/26 [00:02<00:00, 11.21it/s, v_num=2, loss/train=30.50, loss/val=30.90]    Epoch 5:  92%|█████████▏| 24/26 [00:02<00:00, 11.21it/s, v_num=2, loss/train=29.70, loss/val=30.90]    Epoch 5:  96%|█████████▌| 25/26 [00:02<00:00, 11.64it/s, v_num=2, loss/train=29.70, loss/val=30.90]    Epoch 5:  96%|█████████▌| 25/26 [00:02<00:00, 11.64it/s, v_num=2, loss/train=31.70, loss/val=30.90]    Epoch 5: 100%|██████████| 26/26 [00:02<00:00, 12.08it/s, v_num=2, loss/train=31.70, loss/val=30.90]    Epoch 5: 100%|██████████| 26/26 [00:02<00:00, 12.08it/s, v_num=2, loss/train=26.90, loss/val=30.90]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]
    Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 123.86it/s]
    Validation DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 174.03it/s]
    Validation DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 210.84it/s]
    Validation DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 235.57it/s]
    Validation DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 239.15it/s]
    Validation DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 250.55it/s]
                                                                               Epoch 5: 100%|██████████| 26/26 [00:02<00:00,  8.99it/s, v_num=2, loss/train=26.90, loss/val=30.70]    Epoch 5: 100%|██████████| 26/26 [00:02<00:00,  8.99it/s, v_num=2, loss/train=26.90, loss/val=30.70]    Epoch 5:   0%|          | 0/26 [00:00<?, ?it/s, v_num=2, loss/train=26.90, loss/val=30.70]             Epoch 6:   0%|          | 0/26 [00:00<?, ?it/s, v_num=2, loss/train=26.90, loss/val=30.70]    Epoch 6:   4%|▍         | 1/26 [00:01<00:42,  0.59it/s, v_num=2, loss/train=26.90, loss/val=30.70]    Epoch 6:   4%|▍         | 1/26 [00:01<00:42,  0.59it/s, v_num=2, loss/train=30.60, loss/val=30.70]    Epoch 6:   8%|▊         | 2/26 [00:01<00:21,  1.12it/s, v_num=2, loss/train=30.60, loss/val=30.70]    Epoch 6:   8%|▊         | 2/26 [00:01<00:21,  1.12it/s, v_num=2, loss/train=32.80, loss/val=30.70]    Epoch 6:  12%|█▏        | 3/26 [00:01<00:13,  1.65it/s, v_num=2, loss/train=32.80, loss/val=30.70]    Epoch 6:  12%|█▏        | 3/26 [00:01<00:13,  1.65it/s, v_num=2, loss/train=30.50, loss/val=30.70]    Epoch 6:  15%|█▌        | 4/26 [00:01<00:10,  2.18it/s, v_num=2, loss/train=30.50, loss/val=30.70]    Epoch 6:  15%|█▌        | 4/26 [00:01<00:10,  2.18it/s, v_num=2, loss/train=31.00, loss/val=30.70]    Epoch 6:  19%|█▉        | 5/26 [00:01<00:07,  2.70it/s, v_num=2, loss/train=31.00, loss/val=30.70]    Epoch 6:  19%|█▉        | 5/26 [00:01<00:07,  2.70it/s, v_num=2, loss/train=32.30, loss/val=30.70]    Epoch 6:  23%|██▎       | 6/26 [00:01<00:06,  3.21it/s, v_num=2, loss/train=32.30, loss/val=30.70]    Epoch 6:  23%|██▎       | 6/26 [00:01<00:06,  3.21it/s, v_num=2, loss/train=31.90, loss/val=30.70]    Epoch 6:  27%|██▋       | 7/26 [00:01<00:05,  3.71it/s, v_num=2, loss/train=31.90, loss/val=30.70]    Epoch 6:  27%|██▋       | 7/26 [00:01<00:05,  3.71it/s, v_num=2, loss/train=33.40, loss/val=30.70]    Epoch 6:  31%|███       | 8/26 [00:01<00:04,  4.19it/s, v_num=2, loss/train=33.40, loss/val=30.70]    Epoch 6:  31%|███       | 8/26 [00:01<00:04,  4.19it/s, v_num=2, loss/train=32.00, loss/val=30.70]    Epoch 6:  35%|███▍      | 9/26 [00:01<00:03,  4.66it/s, v_num=2, loss/train=32.00, loss/val=30.70]    Epoch 6:  35%|███▍      | 9/26 [00:01<00:03,  4.65it/s, v_num=2, loss/train=29.50, loss/val=30.70]    Epoch 6:  38%|███▊      | 10/26 [00:01<00:03,  5.11it/s, v_num=2, loss/train=29.50, loss/val=30.70]    Epoch 6:  38%|███▊      | 10/26 [00:01<00:03,  5.11it/s, v_num=2, loss/train=32.60, loss/val=30.70]    Epoch 6:  42%|████▏     | 11/26 [00:01<00:02,  5.58it/s, v_num=2, loss/train=32.60, loss/val=30.70]    Epoch 6:  42%|████▏     | 11/26 [00:01<00:02,  5.58it/s, v_num=2, loss/train=32.10, loss/val=30.70]    Epoch 6:  46%|████▌     | 12/26 [00:01<00:02,  6.01it/s, v_num=2, loss/train=32.10, loss/val=30.70]    Epoch 6:  46%|████▌     | 12/26 [00:01<00:02,  6.01it/s, v_num=2, loss/train=32.90, loss/val=30.70]    Epoch 6:  50%|█████     | 13/26 [00:02<00:02,  6.48it/s, v_num=2, loss/train=32.90, loss/val=30.70]    Epoch 6:  50%|█████     | 13/26 [00:02<00:02,  6.48it/s, v_num=2, loss/train=29.90, loss/val=30.70]    Epoch 6:  54%|█████▍    | 14/26 [00:02<00:01,  6.95it/s, v_num=2, loss/train=29.90, loss/val=30.70]    Epoch 6:  54%|█████▍    | 14/26 [00:02<00:01,  6.95it/s, v_num=2, loss/train=30.30, loss/val=30.70]    Epoch 6:  58%|█████▊    | 15/26 [00:02<00:01,  7.41it/s, v_num=2, loss/train=30.30, loss/val=30.70]    Epoch 6:  58%|█████▊    | 15/26 [00:02<00:01,  7.41it/s, v_num=2, loss/train=28.90, loss/val=30.70]    Epoch 6:  62%|██████▏   | 16/26 [00:02<00:01,  7.87it/s, v_num=2, loss/train=28.90, loss/val=30.70]    Epoch 6:  62%|██████▏   | 16/26 [00:02<00:01,  7.87it/s, v_num=2, loss/train=33.00, loss/val=30.70]    Epoch 6:  65%|██████▌   | 17/26 [00:02<00:01,  8.34it/s, v_num=2, loss/train=33.00, loss/val=30.70]    Epoch 6:  65%|██████▌   | 17/26 [00:02<00:01,  8.34it/s, v_num=2, loss/train=30.60, loss/val=30.70]    Epoch 6:  69%|██████▉   | 18/26 [00:02<00:00,  8.81it/s, v_num=2, loss/train=30.60, loss/val=30.70]    Epoch 6:  69%|██████▉   | 18/26 [00:02<00:00,  8.81it/s, v_num=2, loss/train=32.80, loss/val=30.70]    Epoch 6:  73%|███████▎  | 19/26 [00:02<00:00,  9.28it/s, v_num=2, loss/train=32.80, loss/val=30.70]    Epoch 6:  73%|███████▎  | 19/26 [00:02<00:00,  9.27it/s, v_num=2, loss/train=32.50, loss/val=30.70]    Epoch 6:  77%|███████▋  | 20/26 [00:02<00:00,  9.74it/s, v_num=2, loss/train=32.50, loss/val=30.70]    Epoch 6:  77%|███████▋  | 20/26 [00:02<00:00,  9.74it/s, v_num=2, loss/train=32.50, loss/val=30.70]    Epoch 6:  81%|████████  | 21/26 [00:02<00:00, 10.20it/s, v_num=2, loss/train=32.50, loss/val=30.70]    Epoch 6:  81%|████████  | 21/26 [00:02<00:00, 10.20it/s, v_num=2, loss/train=30.10, loss/val=30.70]    Epoch 6:  85%|████████▍ | 22/26 [00:02<00:00, 10.66it/s, v_num=2, loss/train=30.10, loss/val=30.70]    Epoch 6:  85%|████████▍ | 22/26 [00:02<00:00, 10.65it/s, v_num=2, loss/train=32.80, loss/val=30.70]    Epoch 6:  88%|████████▊ | 23/26 [00:02<00:00, 11.10it/s, v_num=2, loss/train=32.80, loss/val=30.70]    Epoch 6:  88%|████████▊ | 23/26 [00:02<00:00, 11.10it/s, v_num=2, loss/train=32.40, loss/val=30.70]    Epoch 6:  92%|█████████▏| 24/26 [00:02<00:00, 11.55it/s, v_num=2, loss/train=32.40, loss/val=30.70]    Epoch 6:  92%|█████████▏| 24/26 [00:02<00:00, 11.55it/s, v_num=2, loss/train=35.50, loss/val=30.70]    Epoch 6:  96%|█████████▌| 25/26 [00:02<00:00, 12.00it/s, v_num=2, loss/train=35.50, loss/val=30.70]    Epoch 6:  96%|█████████▌| 25/26 [00:02<00:00, 11.99it/s, v_num=2, loss/train=31.50, loss/val=30.70]    Epoch 6: 100%|██████████| 26/26 [00:02<00:00, 12.44it/s, v_num=2, loss/train=31.50, loss/val=30.70]    Epoch 6: 100%|██████████| 26/26 [00:02<00:00, 12.44it/s, v_num=2, loss/train=31.50, loss/val=30.70]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]
    Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 54.43it/s]
    Validation DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 16.41it/s]
    Validation DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 24.04it/s]
    Validation DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 31.36it/s]
    Validation DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 37.07it/s]
    Validation DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 43.49it/s]
                                                                              Epoch 6: 100%|██████████| 26/26 [00:02<00:00,  9.12it/s, v_num=2, loss/train=31.50, loss/val=30.40]    Epoch 6: 100%|██████████| 26/26 [00:02<00:00,  9.11it/s, v_num=2, loss/train=31.50, loss/val=30.40]    Epoch 6:   0%|          | 0/26 [00:00<?, ?it/s, v_num=2, loss/train=31.50, loss/val=30.40]             Epoch 7:   0%|          | 0/26 [00:00<?, ?it/s, v_num=2, loss/train=31.50, loss/val=30.40]    Epoch 7:   4%|▍         | 1/26 [00:01<00:29,  0.85it/s, v_num=2, loss/train=31.50, loss/val=30.40]    Epoch 7:   4%|▍         | 1/26 [00:01<00:29,  0.84it/s, v_num=2, loss/train=30.00, loss/val=30.40]    Epoch 7:   8%|▊         | 2/26 [00:01<00:19,  1.22it/s, v_num=2, loss/train=30.00, loss/val=30.40]    Epoch 7:   8%|▊         | 2/26 [00:01<00:19,  1.22it/s, v_num=2, loss/train=32.20, loss/val=30.40]    Epoch 7:  12%|█▏        | 3/26 [00:01<00:12,  1.78it/s, v_num=2, loss/train=32.20, loss/val=30.40]    Epoch 7:  12%|█▏        | 3/26 [00:01<00:12,  1.78it/s, v_num=2, loss/train=30.10, loss/val=30.40]    Epoch 7:  15%|█▌        | 4/26 [00:01<00:09,  2.32it/s, v_num=2, loss/train=30.10, loss/val=30.40]    Epoch 7:  15%|█▌        | 4/26 [00:01<00:09,  2.32it/s, v_num=2, loss/train=31.40, loss/val=30.40]    Epoch 7:  19%|█▉        | 5/26 [00:01<00:08,  2.57it/s, v_num=2, loss/train=31.40, loss/val=30.40]    Epoch 7:  19%|█▉        | 5/26 [00:01<00:08,  2.57it/s, v_num=2, loss/train=30.40, loss/val=30.40]    Epoch 7:  23%|██▎       | 6/26 [00:01<00:06,  3.04it/s, v_num=2, loss/train=30.40, loss/val=30.40]    Epoch 7:  23%|██▎       | 6/26 [00:01<00:06,  3.04it/s, v_num=2, loss/train=30.70, loss/val=30.40]    Epoch 7:  27%|██▋       | 7/26 [00:01<00:05,  3.53it/s, v_num=2, loss/train=30.70, loss/val=30.40]    Epoch 7:  27%|██▋       | 7/26 [00:01<00:05,  3.53it/s, v_num=2, loss/train=30.40, loss/val=30.40]    Epoch 7:  31%|███       | 8/26 [00:01<00:04,  4.02it/s, v_num=2, loss/train=30.40, loss/val=30.40]    Epoch 7:  31%|███       | 8/26 [00:01<00:04,  4.02it/s, v_num=2, loss/train=33.60, loss/val=30.40]    Epoch 7:  35%|███▍      | 9/26 [00:01<00:03,  4.50it/s, v_num=2, loss/train=33.60, loss/val=30.40]    Epoch 7:  35%|███▍      | 9/26 [00:01<00:03,  4.50it/s, v_num=2, loss/train=32.40, loss/val=30.40]    Epoch 7:  38%|███▊      | 10/26 [00:02<00:03,  4.99it/s, v_num=2, loss/train=32.40, loss/val=30.40]    Epoch 7:  38%|███▊      | 10/26 [00:02<00:03,  4.99it/s, v_num=2, loss/train=31.40, loss/val=30.40]    Epoch 7:  42%|████▏     | 11/26 [00:02<00:02,  5.47it/s, v_num=2, loss/train=31.40, loss/val=30.40]    Epoch 7:  42%|████▏     | 11/26 [00:02<00:02,  5.47it/s, v_num=2, loss/train=32.40, loss/val=30.40]    Epoch 7:  46%|████▌     | 12/26 [00:02<00:02,  5.94it/s, v_num=2, loss/train=32.40, loss/val=30.40]    Epoch 7:  46%|████▌     | 12/26 [00:02<00:02,  5.94it/s, v_num=2, loss/train=32.10, loss/val=30.40]    Epoch 7:  50%|█████     | 13/26 [00:02<00:02,  6.42it/s, v_num=2, loss/train=32.10, loss/val=30.40]    Epoch 7:  50%|█████     | 13/26 [00:02<00:02,  6.42it/s, v_num=2, loss/train=31.70, loss/val=30.40]    Epoch 7:  54%|█████▍    | 14/26 [00:02<00:01,  6.90it/s, v_num=2, loss/train=31.70, loss/val=30.40]    Epoch 7:  54%|█████▍    | 14/26 [00:02<00:01,  6.90it/s, v_num=2, loss/train=29.90, loss/val=30.40]    Epoch 7:  58%|█████▊    | 15/26 [00:02<00:01,  7.37it/s, v_num=2, loss/train=29.90, loss/val=30.40]    Epoch 7:  58%|█████▊    | 15/26 [00:02<00:01,  7.36it/s, v_num=2, loss/train=31.70, loss/val=30.40]    Epoch 7:  62%|██████▏   | 16/26 [00:02<00:01,  7.84it/s, v_num=2, loss/train=31.70, loss/val=30.40]    Epoch 7:  62%|██████▏   | 16/26 [00:02<00:01,  7.84it/s, v_num=2, loss/train=32.50, loss/val=30.40]    Epoch 7:  65%|██████▌   | 17/26 [00:02<00:01,  8.30it/s, v_num=2, loss/train=32.50, loss/val=30.40]    Epoch 7:  65%|██████▌   | 17/26 [00:02<00:01,  8.30it/s, v_num=2, loss/train=29.40, loss/val=30.40]    Epoch 7:  69%|██████▉   | 18/26 [00:02<00:00,  8.77it/s, v_num=2, loss/train=29.40, loss/val=30.40]    Epoch 7:  69%|██████▉   | 18/26 [00:02<00:00,  8.77it/s, v_num=2, loss/train=31.10, loss/val=30.40]    Epoch 7:  73%|███████▎  | 19/26 [00:02<00:00,  9.23it/s, v_num=2, loss/train=31.10, loss/val=30.40]    Epoch 7:  73%|███████▎  | 19/26 [00:02<00:00,  9.23it/s, v_num=2, loss/train=31.80, loss/val=30.40]    Epoch 7:  77%|███████▋  | 20/26 [00:02<00:00,  9.69it/s, v_num=2, loss/train=31.80, loss/val=30.40]    Epoch 7:  77%|███████▋  | 20/26 [00:02<00:00,  9.69it/s, v_num=2, loss/train=29.60, loss/val=30.40]    Epoch 7:  81%|████████  | 21/26 [00:02<00:00, 10.15it/s, v_num=2, loss/train=29.60, loss/val=30.40]    Epoch 7:  81%|████████  | 21/26 [00:02<00:00, 10.15it/s, v_num=2, loss/train=29.90, loss/val=30.40]    Epoch 7:  85%|████████▍ | 22/26 [00:02<00:00, 10.58it/s, v_num=2, loss/train=29.90, loss/val=30.40]    Epoch 7:  85%|████████▍ | 22/26 [00:02<00:00, 10.58it/s, v_num=2, loss/train=30.10, loss/val=30.40]    Epoch 7:  88%|████████▊ | 23/26 [00:02<00:00, 11.03it/s, v_num=2, loss/train=30.10, loss/val=30.40]    Epoch 7:  88%|████████▊ | 23/26 [00:02<00:00, 11.03it/s, v_num=2, loss/train=31.40, loss/val=30.40]    Epoch 7:  92%|█████████▏| 24/26 [00:02<00:00, 11.48it/s, v_num=2, loss/train=31.40, loss/val=30.40]    Epoch 7:  92%|█████████▏| 24/26 [00:02<00:00, 11.48it/s, v_num=2, loss/train=31.00, loss/val=30.40]    Epoch 7:  96%|█████████▌| 25/26 [00:02<00:00, 11.93it/s, v_num=2, loss/train=31.00, loss/val=30.40]    Epoch 7:  96%|█████████▌| 25/26 [00:02<00:00, 11.93it/s, v_num=2, loss/train=29.10, loss/val=30.40]    Epoch 7: 100%|██████████| 26/26 [00:02<00:00, 12.37it/s, v_num=2, loss/train=29.10, loss/val=30.40]    Epoch 7: 100%|██████████| 26/26 [00:02<00:00, 12.37it/s, v_num=2, loss/train=28.40, loss/val=30.40]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]
    Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 91.29it/s]
    Validation DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 58.92it/s]
    Validation DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 76.90it/s]
    Validation DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 93.38it/s]
    Validation DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 109.84it/s]
    Validation DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 123.49it/s]
                                                                               Epoch 7: 100%|██████████| 26/26 [00:02<00:00,  9.09it/s, v_num=2, loss/train=28.40, loss/val=30.10]    Epoch 7: 100%|██████████| 26/26 [00:02<00:00,  9.09it/s, v_num=2, loss/train=28.40, loss/val=30.10]    Epoch 7:   0%|          | 0/26 [00:00<?, ?it/s, v_num=2, loss/train=28.40, loss/val=30.10]             Epoch 8:   0%|          | 0/26 [00:00<?, ?it/s, v_num=2, loss/train=28.40, loss/val=30.10]    Epoch 8:   4%|▍         | 1/26 [00:01<00:39,  0.64it/s, v_num=2, loss/train=28.40, loss/val=30.10]    Epoch 8:   4%|▍         | 1/26 [00:01<00:39,  0.64it/s, v_num=2, loss/train=29.50, loss/val=30.10]    Epoch 8:   8%|▊         | 2/26 [00:01<00:19,  1.22it/s, v_num=2, loss/train=29.50, loss/val=30.10]    Epoch 8:   8%|▊         | 2/26 [00:01<00:19,  1.22it/s, v_num=2, loss/train=32.00, loss/val=30.10]    Epoch 8:  12%|█▏        | 3/26 [00:01<00:12,  1.78it/s, v_num=2, loss/train=32.00, loss/val=30.10]    Epoch 8:  12%|█▏        | 3/26 [00:01<00:12,  1.78it/s, v_num=2, loss/train=30.70, loss/val=30.10]    Epoch 8:  15%|█▌        | 4/26 [00:01<00:09,  2.30it/s, v_num=2, loss/train=30.70, loss/val=30.10]    Epoch 8:  15%|█▌        | 4/26 [00:01<00:09,  2.30it/s, v_num=2, loss/train=30.90, loss/val=30.10]    Epoch 8:  19%|█▉        | 5/26 [00:01<00:07,  2.73it/s, v_num=2, loss/train=30.90, loss/val=30.10]    Epoch 8:  19%|█▉        | 5/26 [00:01<00:07,  2.72it/s, v_num=2, loss/train=32.40, loss/val=30.10]    Epoch 8:  23%|██▎       | 6/26 [00:01<00:06,  3.19it/s, v_num=2, loss/train=32.40, loss/val=30.10]    Epoch 8:  23%|██▎       | 6/26 [00:01<00:06,  3.19it/s, v_num=2, loss/train=32.40, loss/val=30.10]    Epoch 8:  27%|██▋       | 7/26 [00:01<00:05,  3.64it/s, v_num=2, loss/train=32.40, loss/val=30.10]    Epoch 8:  27%|██▋       | 7/26 [00:01<00:05,  3.64it/s, v_num=2, loss/train=31.20, loss/val=30.10]    Epoch 8:  31%|███       | 8/26 [00:01<00:04,  4.12it/s, v_num=2, loss/train=31.20, loss/val=30.10]    Epoch 8:  31%|███       | 8/26 [00:01<00:04,  4.12it/s, v_num=2, loss/train=29.50, loss/val=30.10]    Epoch 8:  35%|███▍      | 9/26 [00:01<00:03,  4.61it/s, v_num=2, loss/train=29.50, loss/val=30.10]    Epoch 8:  35%|███▍      | 9/26 [00:01<00:03,  4.61it/s, v_num=2, loss/train=31.20, loss/val=30.10]    Epoch 8:  38%|███▊      | 10/26 [00:01<00:03,  5.09it/s, v_num=2, loss/train=31.20, loss/val=30.10]    Epoch 8:  38%|███▊      | 10/26 [00:01<00:03,  5.09it/s, v_num=2, loss/train=31.60, loss/val=30.10]    Epoch 8:  42%|████▏     | 11/26 [00:01<00:02,  5.58it/s, v_num=2, loss/train=31.60, loss/val=30.10]    Epoch 8:  42%|████▏     | 11/26 [00:01<00:02,  5.58it/s, v_num=2, loss/train=31.80, loss/val=30.10]    Epoch 8:  46%|████▌     | 12/26 [00:01<00:02,  6.05it/s, v_num=2, loss/train=31.80, loss/val=30.10]    Epoch 8:  46%|████▌     | 12/26 [00:01<00:02,  6.05it/s, v_num=2, loss/train=29.90, loss/val=30.10]    Epoch 8:  50%|█████     | 13/26 [00:01<00:01,  6.54it/s, v_num=2, loss/train=29.90, loss/val=30.10]    Epoch 8:  50%|█████     | 13/26 [00:01<00:01,  6.54it/s, v_num=2, loss/train=33.40, loss/val=30.10]    Epoch 8:  54%|█████▍    | 14/26 [00:01<00:01,  7.02it/s, v_num=2, loss/train=33.40, loss/val=30.10]    Epoch 8:  54%|█████▍    | 14/26 [00:01<00:01,  7.02it/s, v_num=2, loss/train=31.90, loss/val=30.10]    Epoch 8:  58%|█████▊    | 15/26 [00:01<00:01,  7.50it/s, v_num=2, loss/train=31.90, loss/val=30.10]    Epoch 8:  58%|█████▊    | 15/26 [00:01<00:01,  7.50it/s, v_num=2, loss/train=34.30, loss/val=30.10]    Epoch 8:  62%|██████▏   | 16/26 [00:02<00:01,  7.98it/s, v_num=2, loss/train=34.30, loss/val=30.10]    Epoch 8:  62%|██████▏   | 16/26 [00:02<00:01,  7.98it/s, v_num=2, loss/train=30.20, loss/val=30.10]    Epoch 8:  65%|██████▌   | 17/26 [00:02<00:01,  8.46it/s, v_num=2, loss/train=30.20, loss/val=30.10]    Epoch 8:  65%|██████▌   | 17/26 [00:02<00:01,  8.45it/s, v_num=2, loss/train=31.90, loss/val=30.10]    Epoch 8:  69%|██████▉   | 18/26 [00:02<00:00,  8.91it/s, v_num=2, loss/train=31.90, loss/val=30.10]    Epoch 8:  69%|██████▉   | 18/26 [00:02<00:00,  8.91it/s, v_num=2, loss/train=28.90, loss/val=30.10]    Epoch 8:  73%|███████▎  | 19/26 [00:02<00:00,  9.38it/s, v_num=2, loss/train=28.90, loss/val=30.10]    Epoch 8:  73%|███████▎  | 19/26 [00:02<00:00,  9.38it/s, v_num=2, loss/train=30.30, loss/val=30.10]    Epoch 8:  77%|███████▋  | 20/26 [00:02<00:00,  9.85it/s, v_num=2, loss/train=30.30, loss/val=30.10]    Epoch 8:  77%|███████▋  | 20/26 [00:02<00:00,  9.85it/s, v_num=2, loss/train=32.10, loss/val=30.10]    Epoch 8:  81%|████████  | 21/26 [00:02<00:00, 10.31it/s, v_num=2, loss/train=32.10, loss/val=30.10]    Epoch 8:  81%|████████  | 21/26 [00:02<00:00, 10.31it/s, v_num=2, loss/train=29.20, loss/val=30.10]    Epoch 8:  85%|████████▍ | 22/26 [00:02<00:00, 10.77it/s, v_num=2, loss/train=29.20, loss/val=30.10]    Epoch 8:  85%|████████▍ | 22/26 [00:02<00:00, 10.77it/s, v_num=2, loss/train=34.10, loss/val=30.10]    Epoch 8:  88%|████████▊ | 23/26 [00:02<00:00, 11.23it/s, v_num=2, loss/train=34.10, loss/val=30.10]    Epoch 8:  88%|████████▊ | 23/26 [00:02<00:00, 11.23it/s, v_num=2, loss/train=29.20, loss/val=30.10]    Epoch 8:  92%|█████████▏| 24/26 [00:02<00:00, 11.69it/s, v_num=2, loss/train=29.20, loss/val=30.10]    Epoch 8:  92%|█████████▏| 24/26 [00:02<00:00, 11.69it/s, v_num=2, loss/train=32.70, loss/val=30.10]    Epoch 8:  96%|█████████▌| 25/26 [00:02<00:00, 12.15it/s, v_num=2, loss/train=32.70, loss/val=30.10]    Epoch 8:  96%|█████████▌| 25/26 [00:02<00:00, 12.15it/s, v_num=2, loss/train=32.80, loss/val=30.10]    Epoch 8: 100%|██████████| 26/26 [00:02<00:00, 12.60it/s, v_num=2, loss/train=32.80, loss/val=30.10]    Epoch 8: 100%|██████████| 26/26 [00:02<00:00, 12.60it/s, v_num=2, loss/train=29.70, loss/val=30.10]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]
    Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 45.54it/s]
    Validation DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 18.83it/s]
    Validation DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 23.12it/s]
    Validation DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 29.65it/s]
    Validation DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 31.03it/s]
    Validation DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 35.58it/s]
                                                                              Epoch 8: 100%|██████████| 26/26 [00:02<00:00,  9.21it/s, v_num=2, loss/train=29.70, loss/val=32.20]    Epoch 8: 100%|██████████| 26/26 [00:02<00:00,  9.21it/s, v_num=2, loss/train=29.70, loss/val=32.20]    Epoch 8:   0%|          | 0/26 [00:00<?, ?it/s, v_num=2, loss/train=29.70, loss/val=32.20]             Epoch 9:   0%|          | 0/26 [00:00<?, ?it/s, v_num=2, loss/train=29.70, loss/val=32.20]    Epoch 9:   4%|▍         | 1/26 [00:01<00:35,  0.71it/s, v_num=2, loss/train=29.70, loss/val=32.20]    Epoch 9:   4%|▍         | 1/26 [00:01<00:35,  0.70it/s, v_num=2, loss/train=30.60, loss/val=32.20]    Epoch 9:   8%|▊         | 2/26 [00:01<00:18,  1.29it/s, v_num=2, loss/train=30.60, loss/val=32.20]    Epoch 9:   8%|▊         | 2/26 [00:01<00:18,  1.29it/s, v_num=2, loss/train=33.50, loss/val=32.20]    Epoch 9:  12%|█▏        | 3/26 [00:01<00:12,  1.84it/s, v_num=2, loss/train=33.50, loss/val=32.20]    Epoch 9:  12%|█▏        | 3/26 [00:01<00:12,  1.84it/s, v_num=2, loss/train=31.10, loss/val=32.20]    Epoch 9:  15%|█▌        | 4/26 [00:01<00:09,  2.33it/s, v_num=2, loss/train=31.10, loss/val=32.20]    Epoch 9:  15%|█▌        | 4/26 [00:01<00:09,  2.33it/s, v_num=2, loss/train=33.40, loss/val=32.20]    Epoch 9:  19%|█▉        | 5/26 [00:01<00:07,  2.89it/s, v_num=2, loss/train=33.40, loss/val=32.20]    Epoch 9:  19%|█▉        | 5/26 [00:01<00:07,  2.89it/s, v_num=2, loss/train=31.20, loss/val=32.20]    Epoch 9:  23%|██▎       | 6/26 [00:01<00:06,  3.06it/s, v_num=2, loss/train=31.20, loss/val=32.20]    Epoch 9:  23%|██▎       | 6/26 [00:01<00:06,  3.05it/s, v_num=2, loss/train=31.50, loss/val=32.20]    Epoch 9:  27%|██▋       | 7/26 [00:01<00:05,  3.55it/s, v_num=2, loss/train=31.50, loss/val=32.20]    Epoch 9:  27%|██▋       | 7/26 [00:01<00:05,  3.55it/s, v_num=2, loss/train=32.60, loss/val=32.20]    Epoch 9:  31%|███       | 8/26 [00:01<00:04,  4.05it/s, v_num=2, loss/train=32.60, loss/val=32.20]    Epoch 9:  31%|███       | 8/26 [00:01<00:04,  4.05it/s, v_num=2, loss/train=32.50, loss/val=32.20]    Epoch 9:  35%|███▍      | 9/26 [00:01<00:03,  4.54it/s, v_num=2, loss/train=32.50, loss/val=32.20]    Epoch 9:  35%|███▍      | 9/26 [00:01<00:03,  4.54it/s, v_num=2, loss/train=32.60, loss/val=32.20]    Epoch 9:  38%|███▊      | 10/26 [00:01<00:03,  5.03it/s, v_num=2, loss/train=32.60, loss/val=32.20]    Epoch 9:  38%|███▊      | 10/26 [00:01<00:03,  5.03it/s, v_num=2, loss/train=28.80, loss/val=32.20]    Epoch 9:  42%|████▏     | 11/26 [00:01<00:02,  5.51it/s, v_num=2, loss/train=28.80, loss/val=32.20]    Epoch 9:  42%|████▏     | 11/26 [00:01<00:02,  5.51it/s, v_num=2, loss/train=28.00, loss/val=32.20]    Epoch 9:  46%|████▌     | 12/26 [00:02<00:02,  5.98it/s, v_num=2, loss/train=28.00, loss/val=32.20]    Epoch 9:  46%|████▌     | 12/26 [00:02<00:02,  5.98it/s, v_num=2, loss/train=29.40, loss/val=32.20]    Epoch 9:  50%|█████     | 13/26 [00:02<00:02,  6.46it/s, v_num=2, loss/train=29.40, loss/val=32.20]    Epoch 9:  50%|█████     | 13/26 [00:02<00:02,  6.46it/s, v_num=2, loss/train=29.00, loss/val=32.20]    Epoch 9:  54%|█████▍    | 14/26 [00:02<00:01,  6.94it/s, v_num=2, loss/train=29.00, loss/val=32.20]    Epoch 9:  54%|█████▍    | 14/26 [00:02<00:01,  6.94it/s, v_num=2, loss/train=31.30, loss/val=32.20]    Epoch 9:  58%|█████▊    | 15/26 [00:02<00:01,  7.41it/s, v_num=2, loss/train=31.30, loss/val=32.20]    Epoch 9:  58%|█████▊    | 15/26 [00:02<00:01,  7.41it/s, v_num=2, loss/train=33.00, loss/val=32.20]    Epoch 9:  62%|██████▏   | 16/26 [00:02<00:01,  7.89it/s, v_num=2, loss/train=33.00, loss/val=32.20]    Epoch 9:  62%|██████▏   | 16/26 [00:02<00:01,  7.89it/s, v_num=2, loss/train=28.80, loss/val=32.20]    Epoch 9:  65%|██████▌   | 17/26 [00:02<00:01,  8.35it/s, v_num=2, loss/train=28.80, loss/val=32.20]    Epoch 9:  65%|██████▌   | 17/26 [00:02<00:01,  8.35it/s, v_num=2, loss/train=30.30, loss/val=32.20]    Epoch 9:  69%|██████▉   | 18/26 [00:02<00:00,  8.82it/s, v_num=2, loss/train=30.30, loss/val=32.20]    Epoch 9:  69%|██████▉   | 18/26 [00:02<00:00,  8.82it/s, v_num=2, loss/train=31.90, loss/val=32.20]    Epoch 9:  73%|███████▎  | 19/26 [00:02<00:00,  9.29it/s, v_num=2, loss/train=31.90, loss/val=32.20]    Epoch 9:  73%|███████▎  | 19/26 [00:02<00:00,  9.29it/s, v_num=2, loss/train=31.60, loss/val=32.20]    Epoch 9:  77%|███████▋  | 20/26 [00:02<00:00,  9.75it/s, v_num=2, loss/train=31.60, loss/val=32.20]    Epoch 9:  77%|███████▋  | 20/26 [00:02<00:00,  9.75it/s, v_num=2, loss/train=30.40, loss/val=32.20]    Epoch 9:  81%|████████  | 21/26 [00:02<00:00, 10.20it/s, v_num=2, loss/train=30.40, loss/val=32.20]    Epoch 9:  81%|████████  | 21/26 [00:02<00:00, 10.20it/s, v_num=2, loss/train=31.10, loss/val=32.20]    Epoch 9:  85%|████████▍ | 22/26 [00:02<00:00, 10.66it/s, v_num=2, loss/train=31.10, loss/val=32.20]    Epoch 9:  85%|████████▍ | 22/26 [00:02<00:00, 10.66it/s, v_num=2, loss/train=30.30, loss/val=32.20]    Epoch 9:  88%|████████▊ | 23/26 [00:02<00:00, 11.11it/s, v_num=2, loss/train=30.30, loss/val=32.20]    Epoch 9:  88%|████████▊ | 23/26 [00:02<00:00, 11.11it/s, v_num=2, loss/train=30.90, loss/val=32.20]    Epoch 9:  92%|█████████▏| 24/26 [00:02<00:00, 11.57it/s, v_num=2, loss/train=30.90, loss/val=32.20]    Epoch 9:  92%|█████████▏| 24/26 [00:02<00:00, 11.56it/s, v_num=2, loss/train=28.60, loss/val=32.20]    Epoch 9:  96%|█████████▌| 25/26 [00:02<00:00, 12.01it/s, v_num=2, loss/train=28.60, loss/val=32.20]    Epoch 9:  96%|█████████▌| 25/26 [00:02<00:00, 12.01it/s, v_num=2, loss/train=28.10, loss/val=32.20]    Epoch 9: 100%|██████████| 26/26 [00:02<00:00, 12.46it/s, v_num=2, loss/train=28.10, loss/val=32.20]    Epoch 9: 100%|██████████| 26/26 [00:02<00:00, 12.46it/s, v_num=2, loss/train=30.00, loss/val=32.20]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]
    Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 31.78it/s]
    Validation DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 19.33it/s]
    Validation DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 18.14it/s]
    Validation DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 23.77it/s]
    Validation DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 29.24it/s]
    Validation DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 34.44it/s]
                                                                              Epoch 9: 100%|██████████| 26/26 [00:02<00:00,  9.08it/s, v_num=2, loss/train=30.00, loss/val=30.90]    Epoch 9: 100%|██████████| 26/26 [00:02<00:00,  9.07it/s, v_num=2, loss/train=30.00, loss/val=30.90]    Epoch 9: 100%|██████████| 26/26 [00:02<00:00,  9.07it/s, v_num=2, loss/train=30.00, loss/val=30.90]
    Sanity Checking: |          | 0/? [00:00<?, ?it/s]    Sanity Checking: |          | 0/? [00:00<?, ?it/s]    Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]    Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 12.06it/s]    Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 22.52it/s]                                                                               Training: |          | 0/? [00:00<?, ?it/s]    Training: |          | 0/? [00:00<?, ?it/s]    Epoch 0:   0%|          | 0/26 [00:00<?, ?it/s]    Epoch 0:   4%|▍         | 1/26 [00:00<00:21,  1.15it/s]    Epoch 0:   4%|▍         | 1/26 [00:00<00:21,  1.14it/s, v_num=3, loss/train=31.00]    Epoch 0:   8%|▊         | 2/26 [00:01<00:12,  1.98it/s, v_num=3, loss/train=31.00]    Epoch 0:   8%|▊         | 2/26 [00:01<00:12,  1.98it/s, v_num=3, loss/train=29.60]    Epoch 0:  12%|█▏        | 3/26 [00:01<00:08,  2.68it/s, v_num=3, loss/train=29.60]    Epoch 0:  12%|█▏        | 3/26 [00:01<00:08,  2.67it/s, v_num=3, loss/train=31.40]    Epoch 0:  15%|█▌        | 4/26 [00:01<00:06,  3.19it/s, v_num=3, loss/train=31.40]    Epoch 0:  15%|█▌        | 4/26 [00:01<00:06,  3.18it/s, v_num=3, loss/train=33.00]    Epoch 0:  19%|█▉        | 5/26 [00:01<00:05,  3.87it/s, v_num=3, loss/train=33.00]    Epoch 0:  19%|█▉        | 5/26 [00:01<00:05,  3.85it/s, v_num=3, loss/train=29.40]    Epoch 0:  23%|██▎       | 6/26 [00:01<00:04,  4.33it/s, v_num=3, loss/train=29.40]    Epoch 0:  23%|██▎       | 6/26 [00:01<00:04,  4.30it/s, v_num=3, loss/train=32.00]    Epoch 0:  27%|██▋       | 7/26 [00:01<00:03,  4.87it/s, v_num=3, loss/train=32.00]    Epoch 0:  27%|██▋       | 7/26 [00:01<00:03,  4.86it/s, v_num=3, loss/train=28.90]    Epoch 0:  31%|███       | 8/26 [00:01<00:03,  5.36it/s, v_num=3, loss/train=28.90]    Epoch 0:  31%|███       | 8/26 [00:01<00:03,  5.36it/s, v_num=3, loss/train=33.20]    Epoch 0:  35%|███▍      | 9/26 [00:01<00:02,  5.94it/s, v_num=3, loss/train=33.20]    Epoch 0:  35%|███▍      | 9/26 [00:01<00:02,  5.94it/s, v_num=3, loss/train=30.70]    Epoch 0:  38%|███▊      | 10/26 [00:01<00:02,  6.53it/s, v_num=3, loss/train=30.70]    Epoch 0:  38%|███▊      | 10/26 [00:01<00:02,  6.52it/s, v_num=3, loss/train=32.40]    Epoch 0:  42%|████▏     | 11/26 [00:01<00:02,  7.13it/s, v_num=3, loss/train=32.40]    Epoch 0:  42%|████▏     | 11/26 [00:01<00:02,  7.12it/s, v_num=3, loss/train=32.00]    Epoch 0:  46%|████▌     | 12/26 [00:01<00:01,  7.71it/s, v_num=3, loss/train=32.00]    Epoch 0:  46%|████▌     | 12/26 [00:01<00:01,  7.70it/s, v_num=3, loss/train=32.10]    Epoch 0:  50%|█████     | 13/26 [00:01<00:01,  8.28it/s, v_num=3, loss/train=32.10]    Epoch 0:  50%|█████     | 13/26 [00:01<00:01,  8.28it/s, v_num=3, loss/train=30.90]    Epoch 0:  54%|█████▍    | 14/26 [00:01<00:01,  8.86it/s, v_num=3, loss/train=30.90]    Epoch 0:  54%|█████▍    | 14/26 [00:01<00:01,  8.85it/s, v_num=3, loss/train=29.70]    Epoch 0:  58%|█████▊    | 15/26 [00:01<00:01,  9.38it/s, v_num=3, loss/train=29.70]    Epoch 0:  58%|█████▊    | 15/26 [00:01<00:01,  9.38it/s, v_num=3, loss/train=30.80]    Epoch 0:  62%|██████▏   | 16/26 [00:01<00:01,  9.96it/s, v_num=3, loss/train=30.80]    Epoch 0:  62%|██████▏   | 16/26 [00:01<00:01,  9.96it/s, v_num=3, loss/train=33.70]    Epoch 0:  65%|██████▌   | 17/26 [00:01<00:00, 10.54it/s, v_num=3, loss/train=33.70]    Epoch 0:  65%|██████▌   | 17/26 [00:01<00:00, 10.54it/s, v_num=3, loss/train=33.10]    Epoch 0:  69%|██████▉   | 18/26 [00:01<00:00, 11.12it/s, v_num=3, loss/train=33.10]    Epoch 0:  69%|██████▉   | 18/26 [00:01<00:00, 11.12it/s, v_num=3, loss/train=32.60]    Epoch 0:  73%|███████▎  | 19/26 [00:01<00:00, 11.67it/s, v_num=3, loss/train=32.60]    Epoch 0:  73%|███████▎  | 19/26 [00:01<00:00, 11.66it/s, v_num=3, loss/train=29.60]    Epoch 0:  77%|███████▋  | 20/26 [00:01<00:00, 12.23it/s, v_num=3, loss/train=29.60]    Epoch 0:  77%|███████▋  | 20/26 [00:01<00:00, 12.23it/s, v_num=3, loss/train=31.40]    Epoch 0:  81%|████████  | 21/26 [00:01<00:00, 12.80it/s, v_num=3, loss/train=31.40]    Epoch 0:  81%|████████  | 21/26 [00:01<00:00, 12.79it/s, v_num=3, loss/train=32.50]    Epoch 0:  85%|████████▍ | 22/26 [00:01<00:00, 13.35it/s, v_num=3, loss/train=32.50]    Epoch 0:  85%|████████▍ | 22/26 [00:01<00:00, 13.35it/s, v_num=3, loss/train=30.10]    Epoch 0:  88%|████████▊ | 23/26 [00:01<00:00, 13.89it/s, v_num=3, loss/train=30.10]    Epoch 0:  88%|████████▊ | 23/26 [00:01<00:00, 13.89it/s, v_num=3, loss/train=30.40]    Epoch 0:  92%|█████████▏| 24/26 [00:01<00:00, 14.44it/s, v_num=3, loss/train=30.40]    Epoch 0:  92%|█████████▏| 24/26 [00:01<00:00, 14.44it/s, v_num=3, loss/train=30.10]    Epoch 0:  96%|█████████▌| 25/26 [00:01<00:00, 14.98it/s, v_num=3, loss/train=30.10]    Epoch 0:  96%|█████████▌| 25/26 [00:01<00:00, 14.98it/s, v_num=3, loss/train=34.80]    Epoch 0: 100%|██████████| 26/26 [00:01<00:00, 15.52it/s, v_num=3, loss/train=34.80]    Epoch 0: 100%|██████████| 26/26 [00:01<00:00, 15.52it/s, v_num=3, loss/train=27.20]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]
    Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 142.88it/s]
    Validation DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 74.90it/s] 
    Validation DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 73.10it/s]
    Validation DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 92.33it/s]
    Validation DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 109.87it/s]
    Validation DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 125.11it/s]
                                                                               Epoch 0: 100%|██████████| 26/26 [00:02<00:00, 10.68it/s, v_num=3, loss/train=27.20, loss/val=31.30]    Epoch 0: 100%|██████████| 26/26 [00:02<00:00, 10.68it/s, v_num=3, loss/train=27.20, loss/val=31.30]    Epoch 0:   0%|          | 0/26 [00:00<?, ?it/s, v_num=3, loss/train=27.20, loss/val=31.30]             Epoch 1:   0%|          | 0/26 [00:00<?, ?it/s, v_num=3, loss/train=27.20, loss/val=31.30]    Epoch 1:   4%|▍         | 1/26 [00:01<00:36,  0.69it/s, v_num=3, loss/train=27.20, loss/val=31.30]    Epoch 1:   4%|▍         | 1/26 [00:01<00:36,  0.69it/s, v_num=3, loss/train=34.40, loss/val=31.30]    Epoch 1:   8%|▊         | 2/26 [00:01<00:18,  1.32it/s, v_num=3, loss/train=34.40, loss/val=31.30]    Epoch 1:   8%|▊         | 2/26 [00:01<00:18,  1.32it/s, v_num=3, loss/train=30.80, loss/val=31.30]    Epoch 1:  12%|█▏        | 3/26 [00:01<00:13,  1.75it/s, v_num=3, loss/train=30.80, loss/val=31.30]    Epoch 1:  12%|█▏        | 3/26 [00:01<00:13,  1.75it/s, v_num=3, loss/train=31.40, loss/val=31.30]    Epoch 1:  15%|█▌        | 4/26 [00:01<00:09,  2.24it/s, v_num=3, loss/train=31.40, loss/val=31.30]    Epoch 1:  15%|█▌        | 4/26 [00:01<00:09,  2.24it/s, v_num=3, loss/train=31.20, loss/val=31.30]    Epoch 1:  19%|█▉        | 5/26 [00:01<00:07,  2.76it/s, v_num=3, loss/train=31.20, loss/val=31.30]    Epoch 1:  19%|█▉        | 5/26 [00:01<00:07,  2.75it/s, v_num=3, loss/train=33.70, loss/val=31.30]    Epoch 1:  23%|██▎       | 6/26 [00:01<00:06,  3.22it/s, v_num=3, loss/train=33.70, loss/val=31.30]    Epoch 1:  23%|██▎       | 6/26 [00:01<00:06,  3.22it/s, v_num=3, loss/train=36.70, loss/val=31.30]    Epoch 1:  27%|██▋       | 7/26 [00:01<00:05,  3.71it/s, v_num=3, loss/train=36.70, loss/val=31.30]    Epoch 1:  27%|██▋       | 7/26 [00:01<00:05,  3.71it/s, v_num=3, loss/train=32.00, loss/val=31.30]    Epoch 1:  31%|███       | 8/26 [00:01<00:04,  4.21it/s, v_num=3, loss/train=32.00, loss/val=31.30]    Epoch 1:  31%|███       | 8/26 [00:01<00:04,  4.20it/s, v_num=3, loss/train=33.70, loss/val=31.30]    Epoch 1:  35%|███▍      | 9/26 [00:01<00:03,  4.68it/s, v_num=3, loss/train=33.70, loss/val=31.30]    Epoch 1:  35%|███▍      | 9/26 [00:01<00:03,  4.68it/s, v_num=3, loss/train=31.20, loss/val=31.30]    Epoch 1:  38%|███▊      | 10/26 [00:01<00:03,  5.15it/s, v_num=3, loss/train=31.20, loss/val=31.30]    Epoch 1:  38%|███▊      | 10/26 [00:01<00:03,  5.14it/s, v_num=3, loss/train=30.20, loss/val=31.30]    Epoch 1:  42%|████▏     | 11/26 [00:01<00:02,  5.63it/s, v_num=3, loss/train=30.20, loss/val=31.30]    Epoch 1:  42%|████▏     | 11/26 [00:01<00:02,  5.63it/s, v_num=3, loss/train=30.50, loss/val=31.30]    Epoch 1:  46%|████▌     | 12/26 [00:01<00:02,  6.12it/s, v_num=3, loss/train=30.50, loss/val=31.30]    Epoch 1:  46%|████▌     | 12/26 [00:01<00:02,  6.12it/s, v_num=3, loss/train=32.90, loss/val=31.30]    Epoch 1:  50%|█████     | 13/26 [00:01<00:01,  6.61it/s, v_num=3, loss/train=32.90, loss/val=31.30]    Epoch 1:  50%|█████     | 13/26 [00:01<00:01,  6.60it/s, v_num=3, loss/train=32.60, loss/val=31.30]    Epoch 1:  54%|█████▍    | 14/26 [00:01<00:01,  7.04it/s, v_num=3, loss/train=32.60, loss/val=31.30]    Epoch 1:  54%|█████▍    | 14/26 [00:01<00:01,  7.04it/s, v_num=3, loss/train=31.10, loss/val=31.30]    Epoch 1:  58%|█████▊    | 15/26 [00:01<00:01,  7.52it/s, v_num=3, loss/train=31.10, loss/val=31.30]    Epoch 1:  58%|█████▊    | 15/26 [00:01<00:01,  7.52it/s, v_num=3, loss/train=29.10, loss/val=31.30]    Epoch 1:  62%|██████▏   | 16/26 [00:02<00:01,  7.99it/s, v_num=3, loss/train=29.10, loss/val=31.30]    Epoch 1:  62%|██████▏   | 16/26 [00:02<00:01,  7.99it/s, v_num=3, loss/train=32.10, loss/val=31.30]    Epoch 1:  65%|██████▌   | 17/26 [00:02<00:01,  8.47it/s, v_num=3, loss/train=32.10, loss/val=31.30]    Epoch 1:  65%|██████▌   | 17/26 [00:02<00:01,  8.47it/s, v_num=3, loss/train=33.90, loss/val=31.30]    Epoch 1:  69%|██████▉   | 18/26 [00:02<00:00,  8.94it/s, v_num=3, loss/train=33.90, loss/val=31.30]    Epoch 1:  69%|██████▉   | 18/26 [00:02<00:00,  8.94it/s, v_num=3, loss/train=29.80, loss/val=31.30]    Epoch 1:  73%|███████▎  | 19/26 [00:02<00:00,  9.41it/s, v_num=3, loss/train=29.80, loss/val=31.30]    Epoch 1:  73%|███████▎  | 19/26 [00:02<00:00,  9.41it/s, v_num=3, loss/train=31.10, loss/val=31.30]    Epoch 1:  77%|███████▋  | 20/26 [00:02<00:00,  9.88it/s, v_num=3, loss/train=31.10, loss/val=31.30]    Epoch 1:  77%|███████▋  | 20/26 [00:02<00:00,  9.87it/s, v_num=3, loss/train=32.40, loss/val=31.30]    Epoch 1:  81%|████████  | 21/26 [00:02<00:00, 10.34it/s, v_num=3, loss/train=32.40, loss/val=31.30]    Epoch 1:  81%|████████  | 21/26 [00:02<00:00, 10.34it/s, v_num=3, loss/train=30.80, loss/val=31.30]    Epoch 1:  85%|████████▍ | 22/26 [00:02<00:00, 10.80it/s, v_num=3, loss/train=30.80, loss/val=31.30]    Epoch 1:  85%|████████▍ | 22/26 [00:02<00:00, 10.80it/s, v_num=3, loss/train=31.10, loss/val=31.30]    Epoch 1:  88%|████████▊ | 23/26 [00:02<00:00, 11.26it/s, v_num=3, loss/train=31.10, loss/val=31.30]    Epoch 1:  88%|████████▊ | 23/26 [00:02<00:00, 11.25it/s, v_num=3, loss/train=32.20, loss/val=31.30]    Epoch 1:  92%|█████████▏| 24/26 [00:02<00:00, 11.71it/s, v_num=3, loss/train=32.20, loss/val=31.30]    Epoch 1:  92%|█████████▏| 24/26 [00:02<00:00, 11.70it/s, v_num=3, loss/train=32.80, loss/val=31.30]    Epoch 1:  96%|█████████▌| 25/26 [00:02<00:00, 12.16it/s, v_num=3, loss/train=32.80, loss/val=31.30]    Epoch 1:  96%|█████████▌| 25/26 [00:02<00:00, 12.15it/s, v_num=3, loss/train=31.60, loss/val=31.30]    Epoch 1: 100%|██████████| 26/26 [00:02<00:00, 12.61it/s, v_num=3, loss/train=31.60, loss/val=31.30]    Epoch 1: 100%|██████████| 26/26 [00:02<00:00, 12.61it/s, v_num=3, loss/train=27.30, loss/val=31.30]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]
    Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 29.69it/s]
    Validation DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 17.42it/s]
    Validation DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 25.48it/s]
    Validation DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 33.20it/s]
    Validation DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 40.57it/s]
    Validation DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 47.49it/s]
                                                                              Epoch 1: 100%|██████████| 26/26 [00:02<00:00,  9.11it/s, v_num=3, loss/train=27.30, loss/val=30.50]    Epoch 1: 100%|██████████| 26/26 [00:02<00:00,  9.11it/s, v_num=3, loss/train=27.30, loss/val=30.50]    Epoch 1:   0%|          | 0/26 [00:00<?, ?it/s, v_num=3, loss/train=27.30, loss/val=30.50]             Epoch 2:   0%|          | 0/26 [00:00<?, ?it/s, v_num=3, loss/train=27.30, loss/val=30.50]    Epoch 2:   4%|▍         | 1/26 [00:01<00:42,  0.58it/s, v_num=3, loss/train=27.30, loss/val=30.50]    Epoch 2:   4%|▍         | 1/26 [00:01<00:43,  0.58it/s, v_num=3, loss/train=34.80, loss/val=30.50]    Epoch 2:   8%|▊         | 2/26 [00:01<00:21,  1.12it/s, v_num=3, loss/train=34.80, loss/val=30.50]    Epoch 2:   8%|▊         | 2/26 [00:01<00:21,  1.12it/s, v_num=3, loss/train=31.70, loss/val=30.50]    Epoch 2:  12%|█▏        | 3/26 [00:01<00:13,  1.66it/s, v_num=3, loss/train=31.70, loss/val=30.50]    Epoch 2:  12%|█▏        | 3/26 [00:01<00:13,  1.66it/s, v_num=3, loss/train=31.80, loss/val=30.50]    Epoch 2:  15%|█▌        | 4/26 [00:01<00:10,  2.18it/s, v_num=3, loss/train=31.80, loss/val=30.50]    Epoch 2:  15%|█▌        | 4/26 [00:01<00:10,  2.18it/s, v_num=3, loss/train=30.60, loss/val=30.50]    Epoch 2:  19%|█▉        | 5/26 [00:01<00:07,  2.64it/s, v_num=3, loss/train=30.60, loss/val=30.50]    Epoch 2:  19%|█▉        | 5/26 [00:01<00:07,  2.64it/s, v_num=3, loss/train=29.30, loss/val=30.50]    Epoch 2:  23%|██▎       | 6/26 [00:01<00:06,  3.10it/s, v_num=3, loss/train=29.30, loss/val=30.50]    Epoch 2:  23%|██▎       | 6/26 [00:01<00:06,  3.10it/s, v_num=3, loss/train=31.50, loss/val=30.50]    Epoch 2:  27%|██▋       | 7/26 [00:01<00:05,  3.57it/s, v_num=3, loss/train=31.50, loss/val=30.50]    Epoch 2:  27%|██▋       | 7/26 [00:01<00:05,  3.57it/s, v_num=3, loss/train=32.30, loss/val=30.50]    Epoch 2:  31%|███       | 8/26 [00:01<00:04,  4.06it/s, v_num=3, loss/train=32.30, loss/val=30.50]    Epoch 2:  31%|███       | 8/26 [00:01<00:04,  4.06it/s, v_num=3, loss/train=30.50, loss/val=30.50]    Epoch 2:  35%|███▍      | 9/26 [00:01<00:03,  4.54it/s, v_num=3, loss/train=30.50, loss/val=30.50]    Epoch 2:  35%|███▍      | 9/26 [00:01<00:03,  4.54it/s, v_num=3, loss/train=30.40, loss/val=30.50]    Epoch 2:  38%|███▊      | 10/26 [00:01<00:03,  5.02it/s, v_num=3, loss/train=30.40, loss/val=30.50]    Epoch 2:  38%|███▊      | 10/26 [00:01<00:03,  5.02it/s, v_num=3, loss/train=32.00, loss/val=30.50]    Epoch 2:  42%|████▏     | 11/26 [00:02<00:02,  5.45it/s, v_num=3, loss/train=32.00, loss/val=30.50]    Epoch 2:  42%|████▏     | 11/26 [00:02<00:02,  5.44it/s, v_num=3, loss/train=31.10, loss/val=30.50]    Epoch 2:  46%|████▌     | 12/26 [00:02<00:02,  5.92it/s, v_num=3, loss/train=31.10, loss/val=30.50]    Epoch 2:  46%|████▌     | 12/26 [00:02<00:02,  5.91it/s, v_num=3, loss/train=31.90, loss/val=30.50]    Epoch 2:  50%|█████     | 13/26 [00:02<00:02,  6.39it/s, v_num=3, loss/train=31.90, loss/val=30.50]    Epoch 2:  50%|█████     | 13/26 [00:02<00:02,  6.39it/s, v_num=3, loss/train=28.20, loss/val=30.50]    Epoch 2:  54%|█████▍    | 14/26 [00:02<00:01,  6.86it/s, v_num=3, loss/train=28.20, loss/val=30.50]    Epoch 2:  54%|█████▍    | 14/26 [00:02<00:01,  6.86it/s, v_num=3, loss/train=29.90, loss/val=30.50]    Epoch 2:  58%|█████▊    | 15/26 [00:02<00:01,  7.33it/s, v_num=3, loss/train=29.90, loss/val=30.50]    Epoch 2:  58%|█████▊    | 15/26 [00:02<00:01,  7.33it/s, v_num=3, loss/train=31.90, loss/val=30.50]    Epoch 2:  62%|██████▏   | 16/26 [00:02<00:01,  7.80it/s, v_num=3, loss/train=31.90, loss/val=30.50]    Epoch 2:  62%|██████▏   | 16/26 [00:02<00:01,  7.80it/s, v_num=3, loss/train=33.40, loss/val=30.50]    Epoch 2:  65%|██████▌   | 17/26 [00:02<00:01,  8.27it/s, v_num=3, loss/train=33.40, loss/val=30.50]    Epoch 2:  65%|██████▌   | 17/26 [00:02<00:01,  8.27it/s, v_num=3, loss/train=28.10, loss/val=30.50]    Epoch 2:  69%|██████▉   | 18/26 [00:02<00:00,  8.73it/s, v_num=3, loss/train=28.10, loss/val=30.50]    Epoch 2:  69%|██████▉   | 18/26 [00:02<00:00,  8.73it/s, v_num=3, loss/train=33.90, loss/val=30.50]    Epoch 2:  73%|███████▎  | 19/26 [00:02<00:00,  9.19it/s, v_num=3, loss/train=33.90, loss/val=30.50]    Epoch 2:  73%|███████▎  | 19/26 [00:02<00:00,  9.19it/s, v_num=3, loss/train=31.00, loss/val=30.50]    Epoch 2:  77%|███████▋  | 20/26 [00:02<00:00,  9.65it/s, v_num=3, loss/train=31.00, loss/val=30.50]    Epoch 2:  77%|███████▋  | 20/26 [00:02<00:00,  9.65it/s, v_num=3, loss/train=31.60, loss/val=30.50]    Epoch 2:  81%|████████  | 21/26 [00:02<00:00, 10.10it/s, v_num=3, loss/train=31.60, loss/val=30.50]    Epoch 2:  81%|████████  | 21/26 [00:02<00:00, 10.10it/s, v_num=3, loss/train=30.30, loss/val=30.50]    Epoch 2:  85%|████████▍ | 22/26 [00:02<00:00, 10.55it/s, v_num=3, loss/train=30.30, loss/val=30.50]    Epoch 2:  85%|████████▍ | 22/26 [00:02<00:00, 10.55it/s, v_num=3, loss/train=30.80, loss/val=30.50]    Epoch 2:  88%|████████▊ | 23/26 [00:02<00:00, 10.99it/s, v_num=3, loss/train=30.80, loss/val=30.50]    Epoch 2:  88%|████████▊ | 23/26 [00:02<00:00, 10.99it/s, v_num=3, loss/train=27.20, loss/val=30.50]    Epoch 2:  92%|█████████▏| 24/26 [00:02<00:00, 11.44it/s, v_num=3, loss/train=27.20, loss/val=30.50]    Epoch 2:  92%|█████████▏| 24/26 [00:02<00:00, 11.44it/s, v_num=3, loss/train=29.90, loss/val=30.50]    Epoch 2:  96%|█████████▌| 25/26 [00:02<00:00, 11.88it/s, v_num=3, loss/train=29.90, loss/val=30.50]    Epoch 2:  96%|█████████▌| 25/26 [00:02<00:00, 11.88it/s, v_num=3, loss/train=33.10, loss/val=30.50]    Epoch 2: 100%|██████████| 26/26 [00:02<00:00, 12.33it/s, v_num=3, loss/train=33.10, loss/val=30.50]    Epoch 2: 100%|██████████| 26/26 [00:02<00:00, 12.32it/s, v_num=3, loss/train=31.00, loss/val=30.50]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]
    Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 128.47it/s]
    Validation DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 170.83it/s]
    Validation DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 143.97it/s]
    Validation DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 163.23it/s]
    Validation DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 69.94it/s] 
    Validation DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 80.44it/s]
                                                                              Epoch 2: 100%|██████████| 26/26 [00:02<00:00,  9.05it/s, v_num=3, loss/train=31.00, loss/val=30.60]    Epoch 2: 100%|██████████| 26/26 [00:02<00:00,  9.04it/s, v_num=3, loss/train=31.00, loss/val=30.60]    Epoch 2:   0%|          | 0/26 [00:00<?, ?it/s, v_num=3, loss/train=31.00, loss/val=30.60]             Epoch 3:   0%|          | 0/26 [00:00<?, ?it/s, v_num=3, loss/train=31.00, loss/val=30.60]    Epoch 3:   4%|▍         | 1/26 [00:01<00:36,  0.68it/s, v_num=3, loss/train=31.00, loss/val=30.60]    Epoch 3:   4%|▍         | 1/26 [00:01<00:36,  0.68it/s, v_num=3, loss/train=30.80, loss/val=30.60]    Epoch 3:   8%|▊         | 2/26 [00:01<00:18,  1.29it/s, v_num=3, loss/train=30.80, loss/val=30.60]    Epoch 3:   8%|▊         | 2/26 [00:01<00:18,  1.29it/s, v_num=3, loss/train=30.20, loss/val=30.60]    Epoch 3:  12%|█▏        | 3/26 [00:01<00:14,  1.63it/s, v_num=3, loss/train=30.20, loss/val=30.60]    Epoch 3:  12%|█▏        | 3/26 [00:01<00:14,  1.63it/s, v_num=3, loss/train=28.30, loss/val=30.60]    Epoch 3:  15%|█▌        | 4/26 [00:01<00:10,  2.14it/s, v_num=3, loss/train=28.30, loss/val=30.60]    Epoch 3:  15%|█▌        | 4/26 [00:01<00:10,  2.14it/s, v_num=3, loss/train=30.90, loss/val=30.60]    Epoch 3:  19%|█▉        | 5/26 [00:01<00:08,  2.60it/s, v_num=3, loss/train=30.90, loss/val=30.60]    Epoch 3:  19%|█▉        | 5/26 [00:01<00:08,  2.60it/s, v_num=3, loss/train=29.70, loss/val=30.60]    Epoch 3:  23%|██▎       | 6/26 [00:01<00:06,  3.09it/s, v_num=3, loss/train=29.70, loss/val=30.60]    Epoch 3:  23%|██▎       | 6/26 [00:01<00:06,  3.09it/s, v_num=3, loss/train=30.40, loss/val=30.60]    Epoch 3:  27%|██▋       | 7/26 [00:01<00:05,  3.57it/s, v_num=3, loss/train=30.40, loss/val=30.60]    Epoch 3:  27%|██▋       | 7/26 [00:01<00:05,  3.57it/s, v_num=3, loss/train=30.60, loss/val=30.60]    Epoch 3:  31%|███       | 8/26 [00:01<00:04,  4.05it/s, v_num=3, loss/train=30.60, loss/val=30.60]    Epoch 3:  31%|███       | 8/26 [00:01<00:04,  4.04it/s, v_num=3, loss/train=32.30, loss/val=30.60]    Epoch 3:  35%|███▍      | 9/26 [00:01<00:03,  4.52it/s, v_num=3, loss/train=32.30, loss/val=30.60]    Epoch 3:  35%|███▍      | 9/26 [00:01<00:03,  4.52it/s, v_num=3, loss/train=32.40, loss/val=30.60]    Epoch 3:  38%|███▊      | 10/26 [00:02<00:03,  4.99it/s, v_num=3, loss/train=32.40, loss/val=30.60]    Epoch 3:  38%|███▊      | 10/26 [00:02<00:03,  4.99it/s, v_num=3, loss/train=27.80, loss/val=30.60]    Epoch 3:  42%|████▏     | 11/26 [00:02<00:02,  5.46it/s, v_num=3, loss/train=27.80, loss/val=30.60]    Epoch 3:  42%|████▏     | 11/26 [00:02<00:02,  5.46it/s, v_num=3, loss/train=33.50, loss/val=30.60]    Epoch 3:  46%|████▌     | 12/26 [00:02<00:02,  5.93it/s, v_num=3, loss/train=33.50, loss/val=30.60]    Epoch 3:  46%|████▌     | 12/26 [00:02<00:02,  5.93it/s, v_num=3, loss/train=31.30, loss/val=30.60]    Epoch 3:  50%|█████     | 13/26 [00:02<00:02,  6.35it/s, v_num=3, loss/train=31.30, loss/val=30.60]    Epoch 3:  50%|█████     | 13/26 [00:02<00:02,  6.35it/s, v_num=3, loss/train=28.10, loss/val=30.60]    Epoch 3:  54%|█████▍    | 14/26 [00:02<00:01,  6.82it/s, v_num=3, loss/train=28.10, loss/val=30.60]    Epoch 3:  54%|█████▍    | 14/26 [00:02<00:01,  6.82it/s, v_num=3, loss/train=31.20, loss/val=30.60]    Epoch 3:  58%|█████▊    | 15/26 [00:02<00:01,  7.28it/s, v_num=3, loss/train=31.20, loss/val=30.60]    Epoch 3:  58%|█████▊    | 15/26 [00:02<00:01,  7.28it/s, v_num=3, loss/train=30.40, loss/val=30.60]    Epoch 3:  62%|██████▏   | 16/26 [00:02<00:01,  7.75it/s, v_num=3, loss/train=30.40, loss/val=30.60]    Epoch 3:  62%|██████▏   | 16/26 [00:02<00:01,  7.74it/s, v_num=3, loss/train=27.30, loss/val=30.60]    Epoch 3:  65%|██████▌   | 17/26 [00:02<00:01,  8.21it/s, v_num=3, loss/train=27.30, loss/val=30.60]    Epoch 3:  65%|██████▌   | 17/26 [00:02<00:01,  8.21it/s, v_num=3, loss/train=33.60, loss/val=30.60]    Epoch 3:  69%|██████▉   | 18/26 [00:02<00:00,  8.67it/s, v_num=3, loss/train=33.60, loss/val=30.60]    Epoch 3:  69%|██████▉   | 18/26 [00:02<00:00,  8.67it/s, v_num=3, loss/train=30.20, loss/val=30.60]    Epoch 3:  73%|███████▎  | 19/26 [00:02<00:00,  9.13it/s, v_num=3, loss/train=30.20, loss/val=30.60]    Epoch 3:  73%|███████▎  | 19/26 [00:02<00:00,  9.13it/s, v_num=3, loss/train=33.10, loss/val=30.60]    Epoch 3:  77%|███████▋  | 20/26 [00:02<00:00,  9.58it/s, v_num=3, loss/train=33.10, loss/val=30.60]    Epoch 3:  77%|███████▋  | 20/26 [00:02<00:00,  9.58it/s, v_num=3, loss/train=30.30, loss/val=30.60]    Epoch 3:  81%|████████  | 21/26 [00:02<00:00, 10.04it/s, v_num=3, loss/train=30.30, loss/val=30.60]    Epoch 3:  81%|████████  | 21/26 [00:02<00:00, 10.03it/s, v_num=3, loss/train=31.50, loss/val=30.60]    Epoch 3:  85%|████████▍ | 22/26 [00:02<00:00, 10.49it/s, v_num=3, loss/train=31.50, loss/val=30.60]    Epoch 3:  85%|████████▍ | 22/26 [00:02<00:00, 10.48it/s, v_num=3, loss/train=31.00, loss/val=30.60]    Epoch 3:  88%|████████▊ | 23/26 [00:02<00:00, 10.90it/s, v_num=3, loss/train=31.00, loss/val=30.60]    Epoch 3:  88%|████████▊ | 23/26 [00:02<00:00, 10.90it/s, v_num=3, loss/train=33.70, loss/val=30.60]    Epoch 3:  92%|█████████▏| 24/26 [00:02<00:00, 11.35it/s, v_num=3, loss/train=33.70, loss/val=30.60]    Epoch 3:  92%|█████████▏| 24/26 [00:02<00:00, 11.35it/s, v_num=3, loss/train=30.60, loss/val=30.60]    Epoch 3:  96%|█████████▌| 25/26 [00:02<00:00, 11.79it/s, v_num=3, loss/train=30.60, loss/val=30.60]    Epoch 3:  96%|█████████▌| 25/26 [00:02<00:00, 11.79it/s, v_num=3, loss/train=32.80, loss/val=30.60]    Epoch 3: 100%|██████████| 26/26 [00:02<00:00, 12.23it/s, v_num=3, loss/train=32.80, loss/val=30.60]    Epoch 3: 100%|██████████| 26/26 [00:02<00:00, 12.23it/s, v_num=3, loss/train=33.80, loss/val=30.60]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]
    Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 125.54it/s]
    Validation DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 160.30it/s]
    Validation DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 74.81it/s] 
    Validation DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 94.37it/s]
    Validation DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 112.29it/s]
    Validation DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 127.88it/s]
                                                                               Epoch 3: 100%|██████████| 26/26 [00:02<00:00,  8.97it/s, v_num=3, loss/train=33.80, loss/val=30.80]    Epoch 3: 100%|██████████| 26/26 [00:02<00:00,  8.97it/s, v_num=3, loss/train=33.80, loss/val=30.80]    Epoch 3:   0%|          | 0/26 [00:00<?, ?it/s, v_num=3, loss/train=33.80, loss/val=30.80]             Epoch 4:   0%|          | 0/26 [00:00<?, ?it/s, v_num=3, loss/train=33.80, loss/val=30.80]    Epoch 4:   4%|▍         | 1/26 [00:01<00:41,  0.60it/s, v_num=3, loss/train=33.80, loss/val=30.80]    Epoch 4:   4%|▍         | 1/26 [00:01<00:41,  0.60it/s, v_num=3, loss/train=31.20, loss/val=30.80]    Epoch 4:   8%|▊         | 2/26 [00:01<00:20,  1.15it/s, v_num=3, loss/train=31.20, loss/val=30.80]    Epoch 4:   8%|▊         | 2/26 [00:01<00:20,  1.15it/s, v_num=3, loss/train=31.50, loss/val=30.80]    Epoch 4:  12%|█▏        | 3/26 [00:01<00:13,  1.67it/s, v_num=3, loss/train=31.50, loss/val=30.80]    Epoch 4:  12%|█▏        | 3/26 [00:01<00:13,  1.67it/s, v_num=3, loss/train=27.30, loss/val=30.80]    Epoch 4:  15%|█▌        | 4/26 [00:01<00:10,  2.18it/s, v_num=3, loss/train=27.30, loss/val=30.80]    Epoch 4:  15%|█▌        | 4/26 [00:01<00:10,  2.17it/s, v_num=3, loss/train=32.00, loss/val=30.80]    Epoch 4:  19%|█▉        | 5/26 [00:01<00:07,  2.69it/s, v_num=3, loss/train=32.00, loss/val=30.80]    Epoch 4:  19%|█▉        | 5/26 [00:01<00:07,  2.69it/s, v_num=3, loss/train=31.60, loss/val=30.80]    Epoch 4:  23%|██▎       | 6/26 [00:01<00:06,  3.19it/s, v_num=3, loss/train=31.60, loss/val=30.80]    Epoch 4:  23%|██▎       | 6/26 [00:01<00:06,  3.19it/s, v_num=3, loss/train=31.40, loss/val=30.80]    Epoch 4:  27%|██▋       | 7/26 [00:01<00:05,  3.68it/s, v_num=3, loss/train=31.40, loss/val=30.80]    Epoch 4:  27%|██▋       | 7/26 [00:01<00:05,  3.68it/s, v_num=3, loss/train=30.20, loss/val=30.80]    Epoch 4:  31%|███       | 8/26 [00:01<00:04,  4.16it/s, v_num=3, loss/train=30.20, loss/val=30.80]    Epoch 4:  31%|███       | 8/26 [00:01<00:04,  4.16it/s, v_num=3, loss/train=28.70, loss/val=30.80]    Epoch 4:  35%|███▍      | 9/26 [00:01<00:03,  4.63it/s, v_num=3, loss/train=28.70, loss/val=30.80]    Epoch 4:  35%|███▍      | 9/26 [00:01<00:03,  4.63it/s, v_num=3, loss/train=29.50, loss/val=30.80]    Epoch 4:  38%|███▊      | 10/26 [00:01<00:03,  5.10it/s, v_num=3, loss/train=29.50, loss/val=30.80]    Epoch 4:  38%|███▊      | 10/26 [00:01<00:03,  5.10it/s, v_num=3, loss/train=30.90, loss/val=30.80]    Epoch 4:  42%|████▏     | 11/26 [00:01<00:02,  5.57it/s, v_num=3, loss/train=30.90, loss/val=30.80]    Epoch 4:  42%|████▏     | 11/26 [00:01<00:02,  5.57it/s, v_num=3, loss/train=29.60, loss/val=30.80]    Epoch 4:  46%|████▌     | 12/26 [00:02<00:02,  5.98it/s, v_num=3, loss/train=29.60, loss/val=30.80]    Epoch 4:  46%|████▌     | 12/26 [00:02<00:02,  5.98it/s, v_num=3, loss/train=30.80, loss/val=30.80]    Epoch 4:  50%|█████     | 13/26 [00:02<00:02,  6.46it/s, v_num=3, loss/train=30.80, loss/val=30.80]    Epoch 4:  50%|█████     | 13/26 [00:02<00:02,  6.45it/s, v_num=3, loss/train=30.60, loss/val=30.80]    Epoch 4:  54%|█████▍    | 14/26 [00:02<00:01,  6.93it/s, v_num=3, loss/train=30.60, loss/val=30.80]    Epoch 4:  54%|█████▍    | 14/26 [00:02<00:01,  6.93it/s, v_num=3, loss/train=31.60, loss/val=30.80]    Epoch 4:  58%|█████▊    | 15/26 [00:02<00:01,  7.40it/s, v_num=3, loss/train=31.60, loss/val=30.80]    Epoch 4:  58%|█████▊    | 15/26 [00:02<00:01,  7.40it/s, v_num=3, loss/train=29.20, loss/val=30.80]    Epoch 4:  62%|██████▏   | 16/26 [00:02<00:01,  7.86it/s, v_num=3, loss/train=29.20, loss/val=30.80]    Epoch 4:  62%|██████▏   | 16/26 [00:02<00:01,  7.86it/s, v_num=3, loss/train=32.30, loss/val=30.80]    Epoch 4:  65%|██████▌   | 17/26 [00:02<00:01,  8.33it/s, v_num=3, loss/train=32.30, loss/val=30.80]    Epoch 4:  65%|██████▌   | 17/26 [00:02<00:01,  8.33it/s, v_num=3, loss/train=31.40, loss/val=30.80]    Epoch 4:  69%|██████▉   | 18/26 [00:02<00:00,  8.80it/s, v_num=3, loss/train=31.40, loss/val=30.80]    Epoch 4:  69%|██████▉   | 18/26 [00:02<00:00,  8.80it/s, v_num=3, loss/train=28.90, loss/val=30.80]    Epoch 4:  73%|███████▎  | 19/26 [00:02<00:00,  9.27it/s, v_num=3, loss/train=28.90, loss/val=30.80]    Epoch 4:  73%|███████▎  | 19/26 [00:02<00:00,  9.27it/s, v_num=3, loss/train=29.50, loss/val=30.80]    Epoch 4:  77%|███████▋  | 20/26 [00:02<00:00,  9.73it/s, v_num=3, loss/train=29.50, loss/val=30.80]    Epoch 4:  77%|███████▋  | 20/26 [00:02<00:00,  9.73it/s, v_num=3, loss/train=32.40, loss/val=30.80]    Epoch 4:  81%|████████  | 21/26 [00:02<00:00, 10.20it/s, v_num=3, loss/train=32.40, loss/val=30.80]    Epoch 4:  81%|████████  | 21/26 [00:02<00:00, 10.19it/s, v_num=3, loss/train=34.20, loss/val=30.80]    Epoch 4:  85%|████████▍ | 22/26 [00:02<00:00, 10.64it/s, v_num=3, loss/train=34.20, loss/val=30.80]    Epoch 4:  85%|████████▍ | 22/26 [00:02<00:00, 10.64it/s, v_num=3, loss/train=31.30, loss/val=30.80]    Epoch 4:  88%|████████▊ | 23/26 [00:02<00:00, 11.10it/s, v_num=3, loss/train=31.30, loss/val=30.80]    Epoch 4:  88%|████████▊ | 23/26 [00:02<00:00, 11.10it/s, v_num=3, loss/train=32.60, loss/val=30.80]    Epoch 4:  92%|█████████▏| 24/26 [00:02<00:00, 11.54it/s, v_num=3, loss/train=32.60, loss/val=30.80]    Epoch 4:  92%|█████████▏| 24/26 [00:02<00:00, 11.54it/s, v_num=3, loss/train=32.70, loss/val=30.80]    Epoch 4:  96%|█████████▌| 25/26 [00:02<00:00, 11.99it/s, v_num=3, loss/train=32.70, loss/val=30.80]    Epoch 4:  96%|█████████▌| 25/26 [00:02<00:00, 11.99it/s, v_num=3, loss/train=29.90, loss/val=30.80]    Epoch 4: 100%|██████████| 26/26 [00:02<00:00, 12.44it/s, v_num=3, loss/train=29.90, loss/val=30.80]    Epoch 4: 100%|██████████| 26/26 [00:02<00:00, 12.43it/s, v_num=3, loss/train=26.00, loss/val=30.80]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]
    Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 70.73it/s]
    Validation DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 72.44it/s]
    Validation DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 90.89it/s]
    Validation DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 105.34it/s]
    Validation DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 117.46it/s]
    Validation DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 104.45it/s]
                                                                               Epoch 4: 100%|██████████| 26/26 [00:02<00:00,  9.05it/s, v_num=3, loss/train=26.00, loss/val=31.70]    Epoch 4: 100%|██████████| 26/26 [00:02<00:00,  9.05it/s, v_num=3, loss/train=26.00, loss/val=31.70]    Epoch 4:   0%|          | 0/26 [00:00<?, ?it/s, v_num=3, loss/train=26.00, loss/val=31.70]             Epoch 5:   0%|          | 0/26 [00:00<?, ?it/s, v_num=3, loss/train=26.00, loss/val=31.70]    Epoch 5:   4%|▍         | 1/26 [00:01<00:38,  0.64it/s, v_num=3, loss/train=26.00, loss/val=31.70]    Epoch 5:   4%|▍         | 1/26 [00:01<00:38,  0.64it/s, v_num=3, loss/train=31.30, loss/val=31.70]    Epoch 5:   8%|▊         | 2/26 [00:01<00:20,  1.20it/s, v_num=3, loss/train=31.30, loss/val=31.70]    Epoch 5:   8%|▊         | 2/26 [00:01<00:20,  1.19it/s, v_num=3, loss/train=33.20, loss/val=31.70]    Epoch 5:  12%|█▏        | 3/26 [00:01<00:13,  1.74it/s, v_num=3, loss/train=33.20, loss/val=31.70]    Epoch 5:  12%|█▏        | 3/26 [00:01<00:13,  1.74it/s, v_num=3, loss/train=33.50, loss/val=31.70]    Epoch 5:  15%|█▌        | 4/26 [00:01<00:09,  2.24it/s, v_num=3, loss/train=33.50, loss/val=31.70]    Epoch 5:  15%|█▌        | 4/26 [00:01<00:09,  2.24it/s, v_num=3, loss/train=31.80, loss/val=31.70]    Epoch 5:  19%|█▉        | 5/26 [00:01<00:07,  2.76it/s, v_num=3, loss/train=31.80, loss/val=31.70]    Epoch 5:  19%|█▉        | 5/26 [00:01<00:07,  2.76it/s, v_num=3, loss/train=31.80, loss/val=31.70]    Epoch 5:  23%|██▎       | 6/26 [00:01<00:06,  3.27it/s, v_num=3, loss/train=31.80, loss/val=31.70]    Epoch 5:  23%|██▎       | 6/26 [00:01<00:06,  3.27it/s, v_num=3, loss/train=31.20, loss/val=31.70]    Epoch 5:  27%|██▋       | 7/26 [00:01<00:05,  3.77it/s, v_num=3, loss/train=31.20, loss/val=31.70]    Epoch 5:  27%|██▋       | 7/26 [00:01<00:05,  3.77it/s, v_num=3, loss/train=31.90, loss/val=31.70]    Epoch 5:  31%|███       | 8/26 [00:01<00:04,  4.23it/s, v_num=3, loss/train=31.90, loss/val=31.70]    Epoch 5:  31%|███       | 8/26 [00:01<00:04,  4.23it/s, v_num=3, loss/train=28.30, loss/val=31.70]    Epoch 5:  35%|███▍      | 9/26 [00:01<00:03,  4.64it/s, v_num=3, loss/train=28.30, loss/val=31.70]    Epoch 5:  35%|███▍      | 9/26 [00:01<00:03,  4.64it/s, v_num=3, loss/train=30.50, loss/val=31.70]    Epoch 5:  38%|███▊      | 10/26 [00:01<00:03,  5.08it/s, v_num=3, loss/train=30.50, loss/val=31.70]    Epoch 5:  38%|███▊      | 10/26 [00:01<00:03,  5.08it/s, v_num=3, loss/train=30.90, loss/val=31.70]    Epoch 5:  42%|████▏     | 11/26 [00:01<00:02,  5.50it/s, v_num=3, loss/train=30.90, loss/val=31.70]    Epoch 5:  42%|████▏     | 11/26 [00:01<00:02,  5.50it/s, v_num=3, loss/train=29.80, loss/val=31.70]    Epoch 5:  46%|████▌     | 12/26 [00:02<00:02,  5.98it/s, v_num=3, loss/train=29.80, loss/val=31.70]    Epoch 5:  46%|████▌     | 12/26 [00:02<00:02,  5.98it/s, v_num=3, loss/train=29.00, loss/val=31.70]    Epoch 5:  50%|█████     | 13/26 [00:02<00:02,  6.44it/s, v_num=3, loss/train=29.00, loss/val=31.70]    Epoch 5:  50%|█████     | 13/26 [00:02<00:02,  6.44it/s, v_num=3, loss/train=29.40, loss/val=31.70]    Epoch 5:  54%|█████▍    | 14/26 [00:02<00:01,  6.87it/s, v_num=3, loss/train=29.40, loss/val=31.70]    Epoch 5:  54%|█████▍    | 14/26 [00:02<00:01,  6.87it/s, v_num=3, loss/train=32.20, loss/val=31.70]    Epoch 5:  58%|█████▊    | 15/26 [00:02<00:01,  7.32it/s, v_num=3, loss/train=32.20, loss/val=31.70]    Epoch 5:  58%|█████▊    | 15/26 [00:02<00:01,  7.32it/s, v_num=3, loss/train=30.40, loss/val=31.70]    Epoch 5:  62%|██████▏   | 16/26 [00:02<00:01,  7.78it/s, v_num=3, loss/train=30.40, loss/val=31.70]    Epoch 5:  62%|██████▏   | 16/26 [00:02<00:01,  7.77it/s, v_num=3, loss/train=32.30, loss/val=31.70]    Epoch 5:  65%|██████▌   | 17/26 [00:02<00:01,  8.23it/s, v_num=3, loss/train=32.30, loss/val=31.70]    Epoch 5:  65%|██████▌   | 17/26 [00:02<00:01,  8.22it/s, v_num=3, loss/train=28.60, loss/val=31.70]    Epoch 5:  69%|██████▉   | 18/26 [00:02<00:00,  8.67it/s, v_num=3, loss/train=28.60, loss/val=31.70]    Epoch 5:  69%|██████▉   | 18/26 [00:02<00:00,  8.66it/s, v_num=3, loss/train=31.80, loss/val=31.70]    Epoch 5:  73%|███████▎  | 19/26 [00:02<00:00,  9.11it/s, v_num=3, loss/train=31.80, loss/val=31.70]    Epoch 5:  73%|███████▎  | 19/26 [00:02<00:00,  9.10it/s, v_num=3, loss/train=32.60, loss/val=31.70]    Epoch 5:  77%|███████▋  | 20/26 [00:02<00:00,  9.56it/s, v_num=3, loss/train=32.60, loss/val=31.70]    Epoch 5:  77%|███████▋  | 20/26 [00:02<00:00,  9.56it/s, v_num=3, loss/train=30.20, loss/val=31.70]    Epoch 5:  81%|████████  | 21/26 [00:02<00:00,  9.99it/s, v_num=3, loss/train=30.20, loss/val=31.70]    Epoch 5:  81%|████████  | 21/26 [00:02<00:00,  9.99it/s, v_num=3, loss/train=32.70, loss/val=31.70]    Epoch 5:  85%|████████▍ | 22/26 [00:02<00:00, 10.44it/s, v_num=3, loss/train=32.70, loss/val=31.70]    Epoch 5:  85%|████████▍ | 22/26 [00:02<00:00, 10.44it/s, v_num=3, loss/train=35.00, loss/val=31.70]    Epoch 5:  88%|████████▊ | 23/26 [00:02<00:00, 10.87it/s, v_num=3, loss/train=35.00, loss/val=31.70]    Epoch 5:  88%|████████▊ | 23/26 [00:02<00:00, 10.87it/s, v_num=3, loss/train=30.90, loss/val=31.70]    Epoch 5:  92%|█████████▏| 24/26 [00:02<00:00, 11.31it/s, v_num=3, loss/train=30.90, loss/val=31.70]    Epoch 5:  92%|█████████▏| 24/26 [00:02<00:00, 11.31it/s, v_num=3, loss/train=30.50, loss/val=31.70]    Epoch 5:  96%|█████████▌| 25/26 [00:02<00:00, 11.75it/s, v_num=3, loss/train=30.50, loss/val=31.70]    Epoch 5:  96%|█████████▌| 25/26 [00:02<00:00, 11.75it/s, v_num=3, loss/train=31.20, loss/val=31.70]    Epoch 5: 100%|██████████| 26/26 [00:02<00:00, 12.19it/s, v_num=3, loss/train=31.20, loss/val=31.70]    Epoch 5: 100%|██████████| 26/26 [00:02<00:00, 12.19it/s, v_num=3, loss/train=25.80, loss/val=31.70]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]
    Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 41.12it/s]
    Validation DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 23.08it/s]
    Validation DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 27.40it/s]
    Validation DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 35.46it/s]
    Validation DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 42.79it/s]
    Validation DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 50.04it/s]
                                                                              Epoch 5: 100%|██████████| 26/26 [00:02<00:00,  8.93it/s, v_num=3, loss/train=25.80, loss/val=31.80]    Epoch 5: 100%|██████████| 26/26 [00:02<00:00,  8.93it/s, v_num=3, loss/train=25.80, loss/val=31.80]    Epoch 5:   0%|          | 0/26 [00:00<?, ?it/s, v_num=3, loss/train=25.80, loss/val=31.80]             Epoch 6:   0%|          | 0/26 [00:00<?, ?it/s, v_num=3, loss/train=25.80, loss/val=31.80]    Epoch 6:   4%|▍         | 1/26 [00:01<00:38,  0.65it/s, v_num=3, loss/train=25.80, loss/val=31.80]    Epoch 6:   4%|▍         | 1/26 [00:01<00:38,  0.65it/s, v_num=3, loss/train=29.60, loss/val=31.80]    Epoch 6:   8%|▊         | 2/26 [00:01<00:20,  1.18it/s, v_num=3, loss/train=29.60, loss/val=31.80]    Epoch 6:   8%|▊         | 2/26 [00:01<00:20,  1.18it/s, v_num=3, loss/train=30.60, loss/val=31.80]    Epoch 6:  12%|█▏        | 3/26 [00:01<00:13,  1.65it/s, v_num=3, loss/train=30.60, loss/val=31.80]    Epoch 6:  12%|█▏        | 3/26 [00:01<00:13,  1.65it/s, v_num=3, loss/train=28.80, loss/val=31.80]    Epoch 6:  15%|█▌        | 4/26 [00:01<00:10,  2.15it/s, v_num=3, loss/train=28.80, loss/val=31.80]    Epoch 6:  15%|█▌        | 4/26 [00:01<00:10,  2.15it/s, v_num=3, loss/train=30.50, loss/val=31.80]    Epoch 6:  19%|█▉        | 5/26 [00:01<00:07,  2.65it/s, v_num=3, loss/train=30.50, loss/val=31.80]    Epoch 6:  19%|█▉        | 5/26 [00:01<00:07,  2.65it/s, v_num=3, loss/train=31.00, loss/val=31.80]    Epoch 6:  23%|██▎       | 6/26 [00:01<00:06,  3.14it/s, v_num=3, loss/train=31.00, loss/val=31.80]    Epoch 6:  23%|██▎       | 6/26 [00:01<00:06,  3.13it/s, v_num=3, loss/train=30.30, loss/val=31.80]    Epoch 6:  27%|██▋       | 7/26 [00:01<00:05,  3.62it/s, v_num=3, loss/train=30.30, loss/val=31.80]    Epoch 6:  27%|██▋       | 7/26 [00:01<00:05,  3.62it/s, v_num=3, loss/train=29.60, loss/val=31.80]    Epoch 6:  31%|███       | 8/26 [00:01<00:04,  4.10it/s, v_num=3, loss/train=29.60, loss/val=31.80]    Epoch 6:  31%|███       | 8/26 [00:01<00:04,  4.10it/s, v_num=3, loss/train=28.90, loss/val=31.80]    Epoch 6:  35%|███▍      | 9/26 [00:01<00:03,  4.57it/s, v_num=3, loss/train=28.90, loss/val=31.80]    Epoch 6:  35%|███▍      | 9/26 [00:01<00:03,  4.57it/s, v_num=3, loss/train=32.10, loss/val=31.80]    Epoch 6:  38%|███▊      | 10/26 [00:01<00:03,  5.04it/s, v_num=3, loss/train=32.10, loss/val=31.80]    Epoch 6:  38%|███▊      | 10/26 [00:01<00:03,  5.04it/s, v_num=3, loss/train=29.90, loss/val=31.80]    Epoch 6:  42%|████▏     | 11/26 [00:02<00:02,  5.44it/s, v_num=3, loss/train=29.90, loss/val=31.80]    Epoch 6:  42%|████▏     | 11/26 [00:02<00:02,  5.43it/s, v_num=3, loss/train=30.80, loss/val=31.80]    Epoch 6:  46%|████▌     | 12/26 [00:02<00:02,  5.88it/s, v_num=3, loss/train=30.80, loss/val=31.80]    Epoch 6:  46%|████▌     | 12/26 [00:02<00:02,  5.88it/s, v_num=3, loss/train=31.90, loss/val=31.80]    Epoch 6:  50%|█████     | 13/26 [00:02<00:02,  6.35it/s, v_num=3, loss/train=31.90, loss/val=31.80]    Epoch 6:  50%|█████     | 13/26 [00:02<00:02,  6.35it/s, v_num=3, loss/train=32.60, loss/val=31.80]    Epoch 6:  54%|█████▍    | 14/26 [00:02<00:01,  6.81it/s, v_num=3, loss/train=32.60, loss/val=31.80]    Epoch 6:  54%|█████▍    | 14/26 [00:02<00:01,  6.81it/s, v_num=3, loss/train=33.00, loss/val=31.80]    Epoch 6:  58%|█████▊    | 15/26 [00:02<00:01,  7.28it/s, v_num=3, loss/train=33.00, loss/val=31.80]    Epoch 6:  58%|█████▊    | 15/26 [00:02<00:01,  7.28it/s, v_num=3, loss/train=30.20, loss/val=31.80]    Epoch 6:  62%|██████▏   | 16/26 [00:02<00:01,  7.74it/s, v_num=3, loss/train=30.20, loss/val=31.80]    Epoch 6:  62%|██████▏   | 16/26 [00:02<00:01,  7.74it/s, v_num=3, loss/train=30.00, loss/val=31.80]    Epoch 6:  65%|██████▌   | 17/26 [00:02<00:01,  8.20it/s, v_num=3, loss/train=30.00, loss/val=31.80]    Epoch 6:  65%|██████▌   | 17/26 [00:02<00:01,  8.20it/s, v_num=3, loss/train=30.10, loss/val=31.80]    Epoch 6:  69%|██████▉   | 18/26 [00:02<00:00,  8.65it/s, v_num=3, loss/train=30.10, loss/val=31.80]    Epoch 6:  69%|██████▉   | 18/26 [00:02<00:00,  8.65it/s, v_num=3, loss/train=27.10, loss/val=31.80]    Epoch 6:  73%|███████▎  | 19/26 [00:02<00:00,  9.10it/s, v_num=3, loss/train=27.10, loss/val=31.80]    Epoch 6:  73%|███████▎  | 19/26 [00:02<00:00,  9.10it/s, v_num=3, loss/train=32.10, loss/val=31.80]    Epoch 6:  77%|███████▋  | 20/26 [00:02<00:00,  9.55it/s, v_num=3, loss/train=32.10, loss/val=31.80]    Epoch 6:  77%|███████▋  | 20/26 [00:02<00:00,  9.54it/s, v_num=3, loss/train=29.70, loss/val=31.80]    Epoch 6:  81%|████████  | 21/26 [00:02<00:00,  9.99it/s, v_num=3, loss/train=29.70, loss/val=31.80]    Epoch 6:  81%|████████  | 21/26 [00:02<00:00,  9.99it/s, v_num=3, loss/train=30.70, loss/val=31.80]    Epoch 6:  85%|████████▍ | 22/26 [00:02<00:00, 10.43it/s, v_num=3, loss/train=30.70, loss/val=31.80]    Epoch 6:  85%|████████▍ | 22/26 [00:02<00:00, 10.42it/s, v_num=3, loss/train=30.10, loss/val=31.80]    Epoch 6:  88%|████████▊ | 23/26 [00:02<00:00, 10.87it/s, v_num=3, loss/train=30.10, loss/val=31.80]    Epoch 6:  88%|████████▊ | 23/26 [00:02<00:00, 10.87it/s, v_num=3, loss/train=31.30, loss/val=31.80]    Epoch 6:  92%|█████████▏| 24/26 [00:02<00:00, 11.30it/s, v_num=3, loss/train=31.30, loss/val=31.80]    Epoch 6:  92%|█████████▏| 24/26 [00:02<00:00, 11.30it/s, v_num=3, loss/train=29.20, loss/val=31.80]    Epoch 6:  96%|█████████▌| 25/26 [00:02<00:00, 11.73it/s, v_num=3, loss/train=29.20, loss/val=31.80]    Epoch 6:  96%|█████████▌| 25/26 [00:02<00:00, 11.73it/s, v_num=3, loss/train=32.20, loss/val=31.80]    Epoch 6: 100%|██████████| 26/26 [00:02<00:00, 12.17it/s, v_num=3, loss/train=32.20, loss/val=31.80]    Epoch 6: 100%|██████████| 26/26 [00:02<00:00, 12.17it/s, v_num=3, loss/train=32.10, loss/val=31.80]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]
    Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 113.16it/s]
    Validation DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 13.42it/s] 
    Validation DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 19.75it/s]
    Validation DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 25.90it/s]
    Validation DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 28.53it/s]
    Validation DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 33.71it/s]
                                                                              Epoch 6: 100%|██████████| 26/26 [00:02<00:00,  8.94it/s, v_num=3, loss/train=32.10, loss/val=31.80]    Epoch 6: 100%|██████████| 26/26 [00:02<00:00,  8.94it/s, v_num=3, loss/train=32.10, loss/val=31.80]    Epoch 6:   0%|          | 0/26 [00:00<?, ?it/s, v_num=3, loss/train=32.10, loss/val=31.80]             Epoch 7:   0%|          | 0/26 [00:00<?, ?it/s, v_num=3, loss/train=32.10, loss/val=31.80]    Epoch 7:   4%|▍         | 1/26 [00:01<00:41,  0.60it/s, v_num=3, loss/train=32.10, loss/val=31.80]    Epoch 7:   4%|▍         | 1/26 [00:01<00:41,  0.60it/s, v_num=3, loss/train=30.20, loss/val=31.80]    Epoch 7:   8%|▊         | 2/26 [00:01<00:20,  1.15it/s, v_num=3, loss/train=30.20, loss/val=31.80]    Epoch 7:   8%|▊         | 2/26 [00:01<00:20,  1.15it/s, v_num=3, loss/train=31.40, loss/val=31.80]    Epoch 7:  12%|█▏        | 3/26 [00:01<00:13,  1.71it/s, v_num=3, loss/train=31.40, loss/val=31.80]    Epoch 7:  12%|█▏        | 3/26 [00:01<00:13,  1.71it/s, v_num=3, loss/train=32.30, loss/val=31.80]    Epoch 7:  15%|█▌        | 4/26 [00:01<00:09,  2.25it/s, v_num=3, loss/train=32.30, loss/val=31.80]    Epoch 7:  15%|█▌        | 4/26 [00:01<00:09,  2.25it/s, v_num=3, loss/train=29.30, loss/val=31.80]    Epoch 7:  19%|█▉        | 5/26 [00:01<00:07,  2.75it/s, v_num=3, loss/train=29.30, loss/val=31.80]    Epoch 7:  19%|█▉        | 5/26 [00:01<00:07,  2.75it/s, v_num=3, loss/train=32.40, loss/val=31.80]    Epoch 7:  23%|██▎       | 6/26 [00:01<00:06,  3.27it/s, v_num=3, loss/train=32.40, loss/val=31.80]    Epoch 7:  23%|██▎       | 6/26 [00:01<00:06,  3.27it/s, v_num=3, loss/train=30.90, loss/val=31.80]    Epoch 7:  27%|██▋       | 7/26 [00:01<00:05,  3.78it/s, v_num=3, loss/train=30.90, loss/val=31.80]    Epoch 7:  27%|██▋       | 7/26 [00:01<00:05,  3.78it/s, v_num=3, loss/train=33.10, loss/val=31.80]    Epoch 7:  31%|███       | 8/26 [00:01<00:04,  4.27it/s, v_num=3, loss/train=33.10, loss/val=31.80]    Epoch 7:  31%|███       | 8/26 [00:01<00:04,  4.27it/s, v_num=3, loss/train=30.90, loss/val=31.80]    Epoch 7:  35%|███▍      | 9/26 [00:01<00:03,  4.76it/s, v_num=3, loss/train=30.90, loss/val=31.80]    Epoch 7:  35%|███▍      | 9/26 [00:01<00:03,  4.76it/s, v_num=3, loss/train=30.60, loss/val=31.80]    Epoch 7:  38%|███▊      | 10/26 [00:01<00:03,  5.21it/s, v_num=3, loss/train=30.60, loss/val=31.80]    Epoch 7:  38%|███▊      | 10/26 [00:01<00:03,  5.21it/s, v_num=3, loss/train=33.10, loss/val=31.80]    Epoch 7:  42%|████▏     | 11/26 [00:01<00:02,  5.57it/s, v_num=3, loss/train=33.10, loss/val=31.80]    Epoch 7:  42%|████▏     | 11/26 [00:01<00:02,  5.57it/s, v_num=3, loss/train=32.80, loss/val=31.80]    Epoch 7:  46%|████▌     | 12/26 [00:01<00:02,  6.05it/s, v_num=3, loss/train=32.80, loss/val=31.80]    Epoch 7:  46%|████▌     | 12/26 [00:01<00:02,  6.05it/s, v_num=3, loss/train=33.50, loss/val=31.80]    Epoch 7:  50%|█████     | 13/26 [00:01<00:01,  6.53it/s, v_num=3, loss/train=33.50, loss/val=31.80]    Epoch 7:  50%|█████     | 13/26 [00:01<00:01,  6.53it/s, v_num=3, loss/train=31.80, loss/val=31.80]    Epoch 7:  54%|█████▍    | 14/26 [00:01<00:01,  7.01it/s, v_num=3, loss/train=31.80, loss/val=31.80]    Epoch 7:  54%|█████▍    | 14/26 [00:01<00:01,  7.01it/s, v_num=3, loss/train=29.80, loss/val=31.80]    Epoch 7:  58%|█████▊    | 15/26 [00:02<00:01,  7.49it/s, v_num=3, loss/train=29.80, loss/val=31.80]    Epoch 7:  58%|█████▊    | 15/26 [00:02<00:01,  7.49it/s, v_num=3, loss/train=31.60, loss/val=31.80]    Epoch 7:  62%|██████▏   | 16/26 [00:02<00:01,  7.97it/s, v_num=3, loss/train=31.60, loss/val=31.80]    Epoch 7:  62%|██████▏   | 16/26 [00:02<00:01,  7.97it/s, v_num=3, loss/train=30.90, loss/val=31.80]    Epoch 7:  65%|██████▌   | 17/26 [00:02<00:01,  8.45it/s, v_num=3, loss/train=30.90, loss/val=31.80]    Epoch 7:  65%|██████▌   | 17/26 [00:02<00:01,  8.45it/s, v_num=3, loss/train=29.40, loss/val=31.80]    Epoch 7:  69%|██████▉   | 18/26 [00:02<00:00,  8.93it/s, v_num=3, loss/train=29.40, loss/val=31.80]    Epoch 7:  69%|██████▉   | 18/26 [00:02<00:00,  8.92it/s, v_num=3, loss/train=31.20, loss/val=31.80]    Epoch 7:  73%|███████▎  | 19/26 [00:02<00:00,  9.39it/s, v_num=3, loss/train=31.20, loss/val=31.80]    Epoch 7:  73%|███████▎  | 19/26 [00:02<00:00,  9.39it/s, v_num=3, loss/train=27.40, loss/val=31.80]    Epoch 7:  77%|███████▋  | 20/26 [00:02<00:00,  9.86it/s, v_num=3, loss/train=27.40, loss/val=31.80]    Epoch 7:  77%|███████▋  | 20/26 [00:02<00:00,  9.86it/s, v_num=3, loss/train=32.10, loss/val=31.80]    Epoch 7:  81%|████████  | 21/26 [00:02<00:00, 10.31it/s, v_num=3, loss/train=32.10, loss/val=31.80]    Epoch 7:  81%|████████  | 21/26 [00:02<00:00, 10.31it/s, v_num=3, loss/train=32.20, loss/val=31.80]    Epoch 7:  85%|████████▍ | 22/26 [00:02<00:00, 10.77it/s, v_num=3, loss/train=32.20, loss/val=31.80]    Epoch 7:  85%|████████▍ | 22/26 [00:02<00:00, 10.77it/s, v_num=3, loss/train=31.60, loss/val=31.80]    Epoch 7:  88%|████████▊ | 23/26 [00:02<00:00, 11.23it/s, v_num=3, loss/train=31.60, loss/val=31.80]    Epoch 7:  88%|████████▊ | 23/26 [00:02<00:00, 11.23it/s, v_num=3, loss/train=32.00, loss/val=31.80]    Epoch 7:  92%|█████████▏| 24/26 [00:02<00:00, 11.68it/s, v_num=3, loss/train=32.00, loss/val=31.80]    Epoch 7:  92%|█████████▏| 24/26 [00:02<00:00, 11.68it/s, v_num=3, loss/train=31.20, loss/val=31.80]    Epoch 7:  96%|█████████▌| 25/26 [00:02<00:00, 12.14it/s, v_num=3, loss/train=31.20, loss/val=31.80]    Epoch 7:  96%|█████████▌| 25/26 [00:02<00:00, 12.14it/s, v_num=3, loss/train=28.30, loss/val=31.80]    Epoch 7: 100%|██████████| 26/26 [00:02<00:00, 12.59it/s, v_num=3, loss/train=28.30, loss/val=31.80]    Epoch 7: 100%|██████████| 26/26 [00:02<00:00, 12.59it/s, v_num=3, loss/train=34.40, loss/val=31.80]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]
    Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 126.36it/s]
    Validation DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 171.38it/s]
    Validation DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 205.95it/s]
    Validation DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 209.56it/s]
    Validation DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 235.02it/s]
    Validation DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 251.14it/s]
                                                                               Epoch 7: 100%|██████████| 26/26 [00:02<00:00,  9.23it/s, v_num=3, loss/train=34.40, loss/val=31.10]    Epoch 7: 100%|██████████| 26/26 [00:02<00:00,  9.22it/s, v_num=3, loss/train=34.40, loss/val=31.10]    Epoch 7:   0%|          | 0/26 [00:00<?, ?it/s, v_num=3, loss/train=34.40, loss/val=31.10]             Epoch 8:   0%|          | 0/26 [00:00<?, ?it/s, v_num=3, loss/train=34.40, loss/val=31.10]    Epoch 8:   4%|▍         | 1/26 [00:01<00:37,  0.66it/s, v_num=3, loss/train=34.40, loss/val=31.10]    Epoch 8:   4%|▍         | 1/26 [00:01<00:37,  0.66it/s, v_num=3, loss/train=31.00, loss/val=31.10]    Epoch 8:   8%|▊         | 2/26 [00:01<00:18,  1.29it/s, v_num=3, loss/train=31.00, loss/val=31.10]    Epoch 8:   8%|▊         | 2/26 [00:01<00:18,  1.29it/s, v_num=3, loss/train=32.60, loss/val=31.10]    Epoch 8:  12%|█▏        | 3/26 [00:01<00:12,  1.84it/s, v_num=3, loss/train=32.60, loss/val=31.10]    Epoch 8:  12%|█▏        | 3/26 [00:01<00:12,  1.84it/s, v_num=3, loss/train=33.90, loss/val=31.10]    Epoch 8:  15%|█▌        | 4/26 [00:01<00:09,  2.38it/s, v_num=3, loss/train=33.90, loss/val=31.10]    Epoch 8:  15%|█▌        | 4/26 [00:01<00:09,  2.38it/s, v_num=3, loss/train=32.30, loss/val=31.10]    Epoch 8:  19%|█▉        | 5/26 [00:01<00:07,  2.87it/s, v_num=3, loss/train=32.30, loss/val=31.10]    Epoch 8:  19%|█▉        | 5/26 [00:01<00:07,  2.86it/s, v_num=3, loss/train=31.30, loss/val=31.10]    Epoch 8:  23%|██▎       | 6/26 [00:01<00:06,  3.23it/s, v_num=3, loss/train=31.30, loss/val=31.10]    Epoch 8:  23%|██▎       | 6/26 [00:01<00:06,  3.22it/s, v_num=3, loss/train=32.50, loss/val=31.10]    Epoch 8:  27%|██▋       | 7/26 [00:01<00:05,  3.72it/s, v_num=3, loss/train=32.50, loss/val=31.10]    Epoch 8:  27%|██▋       | 7/26 [00:01<00:05,  3.72it/s, v_num=3, loss/train=29.90, loss/val=31.10]    Epoch 8:  31%|███       | 8/26 [00:01<00:04,  4.21it/s, v_num=3, loss/train=29.90, loss/val=31.10]    Epoch 8:  31%|███       | 8/26 [00:01<00:04,  4.21it/s, v_num=3, loss/train=30.40, loss/val=31.10]    Epoch 8:  35%|███▍      | 9/26 [00:01<00:03,  4.69it/s, v_num=3, loss/train=30.40, loss/val=31.10]    Epoch 8:  35%|███▍      | 9/26 [00:01<00:03,  4.69it/s, v_num=3, loss/train=32.10, loss/val=31.10]    Epoch 8:  38%|███▊      | 10/26 [00:01<00:03,  5.16it/s, v_num=3, loss/train=32.10, loss/val=31.10]    Epoch 8:  38%|███▊      | 10/26 [00:01<00:03,  5.16it/s, v_num=3, loss/train=29.90, loss/val=31.10]    Epoch 8:  42%|████▏     | 11/26 [00:01<00:02,  5.61it/s, v_num=3, loss/train=29.90, loss/val=31.10]    Epoch 8:  42%|████▏     | 11/26 [00:01<00:02,  5.60it/s, v_num=3, loss/train=29.90, loss/val=31.10]    Epoch 8:  46%|████▌     | 12/26 [00:01<00:02,  6.08it/s, v_num=3, loss/train=29.90, loss/val=31.10]    Epoch 8:  46%|████▌     | 12/26 [00:01<00:02,  6.08it/s, v_num=3, loss/train=30.80, loss/val=31.10]    Epoch 8:  50%|█████     | 13/26 [00:01<00:01,  6.56it/s, v_num=3, loss/train=30.80, loss/val=31.10]    Epoch 8:  50%|█████     | 13/26 [00:01<00:01,  6.56it/s, v_num=3, loss/train=32.40, loss/val=31.10]    Epoch 8:  54%|█████▍    | 14/26 [00:01<00:01,  7.04it/s, v_num=3, loss/train=32.40, loss/val=31.10]    Epoch 8:  54%|█████▍    | 14/26 [00:01<00:01,  7.04it/s, v_num=3, loss/train=29.30, loss/val=31.10]    Epoch 8:  58%|█████▊    | 15/26 [00:02<00:01,  7.50it/s, v_num=3, loss/train=29.30, loss/val=31.10]    Epoch 8:  58%|█████▊    | 15/26 [00:02<00:01,  7.50it/s, v_num=3, loss/train=30.90, loss/val=31.10]    Epoch 8:  62%|██████▏   | 16/26 [00:02<00:01,  7.97it/s, v_num=3, loss/train=30.90, loss/val=31.10]    Epoch 8:  62%|██████▏   | 16/26 [00:02<00:01,  7.96it/s, v_num=3, loss/train=34.90, loss/val=31.10]    Epoch 8:  65%|██████▌   | 17/26 [00:02<00:01,  8.43it/s, v_num=3, loss/train=34.90, loss/val=31.10]    Epoch 8:  65%|██████▌   | 17/26 [00:02<00:01,  8.43it/s, v_num=3, loss/train=31.60, loss/val=31.10]    Epoch 8:  69%|██████▉   | 18/26 [00:02<00:00,  8.90it/s, v_num=3, loss/train=31.60, loss/val=31.10]    Epoch 8:  69%|██████▉   | 18/26 [00:02<00:00,  8.90it/s, v_num=3, loss/train=31.40, loss/val=31.10]    Epoch 8:  73%|███████▎  | 19/26 [00:02<00:00,  9.36it/s, v_num=3, loss/train=31.40, loss/val=31.10]    Epoch 8:  73%|███████▎  | 19/26 [00:02<00:00,  9.36it/s, v_num=3, loss/train=33.60, loss/val=31.10]    Epoch 8:  77%|███████▋  | 20/26 [00:02<00:00,  9.82it/s, v_num=3, loss/train=33.60, loss/val=31.10]    Epoch 8:  77%|███████▋  | 20/26 [00:02<00:00,  9.82it/s, v_num=3, loss/train=30.30, loss/val=31.10]    Epoch 8:  81%|████████  | 21/26 [00:02<00:00, 10.26it/s, v_num=3, loss/train=30.30, loss/val=31.10]    Epoch 8:  81%|████████  | 21/26 [00:02<00:00, 10.26it/s, v_num=3, loss/train=35.00, loss/val=31.10]    Epoch 8:  85%|████████▍ | 22/26 [00:02<00:00, 10.71it/s, v_num=3, loss/train=35.00, loss/val=31.10]    Epoch 8:  85%|████████▍ | 22/26 [00:02<00:00, 10.71it/s, v_num=3, loss/train=29.80, loss/val=31.10]    Epoch 8:  88%|████████▊ | 23/26 [00:02<00:00, 11.17it/s, v_num=3, loss/train=29.80, loss/val=31.10]    Epoch 8:  88%|████████▊ | 23/26 [00:02<00:00, 11.16it/s, v_num=3, loss/train=33.50, loss/val=31.10]    Epoch 8:  92%|█████████▏| 24/26 [00:02<00:00, 11.62it/s, v_num=3, loss/train=33.50, loss/val=31.10]    Epoch 8:  92%|█████████▏| 24/26 [00:02<00:00, 11.61it/s, v_num=3, loss/train=33.60, loss/val=31.10]    Epoch 8:  96%|█████████▌| 25/26 [00:02<00:00, 12.06it/s, v_num=3, loss/train=33.60, loss/val=31.10]    Epoch 8:  96%|█████████▌| 25/26 [00:02<00:00, 12.06it/s, v_num=3, loss/train=30.90, loss/val=31.10]    Epoch 8: 100%|██████████| 26/26 [00:02<00:00, 12.51it/s, v_num=3, loss/train=30.90, loss/val=31.10]    Epoch 8: 100%|██████████| 26/26 [00:02<00:00, 12.51it/s, v_num=3, loss/train=33.20, loss/val=31.10]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]
    Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 70.99it/s]
    Validation DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 11.35it/s]
    Validation DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 16.79it/s]
    Validation DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 22.10it/s]
    Validation DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 27.28it/s]
    Validation DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 32.24it/s]
                                                                              Epoch 8: 100%|██████████| 26/26 [00:02<00:00,  8.98it/s, v_num=3, loss/train=33.20, loss/val=31.20]    Epoch 8: 100%|██████████| 26/26 [00:02<00:00,  8.98it/s, v_num=3, loss/train=33.20, loss/val=31.20]    Epoch 8:   0%|          | 0/26 [00:00<?, ?it/s, v_num=3, loss/train=33.20, loss/val=31.20]             Epoch 9:   0%|          | 0/26 [00:00<?, ?it/s, v_num=3, loss/train=33.20, loss/val=31.20]    Epoch 9:   4%|▍         | 1/26 [00:01<00:41,  0.60it/s, v_num=3, loss/train=33.20, loss/val=31.20]    Epoch 9:   4%|▍         | 1/26 [00:01<00:41,  0.60it/s, v_num=3, loss/train=30.30, loss/val=31.20]    Epoch 9:   8%|▊         | 2/26 [00:01<00:20,  1.15it/s, v_num=3, loss/train=30.30, loss/val=31.20]    Epoch 9:   8%|▊         | 2/26 [00:01<00:20,  1.15it/s, v_num=3, loss/train=33.10, loss/val=31.20]    Epoch 9:  12%|█▏        | 3/26 [00:01<00:14,  1.62it/s, v_num=3, loss/train=33.10, loss/val=31.20]    Epoch 9:  12%|█▏        | 3/26 [00:01<00:14,  1.61it/s, v_num=3, loss/train=33.00, loss/val=31.20]    Epoch 9:  15%|█▌        | 4/26 [00:01<00:10,  2.11it/s, v_num=3, loss/train=33.00, loss/val=31.20]    Epoch 9:  15%|█▌        | 4/26 [00:01<00:10,  2.11it/s, v_num=3, loss/train=31.40, loss/val=31.20]    Epoch 9:  19%|█▉        | 5/26 [00:01<00:08,  2.54it/s, v_num=3, loss/train=31.40, loss/val=31.20]    Epoch 9:  19%|█▉        | 5/26 [00:01<00:08,  2.54it/s, v_num=3, loss/train=31.30, loss/val=31.20]    Epoch 9:  23%|██▎       | 6/26 [00:01<00:06,  3.03it/s, v_num=3, loss/train=31.30, loss/val=31.20]    Epoch 9:  23%|██▎       | 6/26 [00:01<00:06,  3.03it/s, v_num=3, loss/train=33.00, loss/val=31.20]    Epoch 9:  27%|██▋       | 7/26 [00:01<00:05,  3.52it/s, v_num=3, loss/train=33.00, loss/val=31.20]    Epoch 9:  27%|██▋       | 7/26 [00:01<00:05,  3.52it/s, v_num=3, loss/train=30.90, loss/val=31.20]    Epoch 9:  31%|███       | 8/26 [00:01<00:04,  4.01it/s, v_num=3, loss/train=30.90, loss/val=31.20]    Epoch 9:  31%|███       | 8/26 [00:01<00:04,  4.01it/s, v_num=3, loss/train=34.60, loss/val=31.20]    Epoch 9:  35%|███▍      | 9/26 [00:02<00:03,  4.50it/s, v_num=3, loss/train=34.60, loss/val=31.20]    Epoch 9:  35%|███▍      | 9/26 [00:02<00:03,  4.50it/s, v_num=3, loss/train=30.40, loss/val=31.20]    Epoch 9:  38%|███▊      | 10/26 [00:02<00:03,  4.98it/s, v_num=3, loss/train=30.40, loss/val=31.20]    Epoch 9:  38%|███▊      | 10/26 [00:02<00:03,  4.98it/s, v_num=3, loss/train=33.70, loss/val=31.20]    Epoch 9:  42%|████▏     | 11/26 [00:02<00:02,  5.42it/s, v_num=3, loss/train=33.70, loss/val=31.20]    Epoch 9:  42%|████▏     | 11/26 [00:02<00:02,  5.42it/s, v_num=3, loss/train=32.50, loss/val=31.20]    Epoch 9:  46%|████▌     | 12/26 [00:02<00:02,  5.89it/s, v_num=3, loss/train=32.50, loss/val=31.20]    Epoch 9:  46%|████▌     | 12/26 [00:02<00:02,  5.89it/s, v_num=3, loss/train=31.20, loss/val=31.20]    Epoch 9:  50%|█████     | 13/26 [00:02<00:02,  6.35it/s, v_num=3, loss/train=31.20, loss/val=31.20]    Epoch 9:  50%|█████     | 13/26 [00:02<00:02,  6.35it/s, v_num=3, loss/train=31.20, loss/val=31.20]    Epoch 9:  54%|█████▍    | 14/26 [00:02<00:01,  6.80it/s, v_num=3, loss/train=31.20, loss/val=31.20]    Epoch 9:  54%|█████▍    | 14/26 [00:02<00:01,  6.80it/s, v_num=3, loss/train=31.00, loss/val=31.20]    Epoch 9:  58%|█████▊    | 15/26 [00:02<00:01,  7.27it/s, v_num=3, loss/train=31.00, loss/val=31.20]    Epoch 9:  58%|█████▊    | 15/26 [00:02<00:01,  7.27it/s, v_num=3, loss/train=32.10, loss/val=31.20]    Epoch 9:  62%|██████▏   | 16/26 [00:02<00:01,  7.74it/s, v_num=3, loss/train=32.10, loss/val=31.20]    Epoch 9:  62%|██████▏   | 16/26 [00:02<00:01,  7.74it/s, v_num=3, loss/train=28.40, loss/val=31.20]    Epoch 9:  65%|██████▌   | 17/26 [00:02<00:01,  8.19it/s, v_num=3, loss/train=28.40, loss/val=31.20]    Epoch 9:  65%|██████▌   | 17/26 [00:02<00:01,  8.19it/s, v_num=3, loss/train=29.50, loss/val=31.20]    Epoch 9:  69%|██████▉   | 18/26 [00:02<00:00,  8.65it/s, v_num=3, loss/train=29.50, loss/val=31.20]    Epoch 9:  69%|██████▉   | 18/26 [00:02<00:00,  8.65it/s, v_num=3, loss/train=33.90, loss/val=31.20]    Epoch 9:  73%|███████▎  | 19/26 [00:02<00:00,  9.10it/s, v_num=3, loss/train=33.90, loss/val=31.20]    Epoch 9:  73%|███████▎  | 19/26 [00:02<00:00,  9.10it/s, v_num=3, loss/train=32.30, loss/val=31.20]    Epoch 9:  77%|███████▋  | 20/26 [00:02<00:00,  9.55it/s, v_num=3, loss/train=32.30, loss/val=31.20]    Epoch 9:  77%|███████▋  | 20/26 [00:02<00:00,  9.55it/s, v_num=3, loss/train=30.10, loss/val=31.20]    Epoch 9:  81%|████████  | 21/26 [00:02<00:00, 10.00it/s, v_num=3, loss/train=30.10, loss/val=31.20]    Epoch 9:  81%|████████  | 21/26 [00:02<00:00, 10.00it/s, v_num=3, loss/train=35.30, loss/val=31.20]    Epoch 9:  85%|████████▍ | 22/26 [00:02<00:00, 10.45it/s, v_num=3, loss/train=35.30, loss/val=31.20]    Epoch 9:  85%|████████▍ | 22/26 [00:02<00:00, 10.45it/s, v_num=3, loss/train=32.40, loss/val=31.20]    Epoch 9:  88%|████████▊ | 23/26 [00:02<00:00, 10.90it/s, v_num=3, loss/train=32.40, loss/val=31.20]    Epoch 9:  88%|████████▊ | 23/26 [00:02<00:00, 10.90it/s, v_num=3, loss/train=33.40, loss/val=31.20]    Epoch 9:  92%|█████████▏| 24/26 [00:02<00:00, 11.34it/s, v_num=3, loss/train=33.40, loss/val=31.20]    Epoch 9:  92%|█████████▏| 24/26 [00:02<00:00, 11.34it/s, v_num=3, loss/train=33.00, loss/val=31.20]    Epoch 9:  96%|█████████▌| 25/26 [00:02<00:00, 11.77it/s, v_num=3, loss/train=33.00, loss/val=31.20]    Epoch 9:  96%|█████████▌| 25/26 [00:02<00:00, 11.77it/s, v_num=3, loss/train=30.60, loss/val=31.20]    Epoch 9: 100%|██████████| 26/26 [00:02<00:00, 12.21it/s, v_num=3, loss/train=30.60, loss/val=31.20]    Epoch 9: 100%|██████████| 26/26 [00:02<00:00, 12.21it/s, v_num=3, loss/train=32.70, loss/val=31.20]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation: |          | 0/? [00:00<?, ?it/s]
    Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]
    Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 75.50it/s]
    Validation DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 108.61it/s]
    Validation DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 49.22it/s] 
    Validation DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 62.16it/s]
    Validation DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 73.46it/s]
    Validation DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 84.07it/s]
                                                                              Epoch 9: 100%|██████████| 26/26 [00:02<00:00,  8.93it/s, v_num=3, loss/train=32.70, loss/val=29.50]    Epoch 9: 100%|██████████| 26/26 [00:02<00:00,  8.93it/s, v_num=3, loss/train=32.70, loss/val=29.50]    Epoch 9: 100%|██████████| 26/26 [00:02<00:00,  8.92it/s, v_num=3, loss/train=32.70, loss/val=29.50]

    BarlowTwins(
      (encoder): MLP(
        (0): Linear(in_features=272, out_features=64, bias=True)
        (1): ReLU()
        (2): Dropout(p=0.0, inplace=False)
        (3): Linear(in_features=64, out_features=32, bias=True)
        (4): Dropout(p=0.0, inplace=False)
      )
      (projection_head): BarlowTwinsProjectionHead(
        (layers): Sequential(
          (0): Linear(in_features=32, out_features=64, bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=False)
          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU()
          (6): Linear(in_features=64, out_features=32, bias=True)
        )
      )
      (loss): BarlowTwinsLoss()
    )



.. GENERATED FROM PYTHON SOURCE LINES 299-308

Visualization and evaluation of the learned representations
--------------------------------------------------------------

In order to visualize the learned representations of both models, we apply
a widely used dimensionality reduction technique: Multi-Dimensional Scaling
(MDS). This technique project the points in a lower-dimensional space such
that the pairwise distances between points are preserved as much as possible.
Then, we evaluate the learned representations on age prediction using linear
regression and KNN regression.

.. GENERATED FROM PYTHON SOURCE LINES 310-312

We first extract the embeddings of the training and test sets for both VBM
and SBM data.

.. GENERATED FROM PYTHON SOURCE LINES 312-317

.. code-block:: Python

    Z_train_vbm = vbm_model.transform(dataloader_vbm_train)
    Z_test_vbm = vbm_model.transform(dataloader_vbm_test)
    Z_train_sbm = sbm_model.transform(dataloader_sbm_train)
    Z_test_sbm = sbm_model.transform(dataloader_sbm_test)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Predicting: |          | 0/? [00:00<?, ?it/s]    Predicting: |          | 0/? [00:00<?, ?it/s]    Predicting DataLoader 0:   0%|          | 0/26 [00:00<?, ?it/s]    Predicting DataLoader 0:   4%|▍         | 1/26 [00:00<00:00, 45.35it/s]    Predicting DataLoader 0:   8%|▊         | 2/26 [00:00<00:03,  6.43it/s]    Predicting DataLoader 0:  12%|█▏        | 3/26 [00:00<00:02,  9.30it/s]    Predicting DataLoader 0:  15%|█▌        | 4/26 [00:00<00:01, 12.04it/s]    Predicting DataLoader 0:  19%|█▉        | 5/26 [00:00<00:01, 14.45it/s]    Predicting DataLoader 0:  23%|██▎       | 6/26 [00:00<00:01, 14.70it/s]    Predicting DataLoader 0:  27%|██▋       | 7/26 [00:00<00:01, 17.10it/s]    Predicting DataLoader 0:  31%|███       | 8/26 [00:00<00:00, 19.18it/s]    Predicting DataLoader 0:  35%|███▍      | 9/26 [00:00<00:00, 20.89it/s]    Predicting DataLoader 0:  38%|███▊      | 10/26 [00:00<00:00, 22.62it/s]    Predicting DataLoader 0:  42%|████▏     | 11/26 [00:00<00:00, 24.29it/s]    Predicting DataLoader 0:  46%|████▌     | 12/26 [00:00<00:00, 23.90it/s]    Predicting DataLoader 0:  50%|█████     | 13/26 [00:00<00:00, 22.96it/s]    Predicting DataLoader 0:  54%|█████▍    | 14/26 [00:00<00:00, 24.27it/s]    Predicting DataLoader 0:  58%|█████▊    | 15/26 [00:00<00:00, 25.93it/s]    Predicting DataLoader 0:  62%|██████▏   | 16/26 [00:00<00:00, 27.53it/s]    Predicting DataLoader 0:  65%|██████▌   | 17/26 [00:00<00:00, 29.09it/s]    Predicting DataLoader 0:  69%|██████▉   | 18/26 [00:00<00:00, 30.75it/s]    Predicting DataLoader 0:  73%|███████▎  | 19/26 [00:00<00:00, 32.06it/s]    Predicting DataLoader 0:  77%|███████▋  | 20/26 [00:00<00:00, 33.69it/s]    Predicting DataLoader 0:  81%|████████  | 21/26 [00:00<00:00, 35.31it/s]    Predicting DataLoader 0:  85%|████████▍ | 22/26 [00:00<00:00, 34.83it/s]    Predicting DataLoader 0:  88%|████████▊ | 23/26 [00:00<00:00, 34.65it/s]    Predicting DataLoader 0:  92%|█████████▏| 24/26 [00:00<00:00, 36.10it/s]    Predicting DataLoader 0:  96%|█████████▌| 25/26 [00:00<00:00, 37.56it/s]    Predicting DataLoader 0: 100%|██████████| 26/26 [00:00<00:00, 39.01it/s]    Predicting DataLoader 0: 100%|██████████| 26/26 [00:00<00:00, 38.98it/s]
    Predicting: |          | 0/? [00:00<?, ?it/s]    Predicting: |          | 0/? [00:00<?, ?it/s]    Predicting DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]    Predicting DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 139.81it/s]    Predicting DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 52.57it/s]     Predicting DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 29.25it/s]    Predicting DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 38.61it/s]    Predicting DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 47.86it/s]    Predicting DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 56.80it/s]    Predicting DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 56.54it/s]
    Predicting: |          | 0/? [00:00<?, ?it/s]    Predicting: |          | 0/? [00:00<?, ?it/s]    Predicting DataLoader 0:   0%|          | 0/26 [00:00<?, ?it/s]    Predicting DataLoader 0:   4%|▍         | 1/26 [00:00<00:00, 75.91it/s]    Predicting DataLoader 0:   8%|▊         | 2/26 [00:00<00:00, 47.23it/s]    Predicting DataLoader 0:  12%|█▏        | 3/26 [00:00<00:00, 68.82it/s]    Predicting DataLoader 0:  15%|█▌        | 4/26 [00:00<00:00, 41.96it/s]    Predicting DataLoader 0:  19%|█▉        | 5/26 [00:00<00:00, 41.62it/s]    Predicting DataLoader 0:  23%|██▎       | 6/26 [00:00<00:00, 43.44it/s]    Predicting DataLoader 0:  27%|██▋       | 7/26 [00:00<00:00, 43.99it/s]    Predicting DataLoader 0:  31%|███       | 8/26 [00:00<00:00, 49.89it/s]    Predicting DataLoader 0:  35%|███▍      | 9/26 [00:00<00:00, 51.57it/s]    Predicting DataLoader 0:  38%|███▊      | 10/26 [00:00<00:00, 56.92it/s]    Predicting DataLoader 0:  42%|████▏     | 11/26 [00:00<00:00, 51.84it/s]    Predicting DataLoader 0:  46%|████▌     | 12/26 [00:00<00:00, 48.24it/s]    Predicting DataLoader 0:  50%|█████     | 13/26 [00:00<00:00, 52.01it/s]    Predicting DataLoader 0:  54%|█████▍    | 14/26 [00:00<00:00, 44.47it/s]    Predicting DataLoader 0:  58%|█████▊    | 15/26 [00:00<00:00, 47.26it/s]    Predicting DataLoader 0:  62%|██████▏   | 16/26 [00:00<00:00, 50.08it/s]    Predicting DataLoader 0:  65%|██████▌   | 17/26 [00:00<00:00, 52.58it/s]    Predicting DataLoader 0:  69%|██████▉   | 18/26 [00:00<00:00, 55.33it/s]    Predicting DataLoader 0:  73%|███████▎  | 19/26 [00:00<00:00, 58.11it/s]    Predicting DataLoader 0:  77%|███████▋  | 20/26 [00:00<00:00, 60.90it/s]    Predicting DataLoader 0:  81%|████████  | 21/26 [00:00<00:00, 63.40it/s]    Predicting DataLoader 0:  85%|████████▍ | 22/26 [00:00<00:00, 59.43it/s]    Predicting DataLoader 0:  88%|████████▊ | 23/26 [00:00<00:00, 61.95it/s]    Predicting DataLoader 0:  92%|█████████▏| 24/26 [00:00<00:00, 59.06it/s]    Predicting DataLoader 0:  96%|█████████▌| 25/26 [00:00<00:00, 61.38it/s]    Predicting DataLoader 0: 100%|██████████| 26/26 [00:00<00:00, 63.70it/s]    Predicting DataLoader 0: 100%|██████████| 26/26 [00:00<00:00, 63.63it/s]
    Predicting: |          | 0/? [00:00<?, ?it/s]    Predicting: |          | 0/? [00:00<?, ?it/s]    Predicting DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]    Predicting DataLoader 0:  17%|█▋        | 1/6 [00:00<00:00, 55.60it/s]    Predicting DataLoader 0:  33%|███▎      | 2/6 [00:00<00:00, 62.56it/s]    Predicting DataLoader 0:  50%|█████     | 3/6 [00:00<00:00, 41.54it/s]    Predicting DataLoader 0:  67%|██████▋   | 4/6 [00:00<00:00, 53.04it/s]    Predicting DataLoader 0:  83%|████████▎ | 5/6 [00:00<00:00, 59.52it/s]    Predicting DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 70.53it/s]    Predicting DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 70.27it/s]




.. GENERATED FROM PYTHON SOURCE LINES 318-320

We also extract the ages of the subjects for coloring the points in the
visualizations and for evaluating the representations on age prediction.

.. GENERATED FROM PYTHON SOURCE LINES 320-326

.. code-block:: Python

    y_train_vbm = [y for (_, y) in dataloader_vbm_train.dataset.samples]
    y_test_vbm = [y for (_, y) in dataloader_vbm_test.dataset.samples]
    y_train_sbm = [y for (_, y) in dataloader_sbm_train.dataset.samples]
    y_test_sbm = [y for (_, y) in dataloader_sbm_test.dataset.samples]









.. GENERATED FROM PYTHON SOURCE LINES 327-329

We then apply MDS on the test set and visualize the results. The
points are colored according to the age of the subjects.

.. GENERATED FROM PYTHON SOURCE LINES 329-366

.. code-block:: Python



    def plot_mds_side_by_side(Z_vbm, Z_sbm, y_vbm, y_sbm):
        """Run MDS on VBM and SBM embeddings and plot side-by-side scatter
        plots."""
        mds = MDS(n_components=2, n_init=4, max_iter=300)

        # Fit-transform embeddings
        Z_vbm_mds = mds.fit_transform(Z_vbm.cpu())
        Z_sbm_mds = mds.fit_transform(Z_sbm.cpu())

        # Side-by-side plots
        fig, axes = plt.subplots(1, 2, figsize=(12, 5))

        sc1 = axes[0].scatter(
            Z_vbm_mds[:, 0], Z_vbm_mds[:, 1], c=y_vbm, cmap="viridis", alpha=0.8
        )
        axes[0].set_title("VBM - MDS projection")
        axes[0].set_xlabel("Dim 1")
        axes[0].set_ylabel("Dim 2")
        plt.colorbar(sc1, ax=axes[0], label="Age")

        sc2 = axes[1].scatter(
            Z_sbm_mds[:, 0], Z_sbm_mds[:, 1], c=y_sbm, cmap="viridis", alpha=0.8
        )
        axes[1].set_title("SBM - MDS projection")
        axes[1].set_xlabel("Dim 1")
        axes[1].set_ylabel("Dim 2")
        plt.colorbar(sc2, ax=axes[1], label="Age")

        plt.suptitle("MDS projections of test embeddings", fontsize=14)
        plt.tight_layout()
        plt.show()


    plot_mds_side_by_side(Z_test_vbm, Z_test_sbm, y_test_vbm, y_test_sbm)




.. image-sg:: /auto_examples/images/sphx_glr_plot_barlowtwins_openbhb_001.png
   :alt: MDS projections of test embeddings, VBM - MDS projection, SBM - MDS projection
   :srcset: /auto_examples/images/sphx_glr_plot_barlowtwins_openbhb_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 367-371

Finally, we evaluate the learned representations on age prediction using
linear regression and KNN regression. We report the mean absolute error and
the R^2 coefficient between the true and predicted ages on the test set for
each model.

.. GENERATED FROM PYTHON SOURCE LINES 371-448

.. code-block:: Python



    def evaluate_and_predict(model, Z_train, Z_test, y_train, y_test):
        """Train model and return predictions + metrics."""
        model.fit(Z_train.cpu(), y_train)
        y_pred = model.predict(Z_test.cpu())
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        return y_pred, mae, r2


    def plot_comparison(models, embeddings):
        """
        Plot side-by-side scatter plots for each model and modality.
        models: dict of {name: model}
        embeddings: dict of {modality: (Z_train, Z_test, y_train, y_test)}
        """
        n_models = len(models)
        n_modalities = len(embeddings)

        fig, axes = plt.subplots(
            n_models,
            n_modalities,
            figsize=(6 * n_modalities, 5 * n_models),
            sharex=True,
            sharey=True,
        )
        for row, (model_name, model) in enumerate(models.items()):
            for col, (modality, (Z_train, Z_test, y_train, y_test)) in enumerate(
                embeddings.items()
            ):
                y_pred, mae, r2 = evaluate_and_predict(
                    model, Z_train, Z_test, y_train, y_test
                )

                ax = axes[row, col]
                ax.scatter(
                    y_test,
                    y_pred,
                    alpha=0.7,
                    color="orange" if modality == "SBM" else "steelblue",
                )
                ax.plot(
                    [np.min(y_test), np.max(y_test)],
                    [np.min(y_test), np.max(y_test)],
                    "r--",
                    lw=2,
                    label="Ideal",
                )
                ax.set_title(
                    f"{modality} - {model_name}\nMAE={mae:.2f}, R²={r2:.2f}"
                )
                ax.set_xlabel("True Age")
                if col == 0:
                    ax.set_ylabel("Predicted Age")
                ax.legend()
                ax.grid(True)

        plt.suptitle("Model Comparison: VBM vs SBM", fontsize=16, y=1.02)
        plt.tight_layout()
        plt.show()


    # Define models and embeddings
    models = {
        "Linear Regression": LinearRegression(),
        "KNN (k=5)": KNeighborsRegressor(n_neighbors=5),
    }

    embeddings = {
        "VBM": (Z_train_vbm, Z_test_vbm, y_train_vbm, y_test_vbm),
        "SBM": (Z_train_sbm, Z_test_sbm, y_train_sbm, y_test_sbm),
    }

    # Run comparison
    plot_comparison(models, embeddings)




.. image-sg:: /auto_examples/images/sphx_glr_plot_barlowtwins_openbhb_002.png
   :alt: Model Comparison: VBM vs SBM, VBM - Linear Regression MAE=5.89, R²=0.61, SBM - Linear Regression MAE=7.04, R²=0.44, VBM - KNN (k=5) MAE=4.99, R²=0.63, SBM - KNN (k=5) MAE=6.74, R²=0.33
   :srcset: /auto_examples/images/sphx_glr_plot_barlowtwins_openbhb_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 449-458

**Observations**: From the MDS visualizations, we can observe that both VBM
and SBM embeddings show a gradient of ages, indicating that the models have
learned to organize the data in a way that reflects age similarity. However,
the VBM embeddings appear to have a more continuous distribution of ages
compared to SBM. This suggests that VBM may capture age-related features
more effectively than SBM in this context. This is confirmed when looking at
the age prediction results, where VBM outperforms SBM for both linear
regression and KNN regression. However, the results can be improved by
working with the original 3d brain scans instead of the ROI-averaged data.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (1 minutes 21.469 seconds)

**Estimated memory usage:**  115 MB


.. _sphx_glr_download_auto_examples_plot_barlowtwins_openbhb.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_barlowtwins_openbhb.ipynb <plot_barlowtwins_openbhb.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_barlowtwins_openbhb.py <plot_barlowtwins_openbhb.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_barlowtwins_openbhb.zip <plot_barlowtwins_openbhb.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
